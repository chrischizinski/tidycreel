[{"path":[]},{"path":"/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement maintainer@example.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to tidycreel","title":"Contributing to tidycreel","text":"welcome contributions tidycreel! document outlines development standards contribution process.","code":""},{"path":"/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to tidycreel","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":[]},{"path":"/CONTRIBUTING.html","id":"vectorization-first-policy","dir":"","previous_headings":"Development Principles","what":"Vectorization-First Policy","title":"Contributing to tidycreel","text":"tidycreel follows vectorization-first approach ensure performance scalability: Prefer vectorized operations explicit loops (, ) whenever possible Use grouped operations via dplyr::group_by() stratum-level calculations Leverage vectorized functions base R, tidyverse, survey packages Avoid apply() family vectorized alternatives exist Profile performance functions processing large datasets (>10^5 rows) Examples:","code":"# ✅ Good: Vectorized approach effort_total <- sum(design_data$effort * design_data$weights, na.rm = TRUE)  # ✅ Good: Grouped vectorized approach strata_totals <- design_data %>%   group_by(stratum_id) %>%   summarise(effort = sum(effort * weights, na.rm = TRUE))  # ❌ Avoid: Explicit loops effort_total <- 0 for (i in seq_len(nrow(design_data))) {   effort_total <- effort_total + design_data$effort[i] * design_data$weights[i] }"},{"path":"/CONTRIBUTING.html","id":"statistical-foundations","dir":"","previous_headings":"Development Principles","what":"Statistical Foundations","title":"Contributing to tidycreel","text":"tidycreel builds survey package authoritative engine: Use survey::svydesign() survey::svrepdesign() design objects Provide tidy wrappers around survey functions pipe-friendly interfaces Return tibbles estimates, standard errors, metadata Document statistical assumptions variance estimation methods Favor design-based estimators model-based approaches defaults","code":""},{"path":"/CONTRIBUTING.html","id":"tidyverse-style","dir":"","previous_headings":"Development Principles","what":"Tidyverse Style","title":"Contributing to tidycreel","text":"Follow tidyverse style guide completely: Function names: snake_case descriptive verbs (estimate_effort, effort_est) Variable names: snake_case clear meaning (party_size, ps) File names: kebab-case multi-word concepts (design-constructors.R) Documentation: Complete roxygen2 docs examples Pipes: Use %>% multi-step data transformations","code":""},{"path":[]},{"path":"/CONTRIBUTING.html","id":"code-quality","dir":"","previous_headings":"Technical Standards","what":"Code Quality","title":"Contributing to tidycreel","text":"100% public functions must roxygen2 documentation exported functions must include working examples Target ≥90% test coverage meaningful assertions Use usethis, devtools, testthat workflows development Run devtools::check() submitting pull requests","code":""},{"path":"/CONTRIBUTING.html","id":"testing-requirements","dir":"","previous_headings":"Technical Standards","what":"Testing Requirements","title":"Contributing to tidycreel","text":"Every contribution must include tests: Test edge cases explicitly: - Zero effort/catch scenarios - Empty strata - Missing data patterns - Single-observation groups - Date/time boundary conditions (DST, leap years)","code":"test_that(\"estimate_effort returns proper structure\", {   # Arrange   design <- create_test_design()    # Act   result <- estimate_effort(design)    # Assert   expect_s3_class(result, \"tbl_df\")   expect_true(all(c(\"effort_estimate\", \"se\", \"cv\") %in% names(result)))   expect_true(all(result$effort_estimate >= 0)) })"},{"path":"/CONTRIBUTING.html","id":"performance-expectations","dir":"","previous_headings":"Technical Standards","what":"Performance Expectations","title":"Contributing to tidycreel","text":"Functions must scale efficiently: Benchmark large datasets (10^6+ rows) tests Use profvis profiling computationally intensive functions Consider data.table backends heavy processing Document time/memory complexity key algorithms","code":""},{"path":[]},{"path":"/CONTRIBUTING.html","id":"getting-started","dir":"","previous_headings":"Contribution Workflow","what":"Getting Started","title":"Contributing to tidycreel","text":"Fork clone repository Create feature branch: git checkout -b feature/descriptive-name Set development environment:","code":"renv::restore() devtools::load_all()"},{"path":"/CONTRIBUTING.html","id":"development-process","dir":"","previous_headings":"Contribution Workflow","what":"Development Process","title":"Contributing to tidycreel","text":"Write tests first following TDD principles Implement feature following style guide Update documentation including function docs vignettes needed Run comprehensive checks: Commit clear messages following conventional commits","code":"devtools::document() devtools::test() devtools::check()"},{"path":"/CONTRIBUTING.html","id":"pull-request-guidelines","dir":"","previous_headings":"Contribution Workflow","what":"Pull Request Guidelines","title":"Contributing to tidycreel","text":"submitting: - [ ] tests pass (devtools::test()) - [ ] Package passes R CMD check (devtools::check()) - [ ] Documentation complete accurate - [ ] NEWS.md updated user-facing changes - [ ] Code follows tidyverse style (verified styler::style_pkg()) PR Description include: - Summary changes motivation - Links relevant issues - Breaking changes () - Example usage new features","code":""},{"path":[]},{"path":"/CONTRIBUTING.html","id":"file-organization","dir":"","previous_headings":"Package Architecture","what":"File Organization","title":"Contributing to tidycreel","text":"","code":"R/ ├── data-schemas.R      # Schema definitions and validation ├── design-constructors.R  # Survey design object creation ├── estimators.R        # Core estimation functions ├── legacy-*.R          # Legacy API compatibility └── utils.R             # Internal helper functions"},{"path":"/CONTRIBUTING.html","id":"naming-conventions","dir":"","previous_headings":"Package Architecture","what":"Naming Conventions","title":"Contributing to tidycreel","text":"Design functions: design_*() Estimation functions: estimate_*() Validation functions: validate_*() Utility functions: calculate_*(), create_*()","code":""},{"path":"/CONTRIBUTING.html","id":"dependencies","dir":"","previous_headings":"Package Architecture","what":"Dependencies","title":"Contributing to tidycreel","text":"Core dependencies (keep minimal): - survey - design objects estimation - dplyr, tidyr - data manipulation - rlang, vctrs - programming tools Suggested dependencies (specific features): - cli - user messaging - lifecycle - deprecation management","code":""},{"path":"/CONTRIBUTING.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting Help","title":"Contributing to tidycreel","text":"GitHub Issues: Bug reports feature requests GitHub Discussions: Questions community support Code Review: maintainers provide feedback PRs","code":""},{"path":"/CONTRIBUTING.html","id":"recognition","dir":"","previous_headings":"","what":"Recognition","title":"Contributing to tidycreel","text":"Contributors recognized : - Package DESCRIPTION file - NEWS.md release notes - Annual contributor acknowledgments Thank contributing tidycreel!","code":""},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"comprehensive-feature-planning--gap-analysis","dir":"","previous_headings":"","what":"Comprehensive Feature Planning & Gap Analysis","title":"tidycreel Development Roadmap","text":"Last Updated: October 24, 2025 Status: Package ~70% complete basic creel analysis Next Major Milestone: Complete core estimation workflow total harvest","code":""},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"current-state-assessment","dir":"","previous_headings":"Executive Summary","what":"Current State Assessment","title":"tidycreel Development Roadmap","text":"Strengths (): - ✅ 48 exported functions robust survey-first architecture - ✅ Core effort estimation methods (instantaneous, progressive, aerial, bus route) - ✅ CPUE estimation multiple approaches (ratio--means, mean--ratios, auto mode) - ✅ Basic catch estimation interview data - ✅ Survey design integration (as_day_svydesign, replicate designs) - ✅ Comprehensive validation framework - ✅ Basic visualization (plot_design, plot_effort) - ✅ Excellent documentation structure vignettes Critical Gap Identified: package lacks total harvest estimation (effort × CPUE), PRIMARY outcome creel surveys. Users can estimate effort CPUE separately, ’s function properly combine variance propagation using delta method. Completeness Assessment: - Survey Design & Sampling: 90% complete - Effort Estimation: 85% complete (missing tie-estimators, party expansion) - Catch/Harvest Estimation: 60% complete (missing total harvest calculation) - Biological Data Analysis: 20% complete (length frequencies implemented) - Visualization & Reporting: 40% complete (basic plots ) - Data Quality Tools: 70% complete (validation exists, diagnostics limited) - Survey Planning Tools: 10% complete (sample size calculators)","code":""},{"path":[]},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_1--est_total_harvest---highest-priority","dir":"","previous_headings":"Top 10 Priority Functions > PHASE 1 - Critical Missing Pieces (Immediate Priority - Next 4-6 weeks)","what":"1. 🔴 est_total_harvest() - HIGHEST PRIORITY","title":"tidycreel Development Roadmap","text":"Status: implemented Priority: P0 - Blocking users completing analyses Effort: 2-3 weeks (including tests, vignette, validation) Description: Combines effort CPUE estimates calculate total harvest proper variance propagation using delta method. Function Signature: Returns: Tibble schema: [grouping_vars], estimate, se, ci_low, ci_high, n, method, diagnostics Statistical Methods: - Product estimator: H = E × C E = effort, C = CPUE - Delta method variance: Var(H) ≈ E² × Var(C) + C² × Var(E) + 2 × E × C × Cov(E,C) - Correlation handling: effort CPUE survey, estimate correlation; otherwise assume independent Implementation Notes: - Must handle grouped estimates (join grouping variables) - Validate grouping variables match inputs - Propagate diagnostics input estimates - Handle NA values gracefully - Provide informative error messages common mistakes Testing Strategy: - Unit tests known variance propagation - Compare manual calculations - Test correlated uncorrelated inputs - Test grouped ungrouped estimates - Edge cases: zero effort, zero CPUE, single group Documentation: - Comprehensive vignette showing complete workflow: design → effort → CPUE → total harvest - Mathematical notation variance formulas - use method - Interpretation guidance Success Metrics: - Function implemented passing tests - Vignette demonstrating end--end workflow - Matches hand calculations test cases - User can complete full creel analysis start finish","code":"est_total_harvest(   effort_est,           # Tibble from est_effort()   cpue_est,             # Tibble from est_cpue()   by = NULL,            # Grouping variables (must match between inputs)   method = \"product\",   # \"product\", \"ratio_est\", \"separate_ratio\"   correlation = NULL,   # Optional correlation between effort and CPUE   conf_level = 0.95 )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_2--expand_party_to_angler","dir":"","previous_headings":"Top 10 Priority Functions > PHASE 1 - Critical Missing Pieces (Immediate Priority - Next 4-6 weeks)","what":"2. 🟡 expand_party_to_angler()","title":"tidycreel Development Roadmap","text":"Status: implemented Priority: P1 - Commonly needed, workarounds exist Effort: 1 week Description: Converts party-based counts angler counts accurate effort estimation. Many surveys record counts party/boat rather individual anglers. Function Signature: Methods: - Mean ratio: Mean anglers per party interviews, apply counts - Weighted: Survey-weighted mean expansion factor - Stratified: Separate ratios strata (e.g., weekday/weekend, mode) Use Cases: - Boat counts → angler counts - Party counts → angler counts - Vehicle counts → angler counts (occupancy data)","code":"expand_party_to_angler(   data,   party_col = \"parties_count\",   angler_col = \"anglers_count\",   by = NULL,                    # Stratification variables   method = \"mean_ratio\",        # \"mean_ratio\", \"weighted\", \"stratified\"   expansion_source = NULL       # Optional interview data for ratios )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_3--plot_estimates_timeseries","dir":"","previous_headings":"Top 10 Priority Functions > PHASE 1 - Critical Missing Pieces (Immediate Priority - Next 4-6 weeks)","what":"3. 🟡 plot_estimates_timeseries()","title":"tidycreel Development Roadmap","text":"Status: implemented Priority: P1 - Essential reporting Effort: 1-2 weeks Description: Professional time series visualization confidence bands, faceting, reference lines. Function Signature: Features: - Confidence bands customizable transparency - Automatic date formatting x-axis - Faceting categorical variables - Reference lines (e.g., historical average, management target) - Consistent tidycreel theme - Export-ready quality (print, reports, presentations) Example Output:","code":"plot_estimates_timeseries(   estimates,            # Tibble from estimation functions   x = \"date\",   y = \"estimate\",   ci = TRUE,   ci_alpha = 0.2,   facet_by = NULL,      # e.g., \"species\", \"location\"   color_by = NULL,   reference_line = NULL,   title = NULL,   theme = theme_tidycreel() ) # Time series of effort by location effort_est %>%   plot_estimates_timeseries(     x = \"date\",     facet_by = \"location\",     title = \"Fishing Effort by Access Point\"   )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_4--plot_catch_composition","dir":"","previous_headings":"Top 10 Priority Functions > PHASE 1 - Critical Missing Pieces (Immediate Priority - Next 4-6 weeks)","what":"4. 🟡 plot_catch_composition()","title":"tidycreel Development Roadmap","text":"Status: implemented Priority: P1 - Common output multi-species fisheries Effort: 1 week Description: Species composition visualization confidence intervals, supporting multiple display formats. Function Signature: Features: - Multiple visualization types - Error bars bar charts - Proportional absolute scales - Custom ordering colors - Legend management","code":"plot_catch_composition(   catch_data,   by = \"species\",   type = \"bar\",           # \"bar\", \"stacked\", \"pie\", \"treemap\"   proportional = FALSE,   # Show as proportions vs absolute   ci = TRUE,   order_by = \"estimate\",  # \"estimate\", \"alphabetical\", \"manual\"   palette = NULL )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_5--compare_estimates","dir":"","previous_headings":"Top 10 Priority Functions > PHASE 1 - Critical Missing Pieces (Immediate Priority - Next 4-6 weeks)","what":"5. 🟢 compare_estimates()","title":"tidycreel Development Roadmap","text":"Status: implemented Priority: P2 - Useful sensitivity analysis Effort: 1 week Description: Side--side comparison different estimation methods, models, time periods. Function Signature: Outputs: - Comparison table estimates - Optional forest plot showing estimates CIs - Difference calculations significance tests - Relative differences (% change) Use Cases: - Compare ratio--means vs mean--ratios - Compare years (2024 vs 2023) - Sensitivity design assumptions - Method validation","code":"compare_estimates(   estimate_list,        # Named list of estimate tibbles   metric = \"estimate\",   show_ci = TRUE,   format = \"table\",     # \"table\", \"plot\", \"both\"   test_differences = FALSE )"},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_6--est_effort_tiein","dir":"","previous_headings":"Top 10 Priority Functions > PHASE 2 - Survey Planning & Advanced Methods (Months 2-3)","what":"6. 🟢 est_effort_tiein()","title":"tidycreel Development Roadmap","text":"Status: implemented Priority: P2 - Classic methodology, agencies require Effort: 2-3 weeks Description: Classic Robson & Jones (1989) tie-estimator combining interview count data. Function Signature: Statistical Method: 1. interviews: estimate mean party hours per unit time 2. counts: total parties observed 3. Product: total effort = mean party hours × total parties 4. Variance via delta method References: - Robson & Jones (1989) - “Theoretical Basis Access Site Angler Survey Design” - Pollock et al. (1994) - “Angler Survey Methods Applications Fisheries Management”","code":"est_effort_tiein(   interviews,   counts,   svy_day,   by = c(\"date\", \"location\"),   party_hours_col = \"hours_fished\",   count_col = \"parties_count\",   method = \"traditional\"  # \"traditional\", \"stratified\" )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_7--calc_sample_size","dir":"","previous_headings":"Top 10 Priority Functions > PHASE 2 - Survey Planning & Advanced Methods (Months 2-3)","what":"7. 🟢 calc_sample_size()","title":"tidycreel Development Roadmap","text":"Status: implemented Priority: P2 - Essential survey planning Effort: 2 weeks Description: Power analysis sample size determination creel surveys. Function Signature: Methods: - CV-based: Determine n target CV - Power-based: Detect minimum effect size - Precision-based: Achieve target CI width Outputs: - Required sample size - Expected precision - Design effect adjustment - Budget implications (costs provided)","code":"calc_sample_size(   target_cv = 0.2,        # Target coefficient of variation   expected_mean = NULL,   # Expected estimate value   expected_sd = NULL,     # Expected standard deviation   power = 0.8,   alpha = 0.05,   design_effect = 1.5,    # Clustering effect   finite_pop = FALSE,     # Apply FPC?   method = \"cv\"           # \"cv\", \"power\", \"precision\" )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_8--sample_allocation","dir":"","previous_headings":"Top 10 Priority Functions > PHASE 2 - Survey Planning & Advanced Methods (Months 2-3)","what":"8. 🟢 sample_allocation()","title":"tidycreel Development Roadmap","text":"Status: implemented Priority: P2 - Optimize survey design Effort: 1-2 weeks Description: Optimal allocation sampling effort across strata. Function Signature: Methods: - Neyman allocation: Minimize variance fixed n - Proportional: Allocate proportional stratum size - Equal: Equal samples per stratum - Cost-optimal: Minimize cost target precision Use Cases: - Allocate interview days across weekday/weekend - Distribute effort across access points - Balance temporal coverage (months, seasons)","code":"sample_allocation(   total_n,   strata_sizes,         # Population sizes by stratum   strata_variance,      # Expected variance by stratum   method = \"neyman\",    # \"neyman\", \"proportional\", \"equal\", \"cost_optimal\"   costs = NULL,         # Relative costs by stratum   min_per_stratum = 2   # Minimum sample per stratum )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_9--est_length_dist","dir":"","previous_headings":"Top 10 Priority Functions > PHASE 2 - Survey Planning & Advanced Methods (Months 2-3)","what":"9. 🟢 est_length_dist()","title":"tidycreel Development Roadmap","text":"Status: implemented Priority: P2 - Common biological data analysis Effort: 2 weeks Description: Survey-weighted length frequency distribution proper variance estimation. Function Signature: Features: - Survey-weighted frequencies - Variance estimation bin - Flexible binning strategies - Handles multiple species - Integration length-weight relationships Outputs: - Length frequency table CIs - Mean length group - Size structure metrics (PSD, RSD)","code":"est_length_dist(   length_data,   svy_design,   by = NULL,   bins = NULL,            # Or specify breaks   min_length = NULL,   max_length = NULL,   bin_width = 10,         # mm or cm   proportional = FALSE )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_10--creel_report","dir":"","previous_headings":"Top 10 Priority Functions > PHASE 2 - Survey Planning & Advanced Methods (Months 2-3)","what":"10. 🟢 creel_report()","title":"tidycreel Development Roadmap","text":"Status: implemented Priority: P2 - Automate routine reporting Effort: 3-4 weeks Description: Automated comprehensive report generation creel surveys. Function Signature: Report Sections: - Executive summary key findings - Survey design description - Data quality metrics - Effort estimates temporal patterns - CPUE species/group - Total harvest estimates - Length distributions - Diagnostic plots - Methods references Output Formats: - HTML (interactive, embedded plots) - PDF (print-ready) - Word (editable) Template System: - Built-templates common report types - Customizable via Quarto/RMarkdown - Agency-specific branding options","code":"creel_report(   design,   interviews,   counts,   calendar,   output_file = \"creel_report.html\",   template = \"standard\",  # \"standard\", \"detailed\", \"summary\", \"custom\"   include_sections = c(\"effort\", \"cpue\", \"catch\", \"length\", \"diagnostics\"),   custom_sections = NULL,   parameters = list()     # Report parameters (title, dates, waterbody, etc.) )"},{"path":[]},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"detect_outliers","dir":"","previous_headings":"Additional Functions by Category > Data Quality & QA/QC","what":"detect_outliers()","title":"tidycreel Development Roadmap","text":"Priority: P3 Effort: 1 week Identify flag outliers creel data using multiple methods. Methods: - IQR rule (Q1 - k×IQR, Q3 + k×IQR) - MAD (median absolute deviation) - Dixon’s Q test - Grubbs’ test - Multivariate (Mahalanobis distance)","code":"detect_outliers(   data,   vars = c(\"catch_total\", \"hours_fished\", \"cpue\"),   method = \"iqr\",         # \"iqr\", \"mad\", \"dixon\", \"grubbs\", \"mahalanobis\"   action = \"flag\",        # \"flag\", \"remove\", \"winsorize\"   multiplier = 3,   by = NULL               # Group-specific outlier detection )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"survey_coverage_report","dir":"","previous_headings":"Additional Functions by Category > Data Quality & QA/QC","what":"survey_coverage_report()","title":"tidycreel Development Roadmap","text":"Priority: P3 Effort: 1 week Assess temporal spatial coverage survey effort. Metrics: - Percent strata sampled - Days sampled per stratum - Gap analysis (unsampled periods) - Coverage uniformity index - Recommendations additional sampling","code":"survey_coverage_report(   calendar,   actual_days,   target_coverage = 0.8,   by = c(\"month\", \"day_type\", \"location\"),   visualize = TRUE )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"qa_report","dir":"","previous_headings":"Additional Functions by Category > Data Quality & QA/QC","what":"qa_report()","title":"tidycreel Development Roadmap","text":"Priority: P3 Effort: 2 weeks Comprehensive data quality report. Checks: - Missing data patterns - Duplicate detection - Date/time consistency - Outlier flagging - Cross-table validation (interviews match calendar dates) - Species code validation - Effort unit consistency - Interview quality metrics (response rate, refusals)","code":"qa_report(   interviews,   counts,   calendar,   checks = \"all\",         # Specify which checks to run   output_format = \"html\" )"},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"est_mean_length","dir":"","previous_headings":"Additional Functions by Category > Biological Extensions","what":"est_mean_length()","title":"tidycreel Development Roadmap","text":"Priority: P3 Effort: 1 week Survey-weighted mean length group.","code":"est_mean_length(   length_data,   svy_design,   by = c(\"species\"),   length_col = \"length_mm\",   conf_level = 0.95 )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"create_age_length_key","dir":"","previous_headings":"Additional Functions by Category > Biological Extensions","what":"create_age_length_key()","title":"tidycreel Development Roadmap","text":"Priority: P4 (specialized) Effort: 2 weeks Create apply age-length keys age composition estimation.","code":"create_age_length_key(   aged_sample,   length_bins,   method = \"traditional\"  # \"traditional\", \"smooth\" )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"est_mortality_proxy","dir":"","previous_headings":"Additional Functions by Category > Biological Extensions","what":"est_mortality_proxy()","title":"tidycreel Development Roadmap","text":"Priority: P4 (specialized) Effort: 2 weeks Estimate fishing mortality indices catch rates.","code":"est_mortality_proxy(   catch_data,   effort_data,   by = \"year\",   method = \"catch_rate\"   # \"catch_rate\", \"exploitation_rate\" )"},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"model_diagnostics","dir":"","previous_headings":"Additional Functions by Category > Advanced Diagnostics","what":"model_diagnostics()","title":"tidycreel Development Roadmap","text":"Priority: P3 Effort: 2 weeks Residual analysis goodness--fit tests. Diagnostics: - Residual plots - Q-Q plots - Leverage influence - Goodness--fit tests - Variance homogeneity","code":"model_diagnostics(   estimates,   data,   tests = c(\"shapiro\", \"ks\", \"levene\"),   plot = TRUE )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"bootstrap_estimates","dir":"","previous_headings":"Additional Functions by Category > Advanced Diagnostics","what":"bootstrap_estimates()","title":"tidycreel Development Roadmap","text":"Priority: P3 Effort: 2 weeks Bootstrap resampling robust confidence intervals.","code":"bootstrap_estimates(   estimator_function,   data,   svy_design,   n_boot = 1000,   method = \"stratified\",  # \"stratified\", \"cluster\", \"simple\"   parallel = TRUE )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"sensitivity_analysis","dir":"","previous_headings":"Additional Functions by Category > Advanced Diagnostics","what":"sensitivity_analysis()","title":"tidycreel Development Roadmap","text":"Priority: P3 Effort: 2 weeks Systematically vary assumptions assess impact.","code":"sensitivity_analysis(   estimator_function,   data,   parameters,   ranges,               # Parameter ranges to test   metrics = c(\"estimate\", \"cv\", \"ci_width\") )"},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"combine_years","dir":"","previous_headings":"Additional Functions by Category > Multi-year Analysis","what":"combine_years()","title":"tidycreel Development Roadmap","text":"Priority: P3 Effort: 2 weeks Meta-analysis combining multiple years data.","code":"combine_years(   year_list,            # List of annual estimates   method = \"meta\",      # \"meta\", \"pooled\", \"average\"   weights = NULL,       # Optional weights (e.g., by precision)   test_homogeneity = TRUE )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"trend_analysis","dir":"","previous_headings":"Additional Functions by Category > Multi-year Analysis","what":"trend_analysis()","title":"tidycreel Development Roadmap","text":"Priority: P3 Effort: 2-3 weeks Temporal trend estimation survey design. Methods: - Survey-weighted regression - Mann-Kendall trend test - Locally weighted smoothing (LOESS) - Change point detection","code":"trend_analysis(   multi_year_data,   response,   time_var = \"year\",   by = NULL,   method = \"regression\", # \"regression\", \"mann_kendall\", \"loess\"   svy_design = NULL )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"detect_changepoints","dir":"","previous_headings":"Additional Functions by Category > Multi-year Analysis","what":"detect_changepoints()","title":"tidycreel Development Roadmap","text":"Priority: P4 (specialized) Effort: 2 weeks Identify regime shifts time series data.","code":"detect_changepoints(   time_series_data,   response,   method = \"pettitt\",    # \"pettitt\", \"bcp\", \"segmented\"   confidence = 0.95 )"},{"path":[]},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"plot_effort_distribution","dir":"","previous_headings":"Enhanced Visualization Suite > Priority Plots (Beyond Top 10)","what":"plot_effort_distribution()","title":"tidycreel Development Roadmap","text":"Priority: P2 Effort: 1 week Visualize effort distribution time/space.","code":"plot_effort_distribution(   effort_data,   type = \"histogram\",    # \"histogram\", \"density\", \"violin\"   by = NULL,   overlay_normal = FALSE )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"plot_model_comparison","dir":"","previous_headings":"Enhanced Visualization Suite > Priority Plots (Beyond Top 10)","what":"plot_model_comparison()","title":"tidycreel Development Roadmap","text":"Priority: P2 Effort: 1 week Visual comparison different models/methods. Outputs: - Forest plot estimates CIs - AIC comparison table - Relative effect sizes","code":"plot_model_comparison(   model_results,   type = \"forest\",       # \"forest\", \"bar\", \"table\"   metric = \"estimate\",   show_aic = TRUE )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"plot_length_frequency","dir":"","previous_headings":"Enhanced Visualization Suite > Priority Plots (Beyond Top 10)","what":"plot_length_frequency()","title":"tidycreel Development Roadmap","text":"Priority: P2 Effort: 1 week Length frequency histograms confidence intervals.","code":"plot_length_frequency(   length_data,   by = NULL,   bins = 20,   ci = TRUE,   reference_lengths = NULL  # e.g., size limits )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"plot_catch_map-spatial","dir":"","previous_headings":"Enhanced Visualization Suite > Priority Plots (Beyond Top 10)","what":"plot_catch_map() (Spatial)","title":"tidycreel Development Roadmap","text":"Priority: P4 (spatial scope expands) Effort: 2 weeks Spatial distribution catch/effort.","code":"plot_catch_map(   catch_data,   locations,            # Spatial coordinates   metric = \"cpue\",   map_type = \"point\"    # \"point\", \"heatmap\", \"polygon\" )"},{"path":[]},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"sprint-1-critical-gap-closure-weeks-1-4","dir":"","previous_headings":"Implementation Strategy > Development Phases","what":"SPRINT 1: Critical Gap Closure (Weeks 1-4)","title":"tidycreel Development Roadmap","text":"Goal: Enable users complete full creel analysis workflow Deliverables: 1. est_total_harvest() implemented tests 2. expand_party_to_angler() implemented tests 3. Comprehensive vignette: “Complete Creel Analysis Workflow” 4. Update getting-started vignette harvest example Success Criteria: - [ ] User can estimate total harvest effort CPUE - [ ] Variance properly propagated using delta method - [ ] tests passing >90% coverage - [ ] Vignette demonstrates end--end analysis - [ ] Documentation reviewed fisheries expert","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"sprint-2-visualization--communication-weeks-5-7","dir":"","previous_headings":"Implementation Strategy > Development Phases","what":"SPRINT 2: Visualization & Communication (Weeks 5-7)","title":"tidycreel Development Roadmap","text":"Goal: Professional-quality plots reports presentations Deliverables: 1. plot_estimates_timeseries() - time series CIs 2. plot_catch_composition() - species composition 3. compare_estimates() - model comparison 4. Visualization vignette examples 5. Consistent tidycreel theme Success Criteria: - [ ] Plots ready publication/reports - [ ] Consistent styling across plots - [ ] Export common formats (PNG, PDF, SVG) - [ ] Examples vignettes - [ ] User feedback incorporated","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"sprint-3-survey-planning-tools-weeks-8-11","dir":"","previous_headings":"Implementation Strategy > Development Phases","what":"SPRINT 3: Survey Planning Tools (Weeks 8-11)","title":"tidycreel Development Roadmap","text":"Goal: Support survey design optimization Deliverables: 1. calc_sample_size() - power analysis 2. sample_allocation() - optimal allocation 3. survey_coverage_report() - QA/QC 4. Survey planning vignette Success Criteria: - [ ] Sample size calculations match published methods - [ ] Allocation algorithms validated - [ ] Coverage reports actionable - [ ] Integrated design workflow","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"sprint-4-advanced-methods-weeks-12-16","dir":"","previous_headings":"Implementation Strategy > Development Phases","what":"SPRINT 4: Advanced Methods (Weeks 12-16)","title":"tidycreel Development Roadmap","text":"Goal: Classic methods biological extensions Deliverables: 1. est_effort_tiein() - Robson & Jones methodology 2. est_length_dist() - length frequencies 3. est_mean_length() - mean length estimation 4. Biological data vignette Success Criteria: - [ ] Tie-estimates match published examples - [ ] Length distributions properly weighted - [ ] Integration size limit regulations - [ ] Validated known datasets","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"sprint-5-reporting--automation-weeks-17-21","dir":"","previous_headings":"Implementation Strategy > Development Phases","what":"SPRINT 5: Reporting & Automation (Weeks 17-21)","title":"tidycreel Development Roadmap","text":"Goal: Automated report generation Deliverables: 1. creel_report() - comprehensive reports 2. Report templates (standard, detailed, summary) 3. Customization guide 4. Example reports Success Criteria: - [ ] HTML/PDF reports generated automatically - [ ] Templates cover common use cases - [ ] Customization straightforward - [ ] Agency adoption","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"sprint-6-data-quality--diagnostics-weeks-22-26","dir":"","previous_headings":"Implementation Strategy > Development Phases","what":"SPRINT 6: Data Quality & Diagnostics (Weeks 22-26)","title":"tidycreel Development Roadmap","text":"Goal: Robust QA/QC diagnostic tools Deliverables: 1. detect_outliers() - outlier detection 2. qa_report() - comprehensive QA 3. model_diagnostics() - goodness--fit 4. Quality assurance vignette Success Criteria: - [ ] Outlier detection algorithms validated - [ ] QA reports catch common errors - [ ] Diagnostics guide interpretation - [ ] Integration workflow","code":""},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_1-survey-first-consistency","dir":"","previous_headings":"Implementation Strategy > Design Principles","what":"1. Survey-First Consistency","title":"tidycreel Development Roadmap","text":"functions must integrate seamlessly survey package: - Accept svydesign/svrepdesign objects - Return consistent tibble schema - Preserve survey design properties - Support replicate weights Standard Return Schema:","code":"tibble(   [grouping_vars],   estimate,   se,   ci_low,   ci_high,   n,   method,   diagnostics  # list-column with additional info )"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_2-composability--pipe-friendliness","dir":"","previous_headings":"Implementation Strategy > Design Principles","what":"2. Composability & Pipe-Friendliness","title":"tidycreel Development Roadmap","text":"Functions work together seamlessly:","code":"# Example: Complete workflow svy_day %>%   est_effort(counts, method = \"instantaneous\") %>%   combine_with_cpue(cpue_est) %>%   est_total_harvest() %>%   plot_estimates_timeseries(facet_by = \"location\")"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_3-defensive-programming","dir":"","previous_headings":"Implementation Strategy > Design Principles","what":"3. Defensive Programming","title":"tidycreel Development Roadmap","text":"Validate inputs rigorously Informative error messages (use cli package) Warn potential issues (lonely PSUs, small samples) Handle edge cases gracefully (zero values, missing data) Document assumptions clearly Example Error Message:","code":"if (!all(by %in% names(effort_est))) {   cli::cli_abort(c(     \"x\" = \"Grouping variables not found in effort estimates.\",     \"i\" = \"Available variables: {.field {names(effort_est)}}\",     \"!\" = \"Missing: {.field {setdiff(by, names(effort_est))}}\"   )) }"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_4-performance-considerations","dir":"","previous_headings":"Implementation Strategy > Design Principles","what":"4. Performance Considerations","title":"tidycreel Development Roadmap","text":"Vectorize operations (avoid loops) Use grouped operations (dplyr::group_by() + summarise()) Lazy evaluation possible Profile bottlenecks large datasets Consider parallel processing bootstrap/permutation tests","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_5-testing-strategy","dir":"","previous_headings":"Implementation Strategy > Design Principles","what":"5. Testing Strategy","title":"tidycreel Development Roadmap","text":"Test Coverage Targets: - Unit tests: >90% coverage functions - Integration tests: Complete workflows - Validation tests: Compare published results - Edge case tests: Extreme values, missing data, single groups Test Data: - Synthetic data known properties - Published datasets expected results - Edge cases boundary conditions Example Test Structure:","code":"test_that(\"est_total_harvest multiplies effort and CPUE\", {   # Known inputs   effort <- tibble(estimate = 1000, se = 100, species = \"bass\")   cpue <- tibble(estimate = 2, se = 0.2, species = \"bass\")    # Expected output   expected_harvest <- 2000   expected_se <- sqrt(1000^2 * 0.2^2 + 2^2 * 100^2)  # Delta method    # Actual   result <- est_total_harvest(effort, cpue, by = \"species\")    # Assertions   expect_equal(result$estimate, expected_harvest)   expect_equal(result$se, expected_se, tolerance = 0.01) })"},{"path":"/DEVELOPMENT_ROADMAP.html","id":"id_6-documentation-standards","dir":"","previous_headings":"Implementation Strategy > Design Principles","what":"6. Documentation Standards","title":"tidycreel Development Roadmap","text":"Required Function: - Clear purpose statement - Parameter descriptions types defaults - Return value schema - Statistical methods references - Examples using toy data - Common use cases - Edge cases limitations Vignette Structure: - Introduction learning objectives - Conceptual overview - Step--step examples - Real-world applications - Troubleshooting common issues - References literature","code":""},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"p0---blocking-must-have-immediately","dir":"","previous_headings":"Priority Matrix","what":"P0 - Blocking (Must have immediately)","title":"tidycreel Development Roadmap","text":"est_total_harvest() - Can’t complete analyses without ","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"p1---high-priority-next-2-months","dir":"","previous_headings":"Priority Matrix","what":"P1 - High Priority (Next 2 months)","title":"tidycreel Development Roadmap","text":"expand_party_to_angler() - Common preprocessing need plot_estimates_timeseries() - Essential communication plot_catch_composition() - Multi-species fisheries compare_estimates() - Method validation","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"p2---medium-priority-months-3-5","dir":"","previous_headings":"Priority Matrix","what":"P2 - Medium Priority (Months 3-5)","title":"tidycreel Development Roadmap","text":"est_effort_tiein() - Classic methodology calc_sample_size() - Survey planning sample_allocation() - Design optimization est_length_dist() - Biological data creel_report() - Automated reporting","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"p3---nice-to-have-months-6-12","dir":"","previous_headings":"Priority Matrix","what":"P3 - Nice to Have (Months 6-12)","title":"tidycreel Development Roadmap","text":"QA/QC tools (detect_outliers(), qa_report()) Advanced diagnostics (model_diagnostics(), bootstrap_estimates()) Multi-year analysis (combine_years(), trend_analysis()) Enhanced visualizations","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"p4---specialized-future-consideration","dir":"","previous_headings":"Priority Matrix","what":"P4 - Specialized (Future consideration)","title":"tidycreel Development Roadmap","text":"Age composition estimators Economic valuation Spatial analysis tools Mortality proxies","code":""},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"package-completeness","dir":"","previous_headings":"Success Metrics","what":"Package Completeness","title":"tidycreel Development Roadmap","text":"100% core creel workflow implemented 85%+ common use cases supported <5 critical missing features","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"code-quality","dir":"","previous_headings":"Success Metrics","what":"Code Quality","title":"tidycreel Development Roadmap","text":">90% test coverage functions documented examples Zero ERROR/WARNING/NOTE R CMD check Passes lintr style checks","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"user-adoption","dir":"","previous_headings":"Success Metrics","what":"User Adoption","title":"tidycreel Development Roadmap","text":">10 successful analyses external users Positive feedback fisheries professionals Agency adoption (least 1 state/federal agency) Published analyses using package","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"performance","dir":"","previous_headings":"Success Metrics","what":"Performance","title":"tidycreel Development Roadmap","text":"Handles datasets 100K interviews efficiently (<10s) Parallel processing computationally intensive operations Memory-efficient large simulations","code":""},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"technical-risks","dir":"","previous_headings":"Risk Assessment","what":"Technical Risks","title":"tidycreel Development Roadmap","text":"Risk: Variance propagation errors total harvest estimation - Likelihood: Medium - Impact: High (incorrect inference) - Mitigation: Extensive testing known results, peer review statistician Risk: Survey design edge cases (lonely PSUs, single-stratum) - Likelihood: High - Impact: Medium (estimation fails) - Mitigation: Robust error handling, clear warnings, documented solutions Risk: Performance degradation large datasets - Likelihood: Medium - Impact: Medium (user frustration) - Mitigation: Profiling, optimization, parallel processing","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"adoption-risks","dir":"","previous_headings":"Risk Assessment","what":"Adoption Risks","title":"tidycreel Development Roadmap","text":"Risk: Learning curve steep target users - Likelihood: Medium - Impact: High (low adoption) - Mitigation: Comprehensive vignettes, workshops, support Risk: Competition established tools (FSA, RMark, custom scripts) - Likelihood: High - Impact: Medium (slow adoption) - Mitigation: Clear advantages (survey-first, modern, documented), migration guides","code":""},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"current-dependencies-keep-lean","dir":"","previous_headings":"Dependencies","what":"Current Dependencies (Keep Lean)","title":"tidycreel Development Roadmap","text":"survey - Core survey design estimation dplyr - Data manipulation tidyr - Data tidying ggplot2 - Visualization cli - User communication tibble - Modern data frames purrr - Functional programming","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"potential-new-dependencies-evaluate-carefully","dir":"","previous_headings":"Dependencies","what":"Potential New Dependencies (Evaluate Carefully)","title":"tidycreel Development Roadmap","text":"scales - Axis formatting (ggplot2 extension) patchwork - Combine plots gt flextable - Publication-quality tables quarto rmarkdown - Report generation future - Parallel processing backend","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"avoid-unless-essential","dir":"","previous_headings":"Dependencies","what":"Avoid Unless Essential","title":"tidycreel Development Roadmap","text":"Heavy spatial packages (sf, terra) - spatial scope expands Database backends - needed large data Shiny - keep separate core package","code":""},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"statistical-methods","dir":"","previous_headings":"References & Resources","what":"Statistical Methods","title":"tidycreel Development Roadmap","text":"Pollock, K. H., C. M. Jones, T. L. Brown. 1994. “Angler Survey Methods Applications Fisheries Management.” American Fisheries Society Special Publication 25. Robson, D. S., C. M. Jones. 1989. “Theoretical Basis Access Site Angler Survey Design.” Biometrics 45:83-98. Lumley, T. 2010. “Complex Surveys: Guide Analysis Using R.” Wiley.","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"r-package-development","dir":"","previous_headings":"References & Resources","what":"R Package Development","title":"tidycreel Development Roadmap","text":"Wickham, H., J. Bryan. “R Packages” (2nd ed.). https://r-pkgs.org Tidyverse Style Guide: https://style.tidyverse.org","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"survey-package-resources","dir":"","previous_headings":"References & Resources","what":"Survey Package Resources","title":"tidycreel Development Roadmap","text":"survey package documentation: https://r-survey.r-forge.r-project.org/survey/ Survey analysis R tutorial: https://stats.idre.ucla.edu/r/seminars/survey-data-analysis--r/","code":""},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"october-24-2025---initial-roadmap","dir":"","previous_headings":"Changelog","what":"October 24, 2025 - Initial Roadmap","title":"tidycreel Development Roadmap","text":"Completed comprehensive gap analysis Identified top 10 priority functions Defined 6-sprint development plan (26 weeks) Established design principles testing strategy","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"next-review-november-2025","dir":"","previous_headings":"Changelog","what":"Next Review: November 2025","title":"tidycreel Development Roadmap","text":"Assess Sprint 1 progress Adjust priorities based user feedback Update timelines needed","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"tidycreel Development Roadmap","text":"roadmap living document. Contributions feedback welcome: Function Priorities: Disagree priorities? Open issue discuss. New Features: Suggest additional functions use case justification. Implementation: Pick function submit PR following design principles. Testing: Help validate implementations published results. Contact: See CONTRIBUTING.md guidelines.","code":""},{"path":[]},{"path":"/DEVELOPMENT_ROADMAP.html","id":"effort-estimation","dir":"","previous_headings":"Appendix: Function Quick Reference","what":"Effort Estimation","title":"tidycreel Development Roadmap","text":"✅ est_effort() - Wrapper effort estimation ✅ est_effort.instantaneous() - Snapshot counts ✅ est_effort.progressive() - Roving surveys ✅ est_effort.aerial() - Aerial counts ✅ est_effort.busroute() - Bus route method 🔴 est_effort_tiein() - Tie-estimator (IMPLEMENTED)","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"catch--harvest","dir":"","previous_headings":"Appendix: Function Quick Reference","what":"Catch & Harvest","title":"tidycreel Development Roadmap","text":"✅ est_cpue() - Catch per unit effort ✅ est_catch() - Total catch interviews 🔴 est_total_harvest() - Effort × CPUE (IMPLEMENTED)","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"data-preprocessing","dir":"","previous_headings":"Appendix: Function Quick Reference","what":"Data Preprocessing","title":"tidycreel Development Roadmap","text":"🔴 expand_party_to_angler() - Party angler conversion (IMPLEMENTED) ✅ parse_time_column() - Time parsing ✅ standardize_time_columns() - Time standardization","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"survey-design","dir":"","previous_headings":"Appendix: Function Quick Reference","what":"Survey Design","title":"tidycreel Development Roadmap","text":"✅ as_day_svydesign() - Create day-level design ✅ as_survey_design() - Convert survey design ✅ as_svrep_design() - Convert replicate design ✅ design_access() - Access point design (legacy) ✅ design_roving() - Roving design (legacy) ✅ design_busroute() - Bus route design","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"visualization","dir":"","previous_headings":"Appendix: Function Quick Reference","what":"Visualization","title":"tidycreel Development Roadmap","text":"✅ plot_design() - Visualize survey design ✅ plot_effort() - Plot effort estimates 🔴 plot_estimates_timeseries() - Time series CIs (IMPLEMENTED) 🔴 plot_catch_composition() - Species composition (IMPLEMENTED) 🔴 plot_model_comparison() - Compare models (IMPLEMENTED) 🔴 plot_length_frequency() - Length distributions (IMPLEMENTED)","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"survey-planning","dir":"","previous_headings":"Appendix: Function Quick Reference","what":"Survey Planning","title":"tidycreel Development Roadmap","text":"🔴 calc_sample_size() - Sample size calculation (IMPLEMENTED) 🔴 sample_allocation() - Optimal allocation (IMPLEMENTED)","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"data-quality","dir":"","previous_headings":"Appendix: Function Quick Reference","what":"Data Quality","title":"tidycreel Development Roadmap","text":"✅ validate_interviews() - Interview validation ✅ validate_counts() - Count validation ✅ validate_calendar() - Calendar validation 🔴 detect_outliers() - Outlier detection (IMPLEMENTED) 🔴 qa_report() - Quality assurance report (IMPLEMENTED)","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"biological-data","dir":"","previous_headings":"Appendix: Function Quick Reference","what":"Biological Data","title":"tidycreel Development Roadmap","text":"🔴 est_length_dist() - Length frequency (IMPLEMENTED) 🔴 est_mean_length() - Mean length (IMPLEMENTED)","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"analysis--comparison","dir":"","previous_headings":"Appendix: Function Quick Reference","what":"Analysis & Comparison","title":"tidycreel Development Roadmap","text":"🔴 compare_estimates() - Compare estimates (IMPLEMENTED) 🔴 model_diagnostics() - Model diagnostics (IMPLEMENTED) 🔴 trend_analysis() - Temporal trends (IMPLEMENTED)","code":""},{"path":"/DEVELOPMENT_ROADMAP.html","id":"reporting","dir":"","previous_headings":"Appendix: Function Quick Reference","what":"Reporting","title":"tidycreel Development Roadmap","text":"🔴 creel_report() - Automated reports (IMPLEMENTED) Legend: - ✅ Implemented - 🔴 implemented - 🟡 Partially implemented End Roadmap","code":""},{"path":"/TOTAL_HARVEST_DESIGN.html","id":null,"dir":"","previous_headings":"","what":"Total Harvest/Catch Estimator - Design Document","title":"Total Harvest/Catch Estimator - Design Document","text":"Function: est_total_harvest() Status: Design phase Priority: P0 - Critical blocking function","code":""},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Total Harvest/Catch Estimator - Design Document","text":"Estimates total harvest, catch, releases multiplying effort estimates CPUE estimates, properly propagating variance using delta method. Supports general population estimates target species-specific estimates (caught sought).","code":""},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"primary-function","dir":"","previous_headings":"Function Signatures","what":"Primary Function","title":"Total Harvest/Catch Estimator - Design Document","text":"Returns: Standard tidycreel tibble","code":"est_total_harvest(   effort_est,                    # Tibble from est_effort()   cpue_est,                      # Tibble from est_cpue()   by = NULL,                     # Grouping variables (must match)   response = c(\"catch_total\", \"catch_kept\", \"catch_released\"),   species_groups = NULL,         # Named list for species aggregation   aggregate_level = \"species\",   # \"species\", \"group\", \"all\"   method = \"product\",            # \"product\", \"separate_ratio\"   correlation = NULL,            # Optional: correlation between E and CPUE   conf_level = 0.95,   diagnostics = TRUE ) tibble(   [grouping_vars],   estimate,        # Total harvest/catch/release   se,              # Standard error   ci_low,          # Lower confidence limit   ci_high,         # Upper confidence limit   n,               # Sample size   method,          # \"product\" or \"separate_ratio\"   diagnostics      # List-column with details )"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"variant-caught-while-sought-target-species","dir":"","previous_headings":"Function Signatures","what":"Variant: Caught While Sought (Target Species)","title":"Total Harvest/Catch Estimator - Design Document","text":"Alternative approach: Build main function via parameters","code":"est_total_harvest_sought(   effort_est,                    # Total effort (all anglers)   cpue_est_targeted,             # CPUE from anglers targeting this species   target_proportion,             # Proportion of effort targeting species   by = NULL,   response = c(\"catch_total\", \"catch_kept\", \"catch_released\"),   method = \"product\",   conf_level = 0.95,   diagnostics = TRUE ) est_total_harvest(   effort_est,   cpue_est,   by = NULL,   response = \"catch_total\",   target_species_only = FALSE,   # If TRUE, filter to targeted effort   target_species_col = \"target_species\",   method = \"product\",   correlation = NULL,   conf_level = 0.95,   diagnostics = TRUE )"},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"id_1-catch_total-total-catch","dir":"","previous_headings":"Response Types","what":"1. \"catch_total\" (Total Catch)","title":"Total Harvest/Catch Estimator - Design Document","text":"fish caught, including kept released. - Numerator: Total catch interviews - CPUE: Catch per unit effort (fish/hour) - Result: Total catch = Effort × CPUE_total","code":""},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"id_2-catch_kept-total-harvest","dir":"","previous_headings":"Response Types","what":"2. \"catch_kept\" (Total Harvest)","title":"Total Harvest/Catch Estimator - Design Document","text":"Fish kept/harvested . - Numerator: Kept fish interviews - CPUE: Harvest per unit effort (kept fish/hour) - Result: Total harvest = Effort × CPUE_kept","code":""},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"id_3-catch_released-total-released","dir":"","previous_headings":"Response Types","what":"3. \"catch_released\" (Total Released)","title":"Total Harvest/Catch Estimator - Design Document","text":"Fish caught released. - Numerator: Released fish interviews - CPUE: Release rate (released fish/hour) - Result: Total released = Effort × CPUE_released Relationship Check:","code":"# Should hold approximately: catch_total ≈ catch_kept + catch_released"},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"overview-1","dir":"","previous_headings":"Species Aggregation Framework","what":"Overview","title":"Total Harvest/Catch Estimator - Design Document","text":"Creel surveys require flexible species aggregation support multiple reporting levels: 1. Individual Species: Species-specific estimates (e.g., largemouth bass, smallmouth bass) 2. Species Groups: Taxonomic management groups (e.g., black bass, panfish, catfish) 3. Species Combined: Total fishery harvest across species Key Principle: Aggregation must occur CPUE level multiplying effort, using survey-design-based aggregation properly account sampling variance.","code":""},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"level-1-individual-species-default","dir":"","previous_headings":"Species Aggregation Framework > Aggregation Levels","what":"Level 1: Individual Species (Default)","title":"Total Harvest/Catch Estimator - Design Document","text":"Returns estimates species separately:","code":"est_total_harvest(effort_est, cpue_est, by = \"species\") species          estimate    se largemouth_bass      1500   200 smallmouth_bass       800   120 bluegill             600    90"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"level-2-species-groups","dir":"","previous_headings":"Species Aggregation Framework > Aggregation Levels","what":"Level 2: Species Groups","title":"Total Harvest/Catch Estimator - Design Document","text":"Returns estimates group:","code":"species_groups <- list(   black_bass = c(\"largemouth_bass\", \"smallmouth_bass\", \"spotted_bass\"),   panfish = c(\"bluegill\", \"redear_sunfish\", \"green_sunfish\", \"pumpkinseed\"),   catfish = c(\"channel_catfish\", \"flathead_catfish\", \"blue_catfish\"),   centrarchids = c(\"black_bass\", \"panfish\")  # Can reference other groups )  est_total_harvest(   effort_est,   cpue_est,   by = \"species\",   species_groups = species_groups,   aggregate_level = \"group\" ) species_group  estimate    se black_bass         2300   235 panfish            1800   180 catfish             900   130"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"level-3-all-species-combined","dir":"","previous_headings":"Species Aggregation Framework > Aggregation Levels","what":"Level 3: All Species Combined","title":"Total Harvest/Catch Estimator - Design Document","text":"Returns single estimate across species:","code":"est_total_harvest(   effort_est,   cpue_est,   aggregate_level = \"all\" ) estimate    se     5000   350"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"statistical-approach-survey-based-aggregation","dir":"","previous_headings":"Species Aggregation Framework","what":"Statistical Approach: Survey-Based Aggregation","title":"Total Harvest/Catch Estimator - Design Document","text":"CRITICAL: Must aggregate CPUE estimates using survey design, simple addition harvest estimates. Correct Approach: 1. Aggregate CPUE species group level using survey::svyby() survey::svytotal() 2. Multiply aggregated CPUE effort 3. Propagate variance using delta method Incorrect Approach (): ignores covariance species produces incorrect variance estimates.","code":"# WRONG - Don't add harvest estimates directly harvest_bass_total <- harvest_largemouth$estimate + harvest_smallmouth$estimate"},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"option-a-pre-aggregate-cpue-recommended","dir":"","previous_headings":"Species Aggregation Framework > Implementation Strategy","what":"Option A: Pre-aggregate CPUE (Recommended)","title":"Total Harvest/Catch Estimator - Design Document","text":"User aggregates CPUE calling est_total_harvest(): Advantage: Clear two-step process, explicit survey-based aggregation Disadvantage: Requires helper function aggregate_cpue()","code":"# 1. Calculate species-level CPUE cpue_by_species <- est_cpue(svy_int, by = \"species\", response = \"catch_kept\")  # 2. Aggregate CPUE to groups using survey design # Helper function needed: aggregate_cpue() cpue_black_bass <- aggregate_cpue(   cpue_data = interviews,  # Raw interview data   svy_design = svy_int,   species_col = \"species\",   species_values = c(\"largemouth_bass\", \"smallmouth_bass\"),   group_name = \"black_bass\",   response = \"catch_kept\" )  # 3. Calculate total harvest for group harvest_black_bass <- est_total_harvest(effort_est, cpue_black_bass)"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"option-b-integrated-aggregation-user-friendly","dir":"","previous_headings":"Species Aggregation Framework > Implementation Strategy","what":"Option B: Integrated Aggregation (User-Friendly)","title":"Total Harvest/Catch Estimator - Design Document","text":"est_total_harvest() handles aggregation internally: Advantage: One-step process, user-friendly Disadvantage: Function becomes complex, requires raw data + design RECOMMENDATION: Start Option (separate aggregation), add Option B demand exists.","code":"species_groups <- list(   black_bass = c(\"largemouth_bass\", \"smallmouth_bass\") )  harvest_by_group <- est_total_harvest(   effort_est,   cpue_est,   by = \"species\",   species_groups = species_groups,   aggregate_level = \"group\",   cpue_data = interviews,   # Need raw data for aggregation   svy_design = svy_int      # Need survey design )"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"helper-function-aggregate_cpue","dir":"","previous_headings":"Species Aggregation Framework","what":"Helper Function: aggregate_cpue()","title":"Total Harvest/Catch Estimator - Design Document","text":"","code":"#' Aggregate CPUE Across Species Using Survey Design #' #' Combines CPUE estimates for multiple species into a single aggregate, #' properly accounting for survey design and covariance between species. #' #' @param cpue_data Interview data (raw, before estimation) #' @param svy_design Survey design object (svydesign/svrepdesign) #' @param species_col Column name containing species #' @param species_values Character vector of species to aggregate #' @param group_name Name for the aggregated group #' @param by Additional grouping variables (e.g., location, date) #' @param response Type of catch (\"catch_total\", \"catch_kept\", \"catch_released\") #' @param effort_col Effort column (default \"hours_fished\") #' #' @return Tibble with aggregated CPUE estimates (same schema as est_cpue) #' #' @details #' Uses survey package to properly aggregate species: #' 1. Filters to specified species #' 2. Sums catch across species within each interview #' 3. Estimates aggregate CPUE using survey design #' 4. Returns in standard tidycreel format #' #' @examples #' \\dontrun{ #' # Aggregate largemouth and smallmouth bass #' cpue_black_bass <- aggregate_cpue( #'   cpue_data = interviews, #'   svy_design = svy_int, #'   species_col = \"species\", #'   species_values = c(\"largemouth_bass\", \"smallmouth_bass\"), #'   group_name = \"black_bass\", #'   response = \"catch_kept\" #' ) #' #' # Use in total harvest calculation #' harvest_black_bass <- est_total_harvest(effort_est, cpue_black_bass) #' } #' #' @export aggregate_cpue <- function(   cpue_data,   svy_design,   species_col = \"species\",   species_values,   group_name,   by = NULL,   response = c(\"catch_total\", \"catch_kept\", \"catch_released\"),   effort_col = \"hours_fished\" ) {   # Implementation:   # 1. Validate inputs   # 2. Create aggregated catch variable   # 3. Update survey design with aggregated data   # 4. Call est_cpue() on aggregated design   # 5. Add group_name to results }"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"species-group-definitions","dir":"","previous_headings":"Species Aggregation Framework","what":"Species Group Definitions","title":"Total Harvest/Catch Estimator - Design Document","text":"Common groupings fisheries management:","code":"# Standard taxonomic groups standard_groups <- list(   # Sunfish family (Centrarchidae)   black_bass = c(\"largemouth_bass\", \"smallmouth_bass\", \"spotted_bass\",                  \"guadalupe_bass\", \"shoal_bass\"),   panfish = c(\"bluegill\", \"redear_sunfish\", \"green_sunfish\",               \"pumpkinseed\", \"longear_sunfish\", \"warmouth\",               \"white_crappie\", \"black_crappie\"),    # Catfish (Ictaluridae)   catfish = c(\"channel_catfish\", \"flathead_catfish\", \"blue_catfish\",               \"bullhead_spp\"),    # Temperate bass (Moronidae)   temperate_bass = c(\"white_bass\", \"striped_bass\", \"hybrid_striped_bass\"),    # Pike family (Esocidae)   pike = c(\"northern_pike\", \"muskellunge\", \"tiger_muskie\", \"chain_pickerel\"),    # Walleye/Sauger (Percidae - predators)   walleye_sauger = c(\"walleye\", \"sauger\", \"saugeye\"),    # Trout/Salmon (Salmonidae)   trout = c(\"rainbow_trout\", \"brown_trout\", \"brook_trout\", \"lake_trout\",             \"cutthroat_trout\"),   salmon = c(\"chinook_salmon\", \"coho_salmon\", \"sockeye_salmon\",              \"pink_salmon\", \"chum_salmon\"),    # All centrarchids (sunfish family)   centrarchids = c(\"black_bass\", \"panfish\")  # References other groups )  # Management-based groups management_groups <- list(   gamefish = c(\"black_bass\", \"pike\", \"walleye_sauger\", \"trout\", \"salmon\"),   sportfish = c(\"gamefish\", \"catfish\", \"temperate_bass\"),   nongame = c(\"carp\", \"gar\", \"bowfin\", \"buffalo\") )"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"hierarchical-aggregation","dir":"","previous_headings":"Species Aggregation Framework","what":"Hierarchical Aggregation","title":"Total Harvest/Catch Estimator - Design Document","text":"Support nested groupings (groups containing groups): Resolution Algorithm: 1. Expand group references recursively 2. Detect circular references (error) 3. Aggregate bottom (species → groups → meta-groups)","code":"species_groups <- list(   # Base groups (species level)   black_bass = c(\"largemouth_bass\", \"smallmouth_bass\"),   panfish = c(\"bluegill\", \"redear_sunfish\"),    # Meta-groups (group level)   centrarchids = c(\"black_bass\", \"panfish\"),    # Top level (all gamefish)   gamefish = c(\"centrarchids\", \"pike\", \"walleye\") )"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"multiple-stratification-levels","dir":"","previous_headings":"Species Aggregation Framework","what":"Multiple Stratification Levels","title":"Total Harvest/Catch Estimator - Design Document","text":"Support estimation multiple strata simultaneously: Returns:","code":"# By location and species group est_total_harvest(   effort_by_location,           # Effort stratified by location   cpue_by_location_species,     # CPUE by location × species   by = c(\"location\", \"species\"),   species_groups = standard_groups,   aggregate_level = \"group\" ) location  species_group  estimate    se North     black_bass         1500   200 North     panfish             800   120 South     black_bass         2000   250 South     panfish            1200   150"},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"id_1-mixed-aggregation-levels","dir":"","previous_headings":"Species Aggregation Framework > Special Cases","what":"1. Mixed Aggregation Levels","title":"Total Harvest/Catch Estimator - Design Document","text":"User wants species individually groups:","code":"# Want: largemouth (individual), other bass (grouped), panfish (grouped) cpue_largemouth <- est_cpue(svy_int, filter_species = \"largemouth_bass\") cpue_other_bass <- aggregate_cpue(   svy_int, species = c(\"smallmouth_bass\", \"spotted_bass\"),   group_name = \"other_bass\" ) cpue_panfish <- aggregate_cpue(   svy_int, species = panfish_species, group_name = \"panfish\" )  # Combine for reporting harvest_detailed <- bind_rows(   est_total_harvest(effort_est, cpue_largemouth),   est_total_harvest(effort_est, cpue_other_bass),   est_total_harvest(effort_est, cpue_panfish) )"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"id_2-all-species-combined","dir":"","previous_headings":"Species Aggregation Framework > Special Cases","what":"2. All Species Combined","title":"Total Harvest/Catch Estimator - Design Document","text":"","code":"# Aggregate CPUE across ALL species cpue_all <- aggregate_cpue(   cpue_data = interviews,   svy_design = svy_int,   species_col = \"species\",   species_values = unique(interviews$species),  # All species   group_name = \"all_species\",   response = \"catch_kept\" )  harvest_total <- est_total_harvest(effort_est, cpue_all)"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"id_3-conditional-grouping","dir":"","previous_headings":"Species Aggregation Framework > Special Cases","what":"3. Conditional Grouping","title":"Total Harvest/Catch Estimator - Design Document","text":"Group species certain locations:","code":"# Black bass grouped in reservoirs, separate in rivers est_total_harvest(   effort_est,   cpue_est,   by = c(\"waterbody_type\", \"species\"),   species_groups = list(     black_bass = c(\"largemouth_bass\", \"smallmouth_bass\")   ),   aggregate_condition = waterbody_type == \"reservoir\" )"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"validation--error-handling","dir":"","previous_headings":"Species Aggregation Framework","what":"Validation & Error Handling","title":"Total Harvest/Catch Estimator - Design Document","text":"","code":"# Check for species not in data validate_species_groups <- function(species_groups, cpue_data, species_col) {   all_species <- unique(cpue_data[[species_col]])    for (group_name in names(species_groups)) {     group_species <- species_groups[[group_name]]     missing <- setdiff(group_species, all_species)      if (length(missing) > 0) {       cli::cli_warn(c(         \"!\" = \"Species group {.field {group_name}} includes species not in data.\",         \"i\" = \"Missing species: {.val {missing}}\",         \">\" = \"These will be ignored in aggregation.\"       ))     }   } }  # Detect circular references detect_circular_refs <- function(species_groups) {   # Graph-based cycle detection   # Error if circular reference found }"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"performance-considerations","dir":"","previous_headings":"Species Aggregation Framework","what":"Performance Considerations","title":"Total Harvest/Catch Estimator - Design Document","text":"Survey aggregation computationally intensive large datasets Cache intermediate aggregations multiple harvest calculations Consider parallel processing multiple groups Document computational complexity vignettes","code":""},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"method-1-product-estimator-default","dir":"","previous_headings":"Statistical Methods","what":"Method 1: Product Estimator (Default)","title":"Total Harvest/Catch Estimator - Design Document","text":"Estimate: : - H = Total harvest - E = Total effort (angler-hours) - C = CPUE (catch per angler-hour) Variance (Delta Method): E C independent (different surveys): E C correlated (survey): Standard Error: Confidence Interval (Wald):","code":"H = E × C Var(H) = E² × Var(C) + C² × Var(E) Var(H) = E² × Var(C) + C² × Var(E) + 2 × E × C × Cov(E,C) SE(H) = sqrt(Var(H)) CI = H ± z_(α/2) × SE(H)"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"method-2-separate-ratio-estimator","dir":"","previous_headings":"Statistical Methods","what":"Method 2: Separate Ratio Estimator","title":"Total Harvest/Catch Estimator - Design Document","text":"Alternative approach treating ratio estimation problem. Estimate: use survey weights estimate ratio, multiply total effort. Variance: Use Taylor linearization replicate weights survey design.","code":"H = (Σw_i × catch_i) / (Σw_i × effort_i) × E_total"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"correlation-between-effort-and-cpue","dir":"","previous_headings":"Statistical Methods","what":"Correlation Between Effort and CPUE","title":"Total Harvest/Catch Estimator - Design Document","text":"correlated? - CPUE calculated interviews also contribute effort estimates - estimates use survey design/weights independent? - Effort count data, CPUE separate interview data - Different survey designs/time periods Estimating Correlation: provided user, can estimate data survey: Default behavior: - correlation = NULL, assume independent (conservative) - correlation = \"auto\", attempt estimate data - correlation = numeric, use provided value","code":"# If both estimates are from same source data cor_est <- estimate_correlation(effort_data, cpue_data)"},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"conceptual-framework","dir":"","previous_headings":"Target Species (“Caught While Sought”)","what":"Conceptual Framework","title":"Total Harvest/Catch Estimator - Design Document","text":"Total Catch Species S: Simplified incidental catch negligible: : - Effort_targeted_S = Effort anglers targeting species S - CPUE_S_targeted = CPUE species S among targeting ","code":"Total_S = Effort_all × CPUE_S_targeted × Prop_targeted +           Effort_all × CPUE_S_incidental × (1 - Prop_targeted) Total_S_sought = Effort_targeted_S × CPUE_S_targeted"},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"option-a-separate-function-cleaner","dir":"","previous_headings":"Target Species (“Caught While Sought”) > Implementation Options","what":"Option A: Separate Function (Cleaner)","title":"Total Harvest/Catch Estimator - Design Document","text":"","code":"est_total_harvest_sought(   effort_est,                    # Total effort   cpue_est_targeted,             # CPUE from targeted anglers   target_proportion,             # Proportion targeting   by = c(\"species\", \"location\"),   response = \"catch_kept\" )"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"option-b-integrated-function-more-flexible","dir":"","previous_headings":"Target Species (“Caught While Sought”) > Implementation Options","what":"Option B: Integrated Function (More flexible)","title":"Total Harvest/Catch Estimator - Design Document","text":"Recommendation: Start Option B (integrated) flexibility.","code":"est_total_harvest(   effort_est,   cpue_est,   by = c(\"species\", \"location\"),   response = \"catch_kept\",   target_species_only = TRUE,    # NEW parameter   target_col = \"target_species\"  # Column identifying target )"},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"input-effort_est","dir":"","previous_headings":"Data Requirements","what":"Input: effort_est","title":"Total Harvest/Catch Estimator - Design Document","text":"Tibble est_effort() required columns:","code":"- [grouping_vars] : character/factor (e.g., date, location) - estimate        : numeric (angler-hours) - se              : numeric (standard error) - ci_low          : numeric - ci_high         : numeric - n               : integer - method          : character - diagnostics     : list"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"input-cpue_est","dir":"","previous_headings":"Data Requirements","what":"Input: cpue_est","title":"Total Harvest/Catch Estimator - Design Document","text":"Tibble est_cpue() required columns:","code":"- [grouping_vars] : character/factor (must match effort_est) - estimate        : numeric (catch per hour) - se              : numeric (standard error) - ci_low          : numeric - ci_high         : numeric - n               : integer - method          : character - diagnostics     : list"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"validation","dir":"","previous_headings":"Data Requirements","what":"Validation","title":"Total Harvest/Catch Estimator - Design Document","text":"Function must check: 1. ✅ Grouping variables match inputs 2. ✅ missing values estimate/se columns 3. ✅ Positive values estimates SE 4. ✅ number groups inputs 5. ⚠️ Warn methods differ (e.g., instantaneous effort ratio--means CPUE) 6. ⚠️ Warn sample sizes differ substantially","code":""},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"phase-1-core-product-estimator-week-1","dir":"","previous_headings":"Implementation Plan","what":"Phase 1: Core Product Estimator (Week 1)","title":"Total Harvest/Catch Estimator - Design Document","text":"File: R/est-total-harvest.R","code":"#' Total Harvest/Catch Estimator (survey-first) #' #' Estimates total harvest, catch, or releases by multiplying effort and CPUE #' estimates with proper variance propagation using the delta method. #' #' @param effort_est Tibble from \\code{\\link{est_effort}} with effort estimates #' @param cpue_est Tibble from \\code{\\link{est_cpue}} with CPUE estimates #' @param by Character vector of grouping variables (must match between inputs) #' @param response Type of catch: \"catch_total\", \"catch_kept\", \"catch_released\" #' @param method Estimation method: \"product\" (default) or \"separate_ratio\" #' @param correlation Correlation between effort and CPUE. NULL (independent), #'   \"auto\" (estimate from data), or numeric value between -1 and 1. #' @param conf_level Confidence level for Wald CIs (default 0.95) #' @param diagnostics Include diagnostic information (default TRUE) #' #' @return Tibble with grouping columns, estimate, se, ci_low, ci_high, n, #'   method, and diagnostics list-column #' #' @details #' Combines effort and CPUE estimates to calculate total harvest/catch: #' #' \\deqn{H = E \\times C} #' #' where \\eqn{E} is total effort (angler-hours) and \\eqn{C} is CPUE. #' #' **Variance Propagation (Delta Method):** #' #' When effort and CPUE are independent: #' \\deqn{Var(H) = E^2 \\times Var(C) + C^2 \\times Var(E)} #' #' When correlated (e.g., from same survey): #' \\deqn{Var(H) = E^2 \\times Var(C) + C^2 \\times Var(E) + 2EC \\times Cov(E,C)} #' #' @examples #' \\dontrun{ #' # Complete workflow #' library(tidycreel) #' library(survey) #' #' # 1. Estimate effort from counts #' svy_day <- as_day_svydesign(calendar, day_id = \"date\", #'                              strata_vars = c(\"day_type\")) #' effort_est <- est_effort(svy_day, counts, method = \"instantaneous\", #'                          by = c(\"location\")) #' #' # 2. Estimate CPUE from interviews #' svy_int <- svydesign(ids = ~1, weights = ~1, data = interviews) #' cpue_est <- est_cpue(svy_int, by = c(\"location\", \"species\"), #'                      response = \"catch_kept\") #' #' # 3. Calculate total harvest #' harvest_total <- est_total_harvest( #'   effort_est, #'   cpue_est, #'   by = c(\"location\", \"species\"), #'   response = \"catch_kept\", #'   method = \"product\" #' ) #' #' # 4. Total catch and releases #' catch_total <- est_total_harvest(effort_est, cpue_total, #'                                  response = \"catch_total\") #' releases <- est_total_harvest(effort_est, cpue_released, #'                               response = \"catch_released\") #' #' # 5. Verify relationship #' catch_total$estimate ≈ harvest_total$estimate + releases$estimate #' } #' #' @references #' Seber, G.A.F. 1982. The Estimation of Animal Abundance. 2nd edition. #'   Charles Griffin, London. #' #' Pollock, K.H., C.M. Jones, and T.L. Brown. 1994. Angler Survey Methods #'   and Their Applications in Fisheries Management. American Fisheries #'   Society Special Publication 25. #' #' @seealso #' \\code{\\link{est_effort}}, \\code{\\link{est_cpue}}, \\code{\\link{est_catch}} #' #' @export est_total_harvest <- function(   effort_est,   cpue_est,   by = NULL,   response = c(\"catch_total\", \"catch_kept\", \"catch_released\"),   method = c(\"product\", \"separate_ratio\"),   correlation = NULL,   conf_level = 0.95,   diagnostics = TRUE ) {   # Implementation here }"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"phase-2-target-species-variant-week-2","dir":"","previous_headings":"Implementation Plan","what":"Phase 2: Target Species Variant (Week 2)","title":"Total Harvest/Catch Estimator - Design Document","text":"Add parameters main function: separate function:","code":"est_total_harvest(   ...,   target_species_only = FALSE,   target_col = \"target_species\",   target_value = NULL ) est_total_harvest_sought(...)"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"phase-3-testing-week-2-3","dir":"","previous_headings":"Implementation Plan","what":"Phase 3: Testing (Week 2-3)","title":"Total Harvest/Catch Estimator - Design Document","text":"Test File: tests/testthat/test-est-total-harvest.R Test cases: 1. Basic product estimator known values 2. Grouped estimates (species, location) 3. Variance propagation validation 4. Correlation handling (independent, correlated) 5. Different response types (total, kept, released) 6. Edge cases (zero effort, zero CPUE, single group) 7. Input validation (mismatched groups, missing columns) 8. Target species filtering 9. Integration actual survey data","code":""},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"phase-4-documentation-week-3","dir":"","previous_headings":"Implementation Plan","what":"Phase 4: Documentation (Week 3)","title":"Total Harvest/Catch Estimator - Design Document","text":"Vignette: vignettes/complete-creel-workflow.Rmd Sections: 1. Introduction - Complete creel analysis workflow 2. Survey Design - Creating day-level interview designs 3. Effort Estimation - count data 4. CPUE Estimation - interview data 5. Total Harvest Calculation - NEW - Total catch, harvest, releases - Variance propagation - Interpretation 6. Target Species Analysis - NEW - Caught sought - Species-specific effort 7. Visualization - Time series, comparisons 8. Reporting - Tables figures","code":""},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"decision-1-single-function-vs-multiple-functions","dir":"","previous_headings":"API Design Decisions","what":"Decision 1: Single Function vs Multiple Functions","title":"Total Harvest/Catch Estimator - Design Document","text":"Option : Single comprehensive function ✅ Pros: Flexible, fewer functions document ❌ Cons: complex parameter handling Option B: Separate functions ✅ Pros: Clearer intent, simpler parameters ❌ Cons: functions, potential code duplication DECISION: Start Option , add Option B needed.","code":"est_total_harvest(effort_est, cpue_est, ..., target_species_only = FALSE) est_total_harvest(effort_est, cpue_est, ...) est_total_harvest_sought(effort_est, cpue_est, target_col, ...)"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"decision-2-correlation-handling","dir":"","previous_headings":"API Design Decisions","what":"Decision 2: Correlation Handling","title":"Total Harvest/Catch Estimator - Design Document","text":"Option : User provides correlation ✅ Pros: Explicit, user control ❌ Cons: Requires user knowledge Option B: Auto-estimate possible ✅ Pros: Convenient, less user burden ❌ Cons: May incorrect data structure unclear Option C: Always assume independent (default) ✅ Pros: Safe default, wider CIs ❌ Cons: May overly conservative DECISION: Support three, default Option C (NULL = independent).","code":"correlation = 0.3  # User must know/estimate correlation = \"auto\"  # Function attempts to estimate correlation = NULL  # Conservative assumption"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"decision-3-response-type-consistency","dir":"","previous_headings":"API Design Decisions","what":"Decision 3: Response Type Consistency","title":"Total Harvest/Catch Estimator - Design Document","text":"Match existing pattern est_cpue() est_catch(): ADD: \"catch_released\" DECISION: - Keep existing response types - Add \"catch_released\" - Document relationship: catch_total = catch_kept + catch_released","code":"response = c(\"catch_total\", \"catch_kept\", \"weight_total\")"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"diagnostics-output","dir":"","previous_headings":"","what":"Diagnostics Output","title":"Total Harvest/Catch Estimator - Design Document","text":"diagnostics list-column include:","code":"list(   effort_method = \"instantaneous\",           # From effort estimate   cpue_method = \"ratio_of_means\",           # From CPUE estimate   correlation_assumed = 0,                   # Correlation used   correlation_source = \"user\",               # \"user\", \"auto\", \"independent\"   effort_n = 45,                            # Sample size from effort   cpue_n = 120,                             # Sample size from CPUE   variance_components = list(               # Breakdown     var_from_effort = 1000,     var_from_cpue = 500,     var_from_covariance = 0   ),   warnings = character(),                    # Any warnings generated   target_species_filter = FALSE,            # If filtered to target species   target_species_value = NULL               # Value used for filtering )"},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"errors-abort-execution","dir":"","previous_headings":"Error Messages & Warnings","what":"Errors (abort execution)","title":"Total Harvest/Catch Estimator - Design Document","text":"","code":"# Mismatched grouping variables cli::cli_abort(c(   \"x\" = \"Grouping variables don't match between effort and CPUE estimates.\",   \"i\" = \"effort_est groups: {.field {names(effort_est)}}\",   \"i\" = \"cpue_est groups: {.field {names(cpue_est)}}\",   \"!\" = \"Ensure 'by' parameter matches for both est_effort() and est_cpue().\" ))  # Missing required columns cli::cli_abort(c(   \"x\" = \"Required columns missing from {.arg effort_est}.\",   \"i\" = \"Need: {.field estimate, se}\",   \"!\" = \"Received: {.field {names(effort_est)}}\" ))  # Invalid correlation value cli::cli_abort(c(   \"x\" = \"Correlation must be between -1 and 1.\",   \"!\" = \"Received: {.val {correlation}}\" ))"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"warnings-continue-with-caution","dir":"","previous_headings":"Error Messages & Warnings","what":"Warnings (continue with caution)","title":"Total Harvest/Catch Estimator - Design Document","text":"","code":"# Different methods used cli::cli_warn(c(   \"!\" = \"Effort and CPUE used different estimation methods.\",   \"i\" = \"Effort: {.field {effort_method}}\",   \"i\" = \"CPUE: {.field {cpue_method}}\",   \">\" = \"Ensure methods are compatible for your analysis.\" ))  # Large difference in sample sizes cli::cli_warn(c(   \"!\" = \"Sample sizes differ substantially between effort and CPUE.\",   \"i\" = \"Effort n: {.val {effort_n}}\",   \"i\" = \"CPUE n: {.val {cpue_n}}\",   \">\" = \"Consider whether estimates represent same population.\" ))  # Assuming independence cli::cli_inform(c(   \"i\" = \"Assuming independence between effort and CPUE (conservative).\",   \">\" = \"If correlated, provide correlation parameter for more accurate variance.\" ))"},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"unit-tests","dir":"","previous_headings":"Testing Strategy","what":"Unit Tests","title":"Total Harvest/Catch Estimator - Design Document","text":"File: tests/testthat/test-est-total-harvest.R","code":"test_that(\"product estimator multiplies correctly\", {   effort <- tibble(estimate = 1000, se = 100)   cpue <- tibble(estimate = 2, se = 0.2)    result <- est_total_harvest(effort, cpue, correlation = NULL)    expect_equal(result$estimate, 2000) })  test_that(\"variance propagation uses delta method\", {   E <- 1000   SE_E <- 100   C <- 2   SE_C <- 0.2    # Expected variance (independent)   var_expected <- E^2 * SE_C^2 + C^2 * SE_E^2   se_expected <- sqrt(var_expected)    effort <- tibble(estimate = E, se = SE_E)   cpue <- tibble(estimate = C, se = SE_C)    result <- est_total_harvest(effort, cpue, correlation = NULL)    expect_equal(result$se, se_expected, tolerance = 0.01) })  test_that(\"correlation increases/decreases variance appropriately\", {   effort <- tibble(estimate = 1000, se = 100)   cpue <- tibble(estimate = 2, se = 0.2)    # Independent   result_ind <- est_total_harvest(effort, cpue, correlation = NULL)    # Positive correlation   result_pos <- est_total_harvest(effort, cpue, correlation = 0.5)    # Negative correlation   result_neg <- est_total_harvest(effort, cpue, correlation = -0.5)    # Positive correlation should increase variance   expect_gt(result_pos$se, result_ind$se)    # Negative correlation should decrease variance   expect_lt(result_neg$se, result_ind$se) })  test_that(\"grouped estimates work correctly\", {   effort <- tibble(     species = c(\"bass\", \"pike\"),     estimate = c(1000, 800),     se = c(100, 80),     ci_low = c(800, 640),     ci_high = c(1200, 960),     n = c(50, 40),     method = \"instantaneous\",     diagnostics = list(NULL, NULL)   )    cpue <- tibble(     species = c(\"bass\", \"pike\"),     estimate = c(2, 1.5),     se = c(0.2, 0.15),     ci_low = c(1.6, 1.2),     ci_high = c(2.4, 1.8),     n = c(100, 80),     method = \"ratio_of_means\",     diagnostics = list(NULL, NULL)   )    result <- est_total_harvest(effort, cpue, by = \"species\")    expect_equal(nrow(result), 2)   expect_equal(result$estimate[1], 2000)  # bass   expect_equal(result$estimate[2], 1200)  # pike })  test_that(\"response types work correctly\", {   effort <- tibble(estimate = 1000, se = 100, n = 50, method = \"instantaneous\",                    ci_low = 800, ci_high = 1200, diagnostics = list(NULL))   cpue_total <- tibble(estimate = 3, se = 0.3, n = 100, method = \"ratio_of_means\",                        ci_low = 2.4, ci_high = 3.6, diagnostics = list(NULL))   cpue_kept <- tibble(estimate = 2, se = 0.2, n = 100, method = \"ratio_of_means\",                       ci_low = 1.6, ci_high = 2.4, diagnostics = list(NULL))   cpue_released <- tibble(estimate = 1, se = 0.1, n = 100, method = \"ratio_of_means\",                           ci_low = 0.8, ci_high = 1.2, diagnostics = list(NULL))    total <- est_total_harvest(effort, cpue_total, response = \"catch_total\")   kept <- est_total_harvest(effort, cpue_kept, response = \"catch_kept\")   released <- est_total_harvest(effort, cpue_released, response = \"catch_released\")    # Relationship should approximately hold   expect_equal(total$estimate, kept$estimate + released$estimate, tolerance = 0.01) })  test_that(\"input validation catches errors\", {   effort <- tibble(estimate = 1000, se = 100, species = \"bass\",                    n = 50, method = \"instantaneous\", ci_low = 800,                    ci_high = 1200, diagnostics = list(NULL))   cpue <- tibble(estimate = 2, se = 0.2, location = \"lake\",                  n = 100, method = \"ratio_of_means\", ci_low = 1.6,                  ci_high = 2.4, diagnostics = list(NULL))    # Mismatched grouping variables   expect_error(     est_total_harvest(effort, cpue, by = c(\"species\", \"location\")),     \"Grouping variables\"   ) })  test_that(\"zero values handled appropriately\", {   effort <- tibble(estimate = 0, se = 0, n = 50, method = \"instantaneous\",                    ci_low = 0, ci_high = 0, diagnostics = list(NULL))   cpue <- tibble(estimate = 2, se = 0.2, n = 100, method = \"ratio_of_means\",                  ci_low = 1.6, ci_high = 2.4, diagnostics = list(NULL))    result <- est_total_harvest(effort, cpue)    expect_equal(result$estimate, 0)   expect_equal(result$se, 0) })  test_that(\"target species filtering works\", {   # This will test the target_species_only functionality once implemented   skip(\"Target species filtering not yet implemented\") })"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"integration-tests","dir":"","previous_headings":"Testing Strategy","what":"Integration Tests","title":"Total Harvest/Catch Estimator - Design Document","text":"Test real survey workflow: 1. Create survey design 2. Estimate effort counts 3. Estimate CPUE interviews 4. Calculate total harvest 5. Verify results reasonable","code":""},{"path":[]},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"example-1-basic-usage","dir":"","previous_headings":"Documentation Examples","what":"Example 1: Basic Usage","title":"Total Harvest/Catch Estimator - Design Document","text":"","code":"library(tidycreel) library(survey)  # 1. Effort from counts svy_day <- as_day_svydesign(calendar, day_id = \"date\",                              strata_vars = c(\"day_type\")) effort_est <- est_effort(svy_day, counts, method = \"instantaneous\")  # 2. CPUE from interviews svy_int <- svydesign(ids = ~1, weights = ~1, data = interviews) cpue_est <- est_cpue(svy_int, response = \"catch_kept\")  # 3. Total harvest harvest <- est_total_harvest(effort_est, cpue_est, response = \"catch_kept\")  print(harvest) #   estimate    se ci_low ci_high    n method     diagnostics #       2000   250   1510    2490   NA product   <list [1]>"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"example-2-by-species-and-location","dir":"","previous_headings":"Documentation Examples","what":"Example 2: By Species and Location","title":"Total Harvest/Catch Estimator - Design Document","text":"","code":"# Estimate by groups effort_by_loc <- est_effort(svy_day, counts, by = \"location\",                             method = \"instantaneous\") cpue_by_species <- est_cpue(svy_int, by = c(\"location\", \"species\"),                              response = \"catch_kept\")  # Total harvest by location and species harvest_detailed <- est_total_harvest(   effort_by_loc,   cpue_by_species,   by = c(\"location\", \"species\"),   response = \"catch_kept\" )  print(harvest_detailed) #   location species estimate    se ci_low ci_high    n method diagnostics #   North    bass        1500   200   1108    1892   NA product <list [1]> #   North    pike         800   120    565    1035   NA product <list [1]> #   South    bass        2200   280   1651    2749   NA product <list [1]> #   South    pike        1100   150    806    1394   NA product <list [1]>"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"example-3-total-catch-accounting","dir":"","previous_headings":"Documentation Examples","what":"Example 3: Total Catch Accounting","title":"Total Harvest/Catch Estimator - Design Document","text":"","code":"# Calculate total catch, harvest, and releases cpue_total <- est_cpue(svy_int, response = \"catch_total\") cpue_kept <- est_cpue(svy_int, response = \"catch_kept\") cpue_released <- est_cpue(svy_int, response = \"catch_released\")  catch_total <- est_total_harvest(effort_est, cpue_total,                                  response = \"catch_total\") catch_kept <- est_total_harvest(effort_est, cpue_kept,                                 response = \"catch_kept\") catch_released <- est_total_harvest(effort_est, cpue_released,                                     response = \"catch_released\")  # Verify relationship summary_table <- tibble(   metric = c(\"Total Catch\", \"Harvest (Kept)\", \"Released\"),   estimate = c(catch_total$estimate, catch_kept$estimate, catch_released$estimate),   se = c(catch_total$se, catch_kept$se, catch_released$se) )  print(summary_table) #   metric          estimate    se #   Total Catch         5000   500 #   Harvest (Kept)      3000   350 #   Released            2000   300"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"example-4-target-species-caught-while-sought","dir":"","previous_headings":"Documentation Examples","what":"Example 4: Target Species (Caught While Sought)","title":"Total Harvest/Catch Estimator - Design Document","text":"","code":"# Future implementation harvest_bass_sought <- est_total_harvest(   effort_est,   cpue_est,   by = \"species\",   response = \"catch_kept\",   target_species_only = TRUE,   target_col = \"target_species\",   target_value = \"bass\" )  print(harvest_bass_sought) #   species estimate    se ci_low ci_high    n method     diagnostics #   bass        1200   180    847    1553   NA product   <list [1]>"},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"next-steps","dir":"","previous_headings":"","what":"Next Steps","title":"Total Harvest/Catch Estimator - Design Document","text":"✅ Design document complete ⬜ Implement core function (est_total_harvest) ⬜ Write unit tests ⬜ Integration testing real data ⬜ Documentation vignettes ⬜ Add target species variant ⬜ Peer review validation","code":""},{"path":"/TOTAL_HARVEST_DESIGN.html","id":"questions-for-discussion","dir":"","previous_headings":"","what":"Questions for Discussion","title":"Total Harvest/Catch Estimator - Design Document","text":"Correlation default: default NULL (independent), \"auto\", require user specify? Target species: Separate function integrated parameters? Response types: Add \"catch_released\" calculate catch_total - catch_kept? Method options: Start just “product” also implement “separate_ratio”? Diagnostics: additional information included? Author: Planning document generated Claude Code Date: October 24, 2025 Status: Awaiting implementation","code":""},{"path":"/articles/aerial.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Aerial Effort Estimation with survey","text":"assume day-level sampling calendar aerial counts per-count minutes (optionally) total day minutes represented.","code":"library(tidycreel) library(dplyr)  calendar <- tibble::tibble(   date = as.Date(c(\"2025-08-20\",\"2025-08-21\")),   day_type = c(\"weekday\",\"weekday\"),   month = c(\"August\",\"August\"),   target_sample = c(4,4),   actual_sample = c(2,2) )  counts <- tibble::tibble(   date = as.Date(c(\"2025-08-20\",\"2025-08-20\",\"2025-08-21\",\"2025-08-21\")),   location = c(\"A\",\"B\",\"A\",\"B\"),   count = c(10,12,8,15),   interval_minutes = c(60,60,60,60),   total_day_minutes = c(720,720,720,720),   cloud = c(\"low\",\"low\",\"high\",\"high\") )"},{"path":"/articles/aerial.html","id":"day-level-survey-design","dir":"Articles","previous_headings":"","what":"Day-level survey design","title":"Aerial Effort Estimation with survey","text":"Construct day PSU design calendar. Weights target/actual per stratum.","code":"svy_day <- as_day_svydesign(calendar, day_id = \"date\", strata_vars = c(\"day_type\",\"month\"))"},{"path":"/articles/aerial.html","id":"aerial-effort-estimation","dir":"Articles","previous_headings":"","what":"Aerial effort estimation","title":"Aerial Effort Estimation with survey","text":"Estimate per-location totals design-based SE/CI via survey:","code":"res <- est_effort.aerial(   counts,   by = c(\"location\"),   minutes_col = c(\"interval_minutes\"),   total_minutes_col = c(\"total_day_minutes\"),   day_id = \"date\",   covariates = c(\"cloud\"),   svy = svy_day ) res"},{"path":"/articles/aerial.html","id":"post-stratification-calibration-optional","dir":"Articles","previous_headings":"Aerial effort estimation","what":"Post-stratification / calibration (optional)","title":"Aerial Effort Estimation with survey","text":"known population totals categorical covariate (e.g., cloud classes season), can post-stratify design: calibration known totals across numeric auxiliary variables, supply model totals: Note: Choose post-stratification vs calibration based design available auxiliary information; ensure assumptions met targets defensible.","code":"cloud_pop <- tibble::tibble(cloud = c(\"low\",\"high\"), Freq = c(12, 18)) res_ps <- est_effort.aerial(   counts, by = c(\"location\"), minutes_col = \"interval_minutes\",   total_minutes_col = \"total_day_minutes\", day_id = \"date\", svy = svy_day,   post_strata_var = \"cloud\", post_strata = cloud_pop ) res_ps # Example only; supply meaningful totals in your analysis cal_tot <- c(`(Intercept)` = 30) res_cal <- est_effort.aerial(   counts, by = c(\"location\"), minutes_col = \"interval_minutes\",   total_minutes_col = \"total_day_minutes\", day_id = \"date\", svy = svy_day,   calibrate_formula = ~ 1, calibrate_population = cal_tot, calfun = \"linear\" ) res_cal"},{"path":"/articles/aerial.html","id":"method-choice-post-stratification-vs-calibration","dir":"Articles","previous_headings":"","what":"Method Choice: Post-stratification vs Calibration","title":"Aerial Effort Estimation with survey","text":"Best categorical auxiliary variable defensible population distribution (e.g., proportion days cloud class) sample may /-represent levels. Uses survey::postStratify(design, ~cat, pop), pop columns category Freq known totals. Preserves design weights within post-strata; simple stable categories well-populated. Best adjusting numeric auxiliary totals (e.g., totals multiple covariates) raking across several margins. Uses survey::calibrate() model known totals; supports linear, raking, logit calibration functions. flexible can sensitive targets incompatible design extreme weights result; check diagnostics. Practical tips - Define day-level PSU design first; adjustments (post-stratification, calibration) operate design. - Use replicate-weight designs (svrepdesign) robust SEs complex adjustments. - Ensure auxiliary targets well-justified (e.g., climatology, flight logs) cover population period estimates. - Inspect weight distributions adjustment (e.g., summary(weights(design))).","code":""},{"path":"/articles/aerial.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Aerial Effort Estimation with survey","text":"Pollock, K.H., Jones, C.M., & Brown, T.L. (1994). Angler Survey Methods Applications Fisheries Management. American Fisheries Society Special Publication. Malvestuto, S.P. (1996). Sampling creel survey data. : Murphy, B.R. & Willis, D.W. (eds) Fisheries Techniques, 2nd ed. American Fisheries Society. Lumley, T. (2010). Complex Surveys: Guide Analysis Using R. John Wiley & Sons. (Author survey package.) Related background project-specific guidance: see creel_foundations.md, creel_effort_estimation_methods.md, creel_chapter.md repository.","code":""},{"path":"/articles/aerial.html","id":"weight-diagnostics-and-replicate-designs","dir":"Articles","previous_headings":"","what":"Weight Diagnostics and Replicate Designs","title":"Aerial Effort Estimation with survey","text":"Inspect day-level weights adjustment. Large highly skewed weights can inflate variance indicate mismatches design targets.","code":"# Weights before adjustment summary(stats::weights(svy_day))  # Convert to replicate-weight design (bootstrap) for robust SEs svy_rep <- survey::as.svrepdesign(svy_day, type = \"bootstrap\", replicates = 50) summary(svy_rep)  # Example: estimate with replicate design res_rep <- est_effort.aerial(   counts,   by = c(\"location\"),   minutes_col = c(\"interval_minutes\"),   total_minutes_col = c(\"total_day_minutes\"),   day_id = \"date\",   svy = svy_rep ) res_rep  # Optional: simple weight histogram (requires ggplot2) if (requireNamespace(\"ggplot2\", quietly = TRUE)) {   library(ggplot2)   wdf <- tibble::tibble(w = as.numeric(stats::weights(svy_day)))   ggplot(wdf, aes(w)) + geom_histogram(bins = 30) + theme_minimal() +     labs(title = \"Day-level survey weights\", x = \"Weight\", y = \"Count\") }"},{"path":"/articles/cpue_catch.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"CPUE and Catch Estimation","text":"vignette demonstrates estimate Catch Per Unit Effort (CPUE) total catch/harvest using tidycreel’s survey-first approach. estimators build survey package proper design-based inference.","code":""},{"path":[]},{"path":"/articles/cpue_catch.html","id":"cpue-estimation-modes","dir":"Articles","previous_headings":"Key Concepts","what":"CPUE Estimation Modes","title":"CPUE and Catch Estimation","text":"tidycreel provides two CPUE estimation modes: Preferred incomplete trips trip completion varies Uses survey::svyratio() proper variance robust outliers Appropriate complete trips Uses survey::svymean() pre-computed ratios Can sensitive zero-effort trips","code":""},{"path":"/articles/cpue_catch.html","id":"catchharvest-estimation","dir":"Articles","previous_headings":"Key Concepts","what":"Catch/Harvest Estimation","title":"CPUE and Catch Estimation","text":"Total catch harvest uses survey::svytotal() expand interview data population totals proper variance estimation.","code":""},{"path":"/articles/cpue_catch.html","id":"loading-example-data","dir":"Articles","previous_headings":"","what":"Loading Example Data","title":"CPUE and Catch Estimation","text":"","code":"# Load toy datasets interviews <- readr::read_csv(   system.file(\"extdata/toy_interviews.csv\", package = \"tidycreel\"),   show_col_types = FALSE ) calendar <- readr::read_csv(   system.file(\"extdata/toy_calendar.csv\", package = \"tidycreel\"),   show_col_types = FALSE )  # Preview interview data head(interviews) #> # A tibble: 6 × 17 #>   interview_id date       time_start          time_end            location mode  #>   <chr>        <date>     <dttm>              <dttm>              <chr>    <chr> #> 1 INT001       2024-01-01 2024-01-01 08:30:00 2024-01-01 08:45:00 Lake_A   boat  #> 2 INT001B      2024-01-01 2024-01-01 08:30:00 2024-01-01 08:45:00 Lake_B   boat  #> 3 INT002       2024-01-01 2024-01-01 09:15:00 2024-01-01 09:30:00 Lake_A   bank  #> 4 INT002B      2024-01-01 2024-01-01 09:15:00 2024-01-01 09:30:00 Lake_B   bank  #> 5 INT003       2024-01-01 2024-01-01 10:00:00 2024-01-01 10:20:00 Lake_A   boat  #> 6 INT003B      2024-01-01 2024-01-01 10:00:00 2024-01-01 10:20:00 Lake_B   boat  #> # ℹ 11 more variables: shift_block <chr>, day_type <chr>, party_size <dbl>, #> #   hours_fished <dbl>, target_species <chr>, catch_total <dbl>, #> #   catch_kept <dbl>, catch_released <dbl>, weight_total <dbl>, #> #   trip_complete <lgl>, effort_expansion <dbl>"},{"path":[]},{"path":"/articles/cpue_catch.html","id":"day-level-design","dir":"Articles","previous_headings":"Creating Survey Designs","what":"Day-Level Design","title":"CPUE and Catch Estimation","text":"First, create day-level design sampling calendar:","code":"# Create day-level survey design svy_day <- as_day_svydesign(   calendar,   day_id = \"date\",   strata_vars = c(\"day_type\", \"month\") )  # Check the design summary(weights(svy_day)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.027   1.027   1.064   1.052   1.064   1.064"},{"path":"/articles/cpue_catch.html","id":"interview-level-design","dir":"Articles","previous_headings":"Creating Survey Designs","what":"Interview-Level Design","title":"CPUE and Catch Estimation","text":"CPUE catch estimation, need interview-level design. Join day-level weights interviews:","code":"# Join day weights to interviews interviews_weighted <- interviews %>%   left_join(     svy_day$variables %>% select(date, .w),     by = \"date\"   )  # Create interview-level survey design svy_interview <- survey::svydesign(   ids = ~1,   weights = ~.w,   data = interviews_weighted )  # Check the design summary(weights(svy_interview)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.027   1.064   1.064   1.055   1.064   1.064"},{"path":[]},{"path":"/articles/cpue_catch.html","id":"ratio-of-means-default","dir":"Articles","previous_headings":"CPUE Estimation","what":"Ratio-of-Means (Default)","title":"CPUE and Catch Estimation","text":"ratio--means approach preferred creel surveys: estimates CPUE : CPUE=∑wi⋅catchi∑wi⋅efforti\\text{CPUE} = \\frac{\\sum w_i \\cdot \\text{catch}_i}{\\sum w_i \\cdot \\text{effort}_i} wiw_i survey weights.","code":"# CPUE by target species (ratio-of-means) cpue_species <- est_cpue(   svy_interview,   by = c(\"target_species\"),   response = \"catch_total\",   effort = \"hours_fished\",   mode = \"ratio_of_means\" )  cpue_species #> # A tibble: 4 × 8 #>   target_species estimate     se ci_low ci_high     n method         diagnostics #>   <chr>             <dbl>  <dbl>  <dbl>   <dbl> <int> <chr>          <list>      #> 1 bass               1.19 0.0527   1.08    1.29    60 cpue_ratio_of… <NULL>      #> 2 catfish            1    0        1       1       24 cpue_ratio_of… <NULL>      #> 3 panfish            2    0.164    1.68    2.32    24 cpue_ratio_of… <NULL>      #> 4 walleye            1.74 0.0802   1.58    1.90    48 cpue_ratio_of… <NULL>"},{"path":"/articles/cpue_catch.html","id":"mean-of-ratios","dir":"Articles","previous_headings":"CPUE Estimation","what":"Mean-of-Ratios","title":"CPUE and Catch Estimation","text":"complete trips, can use mean--ratios: estimates CPUE : CPUE=1n∑wi⋅catchiefforti\\text{CPUE} = \\frac{1}{n}\\sum w_i \\cdot \\frac{\\text{catch}_i}{\\text{effort}_i}","code":"# Filter to complete trips only complete_trips <- interviews_weighted %>%   filter(trip_complete == TRUE)  svy_complete <- survey::svydesign(   ids = ~1,   weights = ~.w,   data = complete_trips )  # CPUE by species (mean-of-ratios) cpue_mor <- est_cpue(   svy_complete,   by = c(\"target_species\"),   response = \"catch_total\",   effort = \"hours_fished\",   mode = \"mean_of_ratios\" )  cpue_mor #> # A tibble: 4 × 8 #>   target_species estimate     se ci_low ci_high     n method         diagnostics #>   <chr>             <dbl>  <dbl>  <dbl>   <dbl> <int> <chr>          <list>      #> 1 bass               1.16 0.0443   1.07    1.24    60 cpue_mean_of_… <NULL>      #> 2 catfish            1    0        1       1       24 cpue_mean_of_… <NULL>      #> 3 panfish            1.83 0.171    1.50    2.17    24 cpue_mean_of_… <NULL>      #> 4 walleye            1.77 0.0812   1.61    1.93    48 cpue_mean_of_… <NULL>"},{"path":"/articles/cpue_catch.html","id":"comparing-methods","dir":"Articles","previous_headings":"CPUE Estimation","what":"Comparing Methods","title":"CPUE and Catch Estimation","text":"","code":"# Compare the two methods comparison <- bind_rows(   cpue_species %>% mutate(method = \"ratio_of_means\"),   cpue_mor %>% mutate(method = \"mean_of_ratios\") ) %>%   select(target_species, method, estimate, se, ci_low, ci_high)  comparison #> # A tibble: 8 × 6 #>   target_species method         estimate     se ci_low ci_high #>   <chr>          <chr>             <dbl>  <dbl>  <dbl>   <dbl> #> 1 bass           ratio_of_means     1.19 0.0527   1.08    1.29 #> 2 catfish        ratio_of_means     1    0        1       1    #> 3 panfish        ratio_of_means     2    0.164    1.68    2.32 #> 4 walleye        ratio_of_means     1.74 0.0802   1.58    1.90 #> 5 bass           mean_of_ratios     1.16 0.0443   1.07    1.24 #> 6 catfish        mean_of_ratios     1    0        1       1    #> 7 panfish        mean_of_ratios     1.83 0.171    1.50    2.17 #> 8 walleye        mean_of_ratios     1.77 0.0812   1.61    1.93"},{"path":"/articles/cpue_catch.html","id":"cpue-by-multiple-groups","dir":"Articles","previous_headings":"CPUE Estimation","what":"CPUE by Multiple Groups","title":"CPUE and Catch Estimation","text":"can stratify CPUE multiple variables:","code":"# CPUE by species and mode cpue_mode <- est_cpue(   svy_interview,   by = c(\"target_species\", \"mode\"),   response = \"catch_total\",   effort = \"hours_fished\",   mode = \"ratio_of_means\" )  cpue_mode #> # A tibble: 6 × 9 #>   target_species mode  estimate     se ci_low ci_high     n method   diagnostics #>   <chr>          <chr>    <dbl>  <dbl>  <dbl>   <dbl> <int> <chr>    <list>      #> 1 bass           bank     0.667 0       0.667   0.667    12 cpue_ra… <NULL>      #> 2 catfish        bank     1     0       1       1        12 cpue_ra… <NULL>      #> 3 panfish        bank     2     0.164   1.68    2.32     24 cpue_ra… <NULL>      #> 4 bass           boat     1.34  0.0431  1.25    1.42     48 cpue_ra… <NULL>      #> 5 catfish        boat     1     0       1       1        12 cpue_ra… <NULL>      #> 6 walleye        boat     1.74  0.0802  1.58    1.90     48 cpue_ra… <NULL>"},{"path":[]},{"path":"/articles/cpue_catch.html","id":"total-catch","dir":"Articles","previous_headings":"Catch and Harvest Estimation","what":"Total Catch","title":"CPUE and Catch Estimation","text":"Estimate total catch using est_catch():","code":"# Total catch by species catch_species <- est_catch(   svy_interview,   by = c(\"target_species\"),   response = \"catch_total\" )  catch_species #> # A tibble: 4 × 8 #>   target_species estimate    se ci_low ci_high     n method          diagnostics #>   <chr>             <dbl> <dbl>  <dbl>   <dbl> <int> <chr>           <list>      #> 1 bass              203.  24.0   156.    250.     60 catch_total:ca… <NULL>      #> 2 catfish            37.9  7.63   22.9    52.8    24 catch_total:ca… <NULL>      #> 3 panfish            63.8 14.4    35.7    92.0    24 catch_total:ca… <NULL>      #> 4 walleye           430.  55.0   322.    538.     48 catch_total:ca… <NULL>"},{"path":"/articles/cpue_catch.html","id":"harvest-kept-fish","dir":"Articles","previous_headings":"Catch and Harvest Estimation","what":"Harvest (Kept Fish)","title":"CPUE and Catch Estimation","text":"Estimate harvest (kept fish) separately:","code":"# Harvest by species harvest_species <- est_catch(   svy_interview,   by = c(\"target_species\"),   response = \"catch_kept\" )  harvest_species #> # A tibble: 4 × 8 #>   target_species estimate    se ci_low ci_high     n method          diagnostics #>   <chr>             <dbl> <dbl>  <dbl>   <dbl> <int> <chr>           <list>      #> 1 bass              140.  16.3   108.    172.     60 catch_total:ca… <NULL>      #> 2 catfish            37.9  7.63   22.9    52.8    24 catch_total:ca… <NULL>      #> 3 panfish            63.8 14.4    35.7    92.0    24 catch_total:ca… <NULL>      #> 4 walleye           278.  36.0   208.    349.     48 catch_total:ca… <NULL>"},{"path":"/articles/cpue_catch.html","id":"released-fish","dir":"Articles","previous_headings":"Catch and Harvest Estimation","what":"Released Fish","title":"CPUE and Catch Estimation","text":"Calculate released fish difference total catch kept fish:","code":"# Released fish by species (computed as total - kept) # Since est_catch doesn't support \"catch_released\" directly, # we compute it from total catch and harvest estimates  # We already have catch_species (total) and harvest_species (kept) from above released_species <- dplyr::left_join(   catch_species,   harvest_species,   by = \"target_species\",   suffix = c(\"_total\", \"_kept\") ) %>%   dplyr::mutate(     estimate = estimate_total - estimate_kept,     # Conservative variance assuming independence: Var(total) + Var(kept)     se = sqrt(se_total^2 + se_kept^2),     ci_low = estimate - 1.96 * se,     ci_high = estimate + 1.96 * se,     n = pmax(n_total, n_kept, na.rm = TRUE),     method = \"catch_difference\"   ) %>%   dplyr::select(target_species, estimate, se, ci_low, ci_high, n, method)  released_species #> # A tibble: 4 × 7 #>   target_species estimate    se ci_low ci_high     n method           #>   <chr>             <dbl> <dbl>  <dbl>   <dbl> <int> <chr>            #> 1 bass               63.8  29.1   6.89   121.     60 catch_difference #> 2 catfish             0    10.8 -21.1     21.1    24 catch_difference #> 3 panfish             0    20.3 -39.8     39.8    24 catch_difference #> 4 walleye           152.   65.7  23.0    281.     48 catch_difference"},{"path":"/articles/cpue_catch.html","id":"catch-by-multiple-groups","dir":"Articles","previous_headings":"Catch and Harvest Estimation","what":"Catch by Multiple Groups","title":"CPUE and Catch Estimation","text":"","code":"# Catch by species and location catch_location <- est_catch(   svy_interview,   by = c(\"target_species\", \"location\"),   response = \"catch_total\" )  catch_location #> # A tibble: 8 × 9 #>   target_species location estimate    se ci_low ci_high     n method diagnostics #>   <chr>          <chr>       <dbl> <dbl>  <dbl>   <dbl> <int> <chr>  <list>      #> 1 bass           Lake_A      102.  18.8   64.7    139.     30 catch… <NULL>      #> 2 catfish        Lake_A       18.9  5.60   7.95    29.9    12 catch… <NULL>      #> 3 panfish        Lake_A       31.9 10.5   11.4     52.4    12 catch… <NULL>      #> 4 walleye        Lake_A      215.  42.5  132.     298.     24 catch… <NULL>      #> 5 bass           Lake_B      102.  18.8   64.7    139.     30 catch… <NULL>      #> 6 catfish        Lake_B       18.9  5.60   7.95    29.9    12 catch… <NULL>      #> 7 panfish        Lake_B       31.9 10.5   11.4     52.4    12 catch… <NULL>      #> 8 walleye        Lake_B      215.  42.5  132.     298.     24 catch… <NULL>"},{"path":[]},{"path":"/articles/cpue_catch.html","id":"cpue-by-species","dir":"Articles","previous_headings":"Visualization","what":"CPUE by Species","title":"CPUE and Catch Estimation","text":"","code":"# Plot CPUE with confidence intervals ggplot(cpue_species, aes(x = target_species, y = estimate)) +   geom_col(fill = \"steelblue\", alpha = 0.7) +   geom_errorbar(     aes(ymin = ci_low, ymax = ci_high),     width = 0.2   ) +   labs(     title = \"CPUE by Target Species\",     x = \"Target Species\",     y = \"CPUE (fish per hour)\",     caption = \"Error bars show 95% confidence intervals\"   ) +   theme_minimal() +   theme(axis.text.x = element_text(angle = 45, hjust = 1))"},{"path":"/articles/cpue_catch.html","id":"catch-vs-harvest","dir":"Articles","previous_headings":"Visualization","what":"Catch vs Harvest","title":"CPUE and Catch Estimation","text":"","code":"# Combine catch and harvest for comparison catch_harvest <- bind_rows(   catch_species %>% mutate(type = \"Total Catch\"),   harvest_species %>% mutate(type = \"Harvest (Kept)\") )  ggplot(catch_harvest, aes(x = target_species, y = estimate, fill = type)) +   geom_col(position = \"dodge\", alpha = 0.7) +   geom_errorbar(     aes(ymin = ci_low, ymax = ci_high),     position = position_dodge(width = 0.9),     width = 0.2   ) +   labs(     title = \"Total Catch vs Harvest by Species\",     x = \"Target Species\",     y = \"Number of Fish\",     fill = \"Type\",     caption = \"Error bars show 95% confidence intervals\"   ) +   scale_fill_manual(values = c(\"steelblue\", \"coral\")) +   theme_minimal() +   theme(axis.text.x = element_text(angle = 45, hjust = 1))"},{"path":"/articles/cpue_catch.html","id":"advanced-replicate-designs","dir":"Articles","previous_headings":"","what":"Advanced: Replicate Designs","title":"CPUE and Catch Estimation","text":"robust variance estimation, use replicate weights:","code":"# Convert to bootstrap replicate design # Note: This example requires careful setup of replicate weights # For production use, see vignette(\"replicate_designs_creel\")  svy_rep <- survey::as.svrepdesign(   svy_day,   type = \"bootstrap\",   replicates = 50,   mse = TRUE )  # Estimate CPUE with the day-level design (not shown for brevity) # For real applications, carefully join replicate weights to interview data # cpue_rep <- est_cpue(svy_day, by = c(\"target_species\"))"},{"path":"/articles/cpue_catch.html","id":"best-practices","dir":"Articles","previous_headings":"","what":"Best Practices","title":"CPUE and Catch Estimation","text":"Use ratio--means CPUE unless trips complete Check zero-effort trips using mean--ratios Use replicate designs complex variance structures Stratify appropriately using parameter Document assumptions trip completion effort measurement Visualize uncertainty using confidence intervals","code":""},{"path":[]},{"path":"/articles/cpue_catch.html","id":"ratio-of-means-variance","dir":"Articles","previous_headings":"Statistical Notes","what":"Ratio-of-Means Variance","title":"CPUE and Catch Estimation","text":"ratio--means estimator uses delta method via survey::svyratio(): Var(R̂)≈1X‾2[Var(Y‾)+R2Var(X‾)−2RCov(Y‾,X‾)]\\text{Var}(\\hat{R}) \\approx \\frac{1}{\\bar{X}^2}\\left[\\text{Var}(\\bar{Y}) + R^2\\text{Var}(\\bar{X}) - 2R\\text{Cov}(\\bar{Y},\\bar{X})\\right] R=Y‾/X‾R = \\bar{Y}/\\bar{X} ratio, Y‾\\bar{Y} mean catch, X‾\\bar{X} mean effort.","code":""},{"path":"/articles/cpue_catch.html","id":"mean-of-ratios-variance","dir":"Articles","previous_headings":"Statistical Notes","what":"Mean-of-Ratios Variance","title":"CPUE and Catch Estimation","text":"mean--ratios estimator treats ratio observation: Var(R‾)=1nVar(Ri)\\text{Var}(\\bar{R}) = \\frac{1}{n}\\text{Var}(R_i) can unstable effort varies widely includes zeros.","code":""},{"path":"/articles/cpue_catch.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"CPUE and Catch Estimation","text":"Lumley, T. (2004). Analysis complex survey samples. Journal Statistical Software, 9(1), 1-19. Pollock, K. H., Jones, C. M., & Brown, T. L. (1994). Angler survey methods applications fisheries management. American Fisheries Society. Cochran, W. G. (1977). Sampling techniques (3rd ed.). Wiley.","code":""},{"path":"/articles/cpue_catch.html","id":"see-also","dir":"Articles","previous_headings":"","what":"See Also","title":"CPUE and Catch Estimation","text":"vignette(\"getting-started\") - Introduction tidycreel vignette(\"effort_survey_first\") - Effort estimation ?est_cpue - CPUE estimation function documentation ?est_catch - Catch estimation function documentation","code":""},{"path":"/articles/effort_aerial.html","id":"aerial-survey-effort-estimation-in-tidycreel","dir":"Articles","previous_headings":"","what":"Aerial Survey Effort Estimation in tidycreel","title":"Aerial Survey Effort Estimation Example","text":"vignette demonstrates aerial effort estimation using day-PSU survey design optional visibility calibration adjustments.","code":""},{"path":"/articles/effort_aerial.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example Data","title":"Aerial Survey Effort Estimation Example","text":"","code":"library(tidycreel) library(dplyr)  # Minimal calendar and day design calendar <- tibble::tibble(   date = as.Date(c('2025-08-01','2025-08-02')),   day_type = c('weekday','weekend'),   month = c('Aug','Aug'),   target_sample = c(4,4),   actual_sample = c(2,2) ) svy_day <- as_day_svydesign(calendar, day_id = 'date', strata_vars = c('day_type','month'))  # Simulated aerial counts aerial_counts <- tibble::tibble(   date = rep(calendar$date, each = 2),   location = rep(c('A','B'), times = 2),   count = c(20, 15, 25, 18),   interval_minutes = 60,   total_day_minutes = 600,   visibility = c(0.8, 0.9, 0.75, 0.9),   calibration = c(1.05, 1.00, 1.10, 1.02) )"},{"path":"/articles/effort_aerial.html","id":"estimation-with-visibility-and-calibration-correction","dir":"Articles","previous_headings":"","what":"Estimation with Visibility and Calibration Correction","title":"Aerial Survey Effort Estimation Example","text":"","code":"result <- est_effort.aerial(   counts = aerial_counts,   by = c('location'),   minutes_col = 'interval_minutes',   total_minutes_col = 'total_day_minutes',   visibility_col = 'visibility',   calibration_col = 'calibration',   day_id = 'date',   svy = svy_day ) result"},{"path":"/articles/effort_aerial.html","id":"output-structure","dir":"Articles","previous_headings":"","what":"Output Structure","title":"Aerial Survey Effort Estimation Example","text":"estimate: Visibility- calibration-adjusted effort per group se: Standard error (design-based) ci_low, ci_high: Confidence interval n: Number counts per stratum method: “aerial” diagnostics: Diagnostics column (future expansion)","code":""},{"path":"/articles/effort_aerial.html","id":"notes","dir":"Articles","previous_headings":"","what":"Notes","title":"Aerial Survey Effort Estimation Example","text":"Visibility correction adjusts detection probability (e.g., observer bias, weather). Calibration factors integrate ground truth reference counts. Stratified expansion allows aggregation date, location, stratum. Variance estimation supports analytic (Taylor) replicate-weight designs via svrepdesign.","code":""},{"path":"/articles/effort_aerial.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Aerial Survey Effort Estimation Example","text":"Pollock, K. H., et al. (1994). “Estimating fishing effort aerial surveys.” Fisheries Research. Malvestuto, S. P. (1996). “Sampling creel survey design.” American Fisheries Society.","code":""},{"path":"/articles/effort_design_based.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Effort Estimation in Creel Surveys: Design-Based Methods","text":"vignette demonstrates estimate fishing effort using design-based methods creel surveys tidycreel package. covers instantaneous, progressive (roving), aerial estimators using day-PSU survey design variance.","code":""},{"path":"/articles/effort_design_based.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example Data","title":"Effort Estimation in Creel Surveys: Design-Based Methods","text":"","code":"library(tidycreel) library(tibble)  # Simulated instantaneous count data inst_counts <- tibble(   date = as.Date(c(\"2025-08-20\", \"2025-08-20\", \"2025-08-21\")),   time = c(\"12:00\", \"14:00\", \"13:00\"),   count = c(10, 12, 8),   interval_minutes = c(60, 60, 60),   location = c(\"A\", \"A\", \"B\") )"},{"path":"/articles/effort_design_based.html","id":"build-a-day-psu-design","dir":"Articles","previous_headings":"Example Data","what":"Build a day-PSU design","title":"Effort Estimation in Creel Surveys: Design-Based Methods","text":"","code":"calendar <- tibble(   date = as.Date(c(\"2025-08-20\",\"2025-08-21\")),   day_type = c(\"weekday\",\"weekday\"),   month = c(\"Aug\",\"Aug\"),   target_sample = c(4,4),   actual_sample = c(2,2) ) svy_day <- as_day_svydesign(calendar, day_id = \"date\", strata_vars = c(\"day_type\",\"month\"))"},{"path":"/articles/effort_design_based.html","id":"instantaneous-estimator-snapshot","dir":"Articles","previous_headings":"","what":"Instantaneous Estimator (snapshot)","title":"Effort Estimation in Creel Surveys: Design-Based Methods","text":"","code":"est_effort.instantaneous(inst_counts, by = c(\"location\"), minutes_col = \"interval_minutes\", day_id = \"date\", svy = svy_day)"},{"path":"/articles/effort_design_based.html","id":"progressive-roving-estimator","dir":"Articles","previous_headings":"","what":"Progressive (Roving) Estimator","title":"Effort Estimation in Creel Surveys: Design-Based Methods","text":"","code":"prog_counts <- tibble(   date = rep(as.Date(c(\"2025-08-20\",\"2025-08-21\")), each = 2),   location = rep(c(\"A\",\"B\"), times = 2),   pass_id = rep(1:2, times = 2),   count = c(5, 8, 10, 12),   route_minutes = c(45, 45, 45, 45) ) est_effort.progressive(prog_counts, by = c(\"location\"), route_minutes_col = \"route_minutes\", pass_id = \"pass_id\", day_id = \"date\", svy = svy_day)"},{"path":"/articles/effort_design_based.html","id":"aerial-estimator","dir":"Articles","previous_headings":"","what":"Aerial Estimator","title":"Effort Estimation in Creel Surveys: Design-Based Methods","text":"","code":"aerial_counts <- tibble(   date = as.Date(rep(\"2025-08-20\", 3)),   time = c(\"09:00\", \"11:00\", \"13:00\"),   count = c(15, 18, 20),   interval_minutes = c(45, 45, 45),   location = c(\"A\", \"B\", \"B\") ) est_effort.aerial(aerial_counts, by = c(\"location\"), minutes_col = \"interval_minutes\", day_id = \"date\", svy = svy_day)"},{"path":"/articles/effort_design_based.html","id":"diagnostics-and-grouping","dir":"Articles","previous_headings":"Aerial Estimator","what":"Diagnostics and Grouping","title":"Effort Estimation in Creel Surveys: Design-Based Methods","text":"Estimators handle missing grouping columns warnings compute design-based SE/CI day design. single-group cases without design, SE/CI may NA; prefer providing svy.","code":""},{"path":"/articles/effort_design_based.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Effort Estimation in Creel Surveys: Design-Based Methods","text":"Pollock, K.H., et al. (1994). Sampling estimation creel surveys. Fisheries, 19(6), 24-27. Malvestuto, S.P. (1996). Sampling recreational creel. Murphy & Willis (Eds.), Fisheries Techniques (2nd ed.).","code":""},{"path":"/articles/effort_examples.html","id":"extended-examples-for-effort-estimators","dir":"Articles","previous_headings":"","what":"Extended Examples for Effort Estimators","title":"Effort Estimation: Extended Examples","text":"vignette provides additional examples edge cases effort estimators tidycreel. demonstrates grouping, diagnostics, error handling. variance, prefer supplying day-PSU design built as_day_svydesign().","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"/articles/effort_examples.html","id":"example-missing-grouping-columns","dir":"Articles","previous_headings":"","what":"Example: Missing Grouping Columns","title":"Effort Estimation: Extended Examples","text":"","code":"library(tidycreel)  # Data missing 'location' and 'shift_block' counts <- tibble(   date = as.Date(c(\"2025-08-20\", \"2025-08-21\")),   time = c(\"12:00\", \"14:00\"),   count = c(10, 12),   interval_minutes = c(60, 60) ) result <- est_effort.instantaneous(counts) print(result)"},{"path":"/articles/effort_examples.html","id":"example-single-group-seci-na","dir":"Articles","previous_headings":"","what":"Example: Single Group (SE/CI NA)","title":"Effort Estimation: Extended Examples","text":"","code":"single_group <- tibble(   date = as.Date(\"2025-08-20\"),   time = \"12:00\",   count = 10,   interval_minutes = 60 ) result <- est_effort.progressive(single_group, route_minutes_col = \"interval_minutes\") print(result)"},{"path":"/articles/effort_examples.html","id":"example-multiple-groups-seci-calculated","dir":"Articles","previous_headings":"","what":"Example: Multiple Groups (SE/CI calculated)","title":"Effort Estimation: Extended Examples","text":"","code":"multi_group <- tibble(   date = rep(as.Date(\"2025-08-20\"), 4),   time = c(\"08:00\", \"10:00\", \"12:00\", \"14:00\"),   count = c(5, 8, 10, 12),   interval_minutes = c(30, 30, 30, 30),   location = c(\"A\", \"A\", \"B\", \"B\") ) result <- est_effort.aerial(multi_group, minutes_col = \"interval_minutes\") print(result)"},{"path":"/articles/effort_examples.html","id":"example-error-handling-for-missing-columns","dir":"Articles","previous_headings":"","what":"Example: Error Handling for Missing Columns","title":"Effort Estimation: Extended Examples","text":"","code":"bad_data <- tibble(date = as.Date(\"2025-08-20\"), count = 10) try(est_effort.progressive(bad_data)) # Should throw an error (missing route_minutes)"},{"path":"/articles/effort_examples.html","id":"example-custom-grouping","dir":"Articles","previous_headings":"","what":"Example: Custom Grouping","title":"Effort Estimation: Extended Examples","text":"","code":"custom_group <- tibble(   date = rep(as.Date(\"2025-08-20\"), 3),   time = c(\"09:00\", \"11:00\", \"13:00\"),   count = c(15, 18, 20),   interval_minutes = c(45, 45, 45),   region = c(\"North\", \"South\", \"South\") ) result <- est_effort.instantaneous(custom_group, by = c(\"region\")) print(result)"},{"path":[]},{"path":"/articles/effort_survey_first.html","id":"build-a-day-psu-survey-design","dir":"Articles","previous_headings":"","what":"1) Build a day-PSU survey design","title":"Effort Estimation (Survey-First)","text":"","code":"calendar <- tibble::tibble(   date = as.Date(c(\"2025-08-20\",\"2025-08-21\")),   day_type = c(\"weekday\",\"weekday\"),   month = c(\"August\",\"August\"),   target_sample = c(4,4),   actual_sample = c(2,2) )  svy_day <- as_day_svydesign(calendar, day_id = \"date\", strata_vars = c(\"day_type\",\"month\"))"},{"path":"/articles/effort_survey_first.html","id":"instantaneous-snapshot-effort","dir":"Articles","previous_headings":"","what":"2) Instantaneous (snapshot) effort","title":"Effort Estimation (Survey-First)","text":"","code":"counts_inst <- tibble::tibble(   date = as.Date(c(\"2025-08-20\",\"2025-08-20\",\"2025-08-21\",\"2025-08-21\")),   location = c(\"A\",\"B\",\"A\",\"B\"),   count = c(10,12,8,15),   interval_minutes = 60,   total_day_minutes = 720 )  res_inst <- est_effort.instantaneous(   counts_inst,   by = c(\"location\"),   minutes_col = c(\"interval_minutes\"),   total_minutes_col = c(\"total_day_minutes\"),   day_id = \"date\",   svy = svy_day ) res_inst"},{"path":"/articles/effort_survey_first.html","id":"progressive-roving-effort","dir":"Articles","previous_headings":"","what":"3) Progressive (roving) effort","title":"Effort Estimation (Survey-First)","text":"","code":"counts_prog <- tibble::tibble(   date = rep(as.Date(c(\"2025-08-20\",\"2025-08-21\")), each = 4),   location = rep(c(\"A\",\"A\",\"B\",\"B\"), times = 2),   pass_id = rep(c(1,2,1,2), times = 2),   count = c(10,12,8,15,9,11,7,16),   route_minutes = 60 )  res_prog <- est_effort.progressive(   counts_prog,   by = c(\"location\"),   route_minutes_col = c(\"route_minutes\"),   pass_id = c(\"pass_id\"),   day_id = \"date\",   svy = svy_day ) res_prog"},{"path":"/articles/effort_survey_first.html","id":"notes","dir":"Articles","previous_headings":"","what":"Notes","title":"Effort Estimation (Survey-First)","text":"Estimates variance come day-PSU design via survey package. replicate variance, convert svy_day survey::.svrepdesign() pass estimators. Prefer defining total_minutes_col instantaneous counts; otherwise estimator sums per-count minutes warning.","code":""},{"path":"/articles/effort_survey_first.html","id":"see-also","dir":"Articles","previous_headings":"","what":"See also","title":"Effort Estimation (Survey-First)","text":"vignettes/aerial.Rmd aerial snapshot counts covariates calibration/post-stratification. ?est_effort.instantaneous, ?est_effort.progressive, ?as_day_svydesign.","code":""},{"path":"/articles/getting-started.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with tidycreel","text":"tidycreel package provides survey-first framework creel surveys, built survey package. Estimation uses day-level survey designs (svydesign) created sampling calendar as_day_svydesign(), interview-level designs CPUE catch estimation.","code":""},{"path":"/articles/getting-started.html","id":"survey-design-types","dir":"Articles","previous_headings":"","what":"Survey Design Types","title":"Getting Started with tidycreel","text":"tidycreel supports three main data components: Interviews (access-point roving) count tables (instantaneous/progressive). Sampling calendar (days, strata, target vs actual samples). Estimators operate day-PSU svydesign variance.","code":""},{"path":"/articles/getting-started.html","id":"loading-example-data","dir":"Articles","previous_headings":"","what":"Loading Example Data","title":"Getting Started with tidycreel","text":"package includes example datasets ’ll use throughout vignette:","code":"# Load example datasets interviews <- readr::read_csv(   system.file(\"extdata/toy_interviews.csv\", package = \"tidycreel\") ) #> Rows: 26 Columns: 17 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr  (6): interview_id, location, mode, shift_block, day_type, target_species #> dbl  (7): party_size, hours_fished, catch_total, catch_kept, catch_released,... #> lgl  (1): trip_complete #> dttm (2): time_start, time_end #> date (1): date #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. counts <- readr::read_csv(   system.file(\"extdata/toy_counts.csv\", package = \"tidycreel\") ) #> Rows: 24 Columns: 16 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr  (8): count_id, location, mode, weather_code, visibility, count_category... #> dbl  (6): anglers_count, parties_count, temperature, wind_speed, count_durat... #> dttm (1): time #> date (1): date #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. calendar <- readr::read_csv(   system.file(\"extdata/toy_calendar.csv\", package = \"tidycreel\") ) #> Rows: 18 Columns: 11 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr  (6): stratum_id, day_type, season, month, shift_block, location #> dbl  (2): target_sample, actual_sample #> lgl  (2): weekend, holiday #> date (1): date #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.  # Preview the data head(interviews) #> # A tibble: 6 × 17 #>   interview_id date       time_start          time_end            location mode  #>   <chr>        <date>     <dttm>              <dttm>              <chr>    <chr> #> 1 INT001       2024-01-01 2024-01-01 08:30:00 2024-01-01 08:45:00 Lake_A   boat  #> 2 INT001B      2024-01-01 2024-01-01 08:30:00 2024-01-01 08:45:00 Lake_B   boat  #> 3 INT002       2024-01-01 2024-01-01 09:15:00 2024-01-01 09:30:00 Lake_A   bank  #> 4 INT002B      2024-01-01 2024-01-01 09:15:00 2024-01-01 09:30:00 Lake_B   bank  #> 5 INT003       2024-01-01 2024-01-01 10:00:00 2024-01-01 10:20:00 Lake_A   boat  #> 6 INT003B      2024-01-01 2024-01-01 10:00:00 2024-01-01 10:20:00 Lake_B   boat  #> # ℹ 11 more variables: shift_block <chr>, day_type <chr>, party_size <dbl>, #> #   hours_fished <dbl>, target_species <chr>, catch_total <dbl>, #> #   catch_kept <dbl>, catch_released <dbl>, weight_total <dbl>, #> #   trip_complete <lgl>, effort_expansion <dbl> head(counts) #> # A tibble: 6 × 16 #>   count_id date       time                location mode  anglers_count #>   <chr>    <date>     <dttm>              <chr>    <chr>         <dbl> #> 1 C001     2024-01-01 2024-01-01 08:30:00 Lake_A   boat             10 #> 2 C002     2024-01-01 2024-01-01 09:15:00 Lake_A   bank              8 #> 3 C003     2024-01-01 2024-01-01 14:30:00 Lake_A   boat              6 #> 4 C004     2024-01-01 2024-01-01 15:20:00 Lake_A   bank              4 #> 5 C005     2024-01-02 2024-01-02 07:45:00 Lake_A   boat             12 #> 6 C006     2024-01-02 2024-01-02 09:30:00 Lake_A   boat              9 #> # ℹ 10 more variables: parties_count <dbl>, weather_code <chr>, #> #   temperature <dbl>, wind_speed <dbl>, visibility <chr>, #> #   count_duration <dbl>, count_category <chr>, count_value <dbl>, #> #   shift_block <chr>, day_type <chr> head(calendar) #> # A tibble: 6 × 11 #>   date       stratum_id        day_type season month weekend holiday shift_block #>   <date>     <chr>             <chr>    <chr>  <chr> <lgl>   <lgl>   <chr>       #> 1 2024-01-01 2024-01-01-weekd… weekday  winter Janu… FALSE   FALSE   morning     #> 2 2024-01-01 2024-01-01-weekd… weekday  winter Janu… FALSE   FALSE   morning     #> 3 2024-01-01 2024-01-01-weekd… weekday  winter Janu… FALSE   FALSE   afternoon   #> 4 2024-01-01 2024-01-01-weekd… weekday  winter Janu… FALSE   FALSE   afternoon   #> 5 2024-01-01 2024-01-01-weekd… weekday  winter Janu… FALSE   FALSE   evening     #> 6 2024-01-01 2024-01-01-weekd… weekday  winter Janu… FALSE   FALSE   evening     #> # ℹ 3 more variables: location <chr>, target_sample <dbl>, actual_sample <dbl>"},{"path":"/articles/getting-started.html","id":"creating-survey-designs","dir":"Articles","previous_headings":"","what":"Creating Survey Designs","title":"Getting Started with tidycreel","text":"survey-first approach uses survey package directly. create day-level survey design sampling calendar using as_day_svydesign().","code":"# Create day-level survey design from calendar svy_day <- as_day_svydesign(   calendar,   day_id = \"date\",   strata_vars = c(\"day_type\", \"month\") )  # Examine the survey design class(svy_day) #> [1] \"survey.design2\" \"survey.design\" summary(stats::weights(svy_day)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.027   1.027   1.064   1.052   1.064   1.064"},{"path":"/articles/getting-started.html","id":"interview-level-survey-designs","dir":"Articles","previous_headings":"","what":"Interview-Level Survey Designs","title":"Getting Started with tidycreel","text":"CPUE catch estimation, can create interview-level survey designs directly survey package:","code":"# Simple survey design from interviews (no stratification) svy_interviews <- survey::svydesign(   ids = ~1,   weights = ~1,   data = interviews )  # Or with stratification if needed # svy_interviews_strat <- survey::svydesign( #   ids = ~1, #   strata = ~location, #   weights = ~1, #   data = interviews # )"},{"path":"/articles/getting-started.html","id":"replicate-variance-optional","dir":"Articles","previous_headings":"","what":"Replicate Variance (Optional)","title":"Getting Started with tidycreel","text":"can convert day-level designs replicate-weight designs robust standard errors:","code":"# Bootstrap replicate design with 50 reps (keep small in examples) svy_rep <- survey::as.svrepdesign(svy_day, type = \"bootstrap\", replicates = 50, mse = TRUE) class(svy_rep) #> [1] \"svyrep.design\""},{"path":"/articles/getting-started.html","id":"estimating-effort-survey-first","dir":"Articles","previous_headings":"","what":"Estimating Effort (Survey-First)","title":"Getting Started with tidycreel","text":"day-PSU design, estimate effort counts using survey-first estimators.","code":"# Example instantaneous counts (toy) counts_inst <- tibble::tibble(   date = as.Date(c(\"2024-01-01\",\"2024-01-01\",\"2024-01-02\",\"2024-01-02\")),   location = c(\"A\",\"B\",\"A\",\"B\"),   count = c(10,12,8,15),   interval_minutes = 60,   total_day_minutes = 600 )  est_effort(   design = svy_day,   counts = counts_inst,   method = \"instantaneous\",   by = c(\"location\") ) #> # A tibble: 2 × 8 #>   location estimate    se ci_low ci_high     n method        diagnostics #>   <chr>       <dbl> <dbl>  <dbl>   <dbl> <int> <chr>         <list>      #> 1 A            191.    NA     NA      NA    NA instantaneous <NULL>      #> 2 B            287.    NA     NA      NA    NA instantaneous <NULL>"},{"path":"/articles/getting-started.html","id":"estimating-cpue-and-catch-survey-first","dir":"Articles","previous_headings":"","what":"Estimating CPUE and Catch (Survey-First)","title":"Getting Started with tidycreel","text":"CPUE estimated design-based interview data. Prefer ratio--means form incomplete trips; use mean--ratios complete trips.","code":"# CPUE/Catch use interview-level survey designs # CPUE by species (ratio-of-means) suppressWarnings({   cpue_species <- est_cpue(svy_interviews, by = c(\"target_species\"), response = \"catch_total\") }) #> ✔ Auto mode: Detected 100% complete trips (n=26). #> ℹ Using mean-of-ratios estimator (appropriate for complete trips). cpue_species #> # A tibble: 4 × 8 #>   target_species estimate    se ci_low ci_high     n method          diagnostics #>   <chr>             <dbl> <dbl>  <dbl>   <dbl> <int> <chr>           <list>      #> 1 bass               1.16 0.110  0.941    1.37    10 cpue_mean_of_r… <NULL>      #> 2 catfish            1    0      1        1        4 cpue_mean_of_r… <NULL>      #> 3 panfish            1.83 0.425  1.00     2.67     4 cpue_mean_of_r… <NULL>      #> 4 walleye            1.77 0.202  1.38     2.17     8 cpue_mean_of_r… <NULL>  # CPUE (mean-of-ratios) — for complete trips suppressWarnings({   cpue_mor <- est_cpue(svy_interviews, by = c(\"target_species\"), response = \"catch_total\", mode = \"mean_of_ratios\") }) cpue_mor #> # A tibble: 4 × 8 #>   target_species estimate    se ci_low ci_high     n method          diagnostics #>   <chr>             <dbl> <dbl>  <dbl>   <dbl> <int> <chr>           <list>      #> 1 bass               1.16 0.110  0.941    1.37    10 cpue_mean_of_r… <NULL>      #> 2 catfish            1    0      1        1        4 cpue_mean_of_r… <NULL>      #> 3 panfish            1.83 0.425  1.00     2.67     4 cpue_mean_of_r… <NULL>      #> 4 walleye            1.77 0.202  1.38     2.17     8 cpue_mean_of_r… <NULL>  # Harvest totals by species suppressWarnings({   harvest_species <- est_catch(svy_interviews, by = c(\"target_species\"), response = \"catch_kept\") }) harvest_species #> # A tibble: 4 × 8 #>   target_species estimate    se ci_low ci_high     n method          diagnostics #>   <chr>             <dbl> <dbl>  <dbl>   <dbl> <int> <chr>           <list>      #> 1 bass                 22  6.4   9.46     34.5    10 catch_total:ca… <NULL>      #> 2 catfish               6  2.99  0.133    11.9     4 catch_total:ca… <NULL>      #> 3 panfish              10  5.6  -0.976    21.0     4 catch_total:ca… <NULL>      #> 4 walleye              44 14.2  16.2      71.8     8 catch_total:ca… <NULL>"},{"path":[]},{"path":"/articles/getting-started.html","id":"custom-stratification","dir":"Articles","previous_headings":"Advanced Usage","what":"Custom Stratification","title":"Getting Started with tidycreel","text":"can specify custom stratification variables creating survey designs:","code":"## Diagnostics: check structure before design creation str(calendar) #> spc_tbl_ [18 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame) #>  $ date         : Date[1:18], format: \"2024-01-01\" \"2024-01-01\" ... #>  $ stratum_id   : chr [1:18] \"2024-01-01-weekday-morning\" \"2024-01-01-weekday-morning\" \"2024-01-01-weekday-afternoon\" \"2024-01-01-weekday-afternoon\" ... #>  $ day_type     : chr [1:18] \"weekday\" \"weekday\" \"weekday\" \"weekday\" ... #>  $ season       : chr [1:18] \"winter\" \"winter\" \"winter\" \"winter\" ... #>  $ month        : chr [1:18] \"January\" \"January\" \"January\" \"January\" ... #>  $ weekend      : logi [1:18] FALSE FALSE FALSE FALSE FALSE FALSE ... #>  $ holiday      : logi [1:18] FALSE FALSE FALSE FALSE FALSE FALSE ... #>  $ shift_block  : chr [1:18] \"morning\" \"morning\" \"afternoon\" \"afternoon\" ... #>  $ location     : chr [1:18] \"Lake_A\" \"Lake_B\" \"Lake_A\" \"Lake_B\" ... #>  $ target_sample: num [1:18] 10 10 10 10 5 5 10 10 10 10 ... #>  $ actual_sample: num [1:18] 8 8 12 12 3 3 10 10 9 9 ... #>  - attr(*, \"spec\")= #>   .. cols( #>   ..   date = col_date(format = \"\"), #>   ..   stratum_id = col_character(), #>   ..   day_type = col_character(), #>   ..   season = col_character(), #>   ..   month = col_character(), #>   ..   weekend = col_logical(), #>   ..   holiday = col_logical(), #>   ..   shift_block = col_character(), #>   ..   location = col_character(), #>   ..   target_sample = col_double(), #>   ..   actual_sample = col_double() #>   .. ) #>  - attr(*, \"problems\")=<externalptr> str(interviews) #> spc_tbl_ [26 × 17] (S3: spec_tbl_df/tbl_df/tbl/data.frame) #>  $ interview_id    : chr [1:26] \"INT001\" \"INT001B\" \"INT002\" \"INT002B\" ... #>  $ date            : Date[1:26], format: \"2024-01-01\" \"2024-01-01\" ... #>  $ time_start      : POSIXct[1:26], format: \"2024-01-01 08:30:00\" \"2024-01-01 08:30:00\" ... #>  $ time_end        : POSIXct[1:26], format: \"2024-01-01 08:45:00\" \"2024-01-01 08:45:00\" ... #>  $ location        : chr [1:26] \"Lake_A\" \"Lake_B\" \"Lake_A\" \"Lake_B\" ... #>  $ mode            : chr [1:26] \"boat\" \"boat\" \"bank\" \"bank\" ... #>  $ shift_block     : chr [1:26] \"morning\" \"morning\" \"morning\" \"morning\" ... #>  $ day_type        : chr [1:26] \"weekday\" \"weekday\" \"weekday\" \"weekday\" ... #>  $ party_size      : num [1:26] 2 2 1 1 3 3 2 2 1 1 ... #>  $ hours_fished    : num [1:26] 4.5 4.5 3 3 6 6 2.5 2.5 1.5 1.5 ... #>  $ target_species  : chr [1:26] \"walleye\" \"walleye\" \"bass\" \"bass\" ... #>  $ catch_total     : num [1:26] 5 5 2 2 8 8 3 3 4 4 ... #>  $ catch_kept      : num [1:26] 3 3 1 1 5 5 2 2 4 4 ... #>  $ catch_released  : num [1:26] 2 2 1 1 3 3 1 1 0 0 ... #>  $ weight_total    : num [1:26] 2.5 2.5 1.2 1.2 4.1 4.1 1.8 1.8 0.8 0.8 ... #>  $ trip_complete   : logi [1:26] TRUE TRUE TRUE TRUE TRUE TRUE ... #>  $ effort_expansion: num [1:26] 1 1 1 1 1 1 1 1 1 1 ... #>  - attr(*, \"spec\")= #>   .. cols( #>   ..   interview_id = col_character(), #>   ..   date = col_date(format = \"\"), #>   ..   time_start = col_datetime(format = \"\"), #>   ..   time_end = col_datetime(format = \"\"), #>   ..   location = col_character(), #>   ..   mode = col_character(), #>   ..   shift_block = col_character(), #>   ..   day_type = col_character(), #>   ..   party_size = col_double(), #>   ..   hours_fished = col_double(), #>   ..   target_species = col_character(), #>   ..   catch_total = col_double(), #>   ..   catch_kept = col_double(), #>   ..   catch_released = col_double(), #>   ..   weight_total = col_double(), #>   ..   trip_complete = col_logical(), #>   ..   effort_expansion = col_double() #>   .. ) #>  - attr(*, \"problems\")=<externalptr>  # Create day-level design with simpler stratification svy_day_simple <- as_day_svydesign(   calendar,   day_id = \"date\",   strata_vars = c(\"day_type\")  # Single stratification variable )  # Check stratification summary(svy_day_simple) #> Stratified 1 - level Cluster Sampling design (with replacement) #> With (3) clusters. #> survey::svydesign(ids = ids_formula, strata = strata_formula,  #>     weights = ~.w, data = cal, nest = TRUE, lonely.psu = \"adjust\") #> Probabilities: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.9400  0.9400  0.9400  0.9512  0.9737  0.9737  #> Stratum Sizes:  #>            weekday weekend #> obs             12       6 #> design.PSU       2       1 #> actual.PSU       2       1 #> Data variables: #>  [1] \"date\"          \"stratum_id\"    \"day_type\"      \"season\"        #>  [5] \"month\"         \"weekend\"       \"holiday\"       \"shift_block\"   #>  [9] \"location\"      \"target_sample\" \"actual_sample\" \".target\"       #> [13] \".actual\"       \".w\" table(calendar$day_type) #>  #> weekday weekend  #>      12       6"},{"path":"/articles/getting-started.html","id":"handling-missing-data","dir":"Articles","previous_headings":"Advanced Usage","what":"Handling Missing Data","title":"Getting Started with tidycreel","text":"validation functions catch missing required columns:","code":"# This will produce an error due to missing columns tryCatch({   bad_calendar <- calendar[, -1]  # Remove first column   as_day_svydesign(bad_calendar, day_id = \"date\", strata_vars = c(\"day_type\")) }, error = function(e) {   message(\"Validation error: \", e$message) }) #> Validation error: Missing required columns in as_day_svydesign."},{"path":"/articles/getting-started.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Getting Started with tidycreel","text":"Now survey designs survey package, can: Estimate effort counts using day-level designs (est_effort()) Estimate CPUE catch interviews using interview-level designs (est_cpue(), est_catch()) Use replicate designs robust variance estimation Perform hypothesis tests comparing different groups time periods Generate reports confidence intervals uncertainty bounds See package vignettes advanced features: - vignette(\"effort-survey-first\") detailed effort estimation - vignette(\"aerial\") aerial survey methods - vignette(\"cpue-catch\") CPUE catch estimation (coming soon)","code":""},{"path":"/articles/getting-started.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Getting Started with tidycreel","text":"Pollock, K. H., Jones, C. M., & Brown, T. L. (1994). Angler survey methods applications fisheries management. American Fisheries Society. Malvestuto, S. P. (1996). Sampling recreational creel. Murphy, B. R. & Willis, D. W. (Eds.), Fisheries techniques (2nd ed., pp. 591-623). American Fisheries Society.","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Ratio Estimators","text":"One common questions creel survey analysis : “use ratio--means mean--ratios estimate catch rate?” vignette answers question : Decision rules based survey design type Simulation demonstrations showing estimator performance Practical guidance variance estimation Clear examples using tidycreel","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"quick-answer-decision-tree","dir":"Articles","previous_headings":"","what":"Quick Answer: Decision Tree","title":"Ratio Estimators","text":"","code":"# Code code example ┌─────────────────────────────────────────────┐ │   What type of interviews do you have?      │ └─────────────────┬───────────────────────────┘                   │         ┌─────────┴───────────┐         │                     │     ┌───▼──────┐          ┌───▼────────┐     │ ACCESS   │          │ ROVING     │     │(Complete │          │(Incomplete │     │ trips)   │          │  trips)    │     └───┬──────┘          └───┬────────┘         │                     │         │                     │     ┌───▼─────────────────┐   │     │ Use RATIO-OF-MEANS  │   │     │  R₁ = Σcatch/Σeffort│   │     │                     │   │     │ Why? Each angler    │   │     │ has equal sampling  │   │     │ probability.        │   │     │                     │   │     │ ✓ Unbiased          │   │     │ ✓ Finite variance   │   │     └─────────────────────┘   │                               │                   ┌───────────▼────────────────┐                   │ Use MEAN-OF-RATIOS         │                   │  R₂ = (1/n)Σ(catch/effort) │                   │                            │                   │ IMPORTANT: Truncate short  │                   │ trips (< 20-30 minutes)    │                   │                            │                   │ Why? Sampling probability  │                   │ ∝ trip length. R₁ would    │                   │ give biased estimate.      │                   │                            │                   │ ⚠ Avoid if bag limits      │                   │   are low & easily obtained│                   └────────────────────────────┘"},{"path":"/articles/ratio-estimators-guide.html","id":"theoretical-background","dir":"Articles","previous_headings":"","what":"Theoretical Background","title":"Ratio Estimators","text":"diving simulations practical examples, let’s establish statistical foundation estimator choice matters. key understanding sampling probabilities differ survey designs. Sampling Design: complete - Interviews conducted anglers complete trips equal probability - anglers equal probability interviewed - P(interviewed) = constant, regardless trip length Appropriate Estimator: Ratio--Means (R₁) R̂1=∑j=1nCj*∑j=1nLj*\\hat{R}_1 = \\frac{\\sum_{j=1}^{n} C_j^*}{\\sum_{j=1}^{n} L_j^*} Cj*C_j^* = total catch completed trip Lj*L_j^* = total trip length completion. Expected Value: E(R̂1)≈Total CatchTotal EffortE(\\hat{R}_1) \\approx \\frac{\\text{Total Catch}}{\\text{Total Effort}} ✓ want total catch estimation! Sampling Design: - Interviews conducted fishing trips ∝ trip length - Sampling probability ∝ trip length - Longer trips likely encountered Appropriate Estimator: Mean--Ratios (R₂) Truncation R̂2=1n∑j=1nCjLj\\hat{R}_2 = \\frac{1}{n} \\sum_{j=1}^{n} \\frac{C_j}{L_j} CjC_j = catch time interview LjL_j = elapsed time interview. truncation: include interviews Lj>LminL_j > L_{min} (typically 20-30 minutes). Expected Value: E(R̂2)≈Total CatchTotal EffortE(\\hat{R}_2) \\approx \\frac{\\text{Total Catch}}{\\text{Total Effort}} ✓ Correct roving interviews! use R₁ roving? ratio--means roving interviews : E(R̂1roving)≈∑Lj*2⋅(Cj*/Lj*)∑Lj*2E(\\hat{R}_1^{roving}) \\approx \\frac{\\sum L_j^{*2} \\cdot (C_j^*/L_j^*)}{\\sum L_j^{*2}} weighted average weights = (trip length)², estimate population catch rate!","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"access-point-complete-trip-interviews","dir":"Articles","previous_headings":"","what":"Access Point (Complete Trip) Interviews","title":"Ratio Estimators","text":"Sampling Design: complete - Interviews conducted anglers complete trips equal probability - anglers equal probability interviewed - P(interviewed) = constant, regardless trip length Appropriate Estimator: Ratio--Means (R₁) R̂1=∑j=1nCj*∑j=1nLj*\\hat{R}_1 = \\frac{\\sum_{j=1}^{n} C_j^*}{\\sum_{j=1}^{n} L_j^*} Cj*C_j^* = total catch completed trip Lj*L_j^* = total trip length completion. Expected Value: E(R̂1)≈Total CatchTotal EffortE(\\hat{R}_1) \\approx \\frac{\\text{Total Catch}}{\\text{Total Effort}} ✓ want total catch estimation!","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"roving-incomplete-trip-interviews","dir":"Articles","previous_headings":"","what":"Roving (Incomplete Trip) Interviews","title":"Ratio Estimators","text":"Sampling Design: - Interviews conducted fishing trips ∝ trip length - Sampling probability ∝ trip length - Longer trips likely encountered Appropriate Estimator: Mean--Ratios (R₂) Truncation R̂2=1n∑j=1nCjLj\\hat{R}_2 = \\frac{1}{n} \\sum_{j=1}^{n} \\frac{C_j}{L_j} CjC_j = catch time interview LjL_j = elapsed time interview. truncation: include interviews Lj>LminL_j > L_{min} (typically 20-30 minutes). Expected Value: E(R̂2)≈Total CatchTotal EffortE(\\hat{R}_2) \\approx \\frac{\\text{Total Catch}}{\\text{Total Effort}} ✓ Correct roving interviews! use R₁ roving? ratio--means roving interviews : E(R̂1roving)≈∑Lj*2⋅(Cj*/Lj*)∑Lj*2E(\\hat{R}_1^{roving}) \\approx \\frac{\\sum L_j^{*2} \\cdot (C_j^*/L_j^*)}{\\sum L_j^{*2}} weighted average weights = (trip length)², estimate population catch rate!","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"handling-mixed-complete-and-incomplete-trips","dir":"Articles","previous_headings":"","what":"Handling Mixed Complete and Incomplete Trips","title":"Ratio Estimators","text":"matters. Real creel surveys often produce mix completed (access-point) incomplete (roving/intercept) interviews. Estimator choice must follow inclusion probability, just trip status, avoid bias. inclusion probability differs design (equal-probability access points vs. length-biased roving), pooling interviews applying single estimator can introduce bias. Treat designs according sampling properties. Treat complete incomplete interviews two strata, combine effort weighting: Complete trips (access point): use Ratio--Means (R₁ = ΣC / ΣE). Incomplete trips (roving): use Mean--Ratios (R₂ = (1/n) Σ(C/E)) truncation short trips (e.g., < 20–30 min). Effort-weighted combination: R̂combined=R1Ecomplete+R2EincompleteEcomplete+Eincomplete \\hat{R}_{\\text{combined}} = \\frac{R_1 E_{\\text{complete}} + R_2 E_{\\text{incomplete}}}{E_{\\text{complete}} + E_{\\text{incomplete}}} can estimate selection/inclusion probabilities (e.g., model trip completeness roving intercept likelihood), use weighted ratio: R̂weighted=∑iwiCi∑iwiEi,wi=1/P(selecti). \\hat{R}_{\\text{weighted}} = \\frac{\\sum_i w_i C_i}{\\sum_i w_i E_i}, \\quad w_i = 1 / P(\\text{select}_i). useful hybrid designs sampling varies predictably across modes, times, sites. Compute: () R₁ complete , (b) R₂ incomplete (truncation), (c) combined estimator. differences small (e.g., < 5–10%), pooling assumptions may reasonable; document . apply R₁ unfiltered roving data — biased high due length-biased sampling. apply R₂ complete trips — bias direction depends effort variability. Always truncate short incomplete trips stabilize R₂ reduce small-denominator issues. bag limits frequently hit, cautious R₂ (ceiling effects can distort ratios). Estimate SEs stratum appropriate formula (delta-method R₁; sample variance ratios R₂), combine via delta-method using effort-weight combination .","code":"# R code example complete <- data %>% dplyr::filter(trip_complete == TRUE) incomplete <- data %>% dplyr::filter(trip_complete == FALSE, trip_length >= 0.5)  # 0.5 h = 30 min  r1 <- sum(complete$catch) / sum(complete$effort) r2 <- mean(incomplete$catch / incomplete$effort)  E1 <- sum(complete$effort) E2 <- sum(incomplete$effort)  R_combined <- (r1 * E1 + r2 * E2) / (E1 + E2)"},{"path":"/articles/ratio-estimators-guide.html","id":"principle","dir":"Articles","previous_headings":"","what":"Principle","title":"Ratio Estimators","text":"inclusion probability differs design (equal-probability access points vs. length-biased roving), pooling interviews applying single estimator can introduce bias. Treat designs according sampling properties.","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"separate-estimation-recommended","dir":"Articles","previous_headings":"","what":"1️⃣ Separate Estimation (Recommended)","title":"Ratio Estimators","text":"Treat complete incomplete interviews two strata, combine effort weighting: Complete trips (access point): use Ratio--Means (R₁ = ΣC / ΣE). Incomplete trips (roving): use Mean--Ratios (R₂ = (1/n) Σ(C/E)) truncation short trips (e.g., < 20–30 min). Effort-weighted combination: R̂combined=R1Ecomplete+R2EincompleteEcomplete+Eincomplete \\hat{R}_{\\text{combined}} = \\frac{R_1 E_{\\text{complete}} + R_2 E_{\\text{incomplete}}}{E_{\\text{complete}} + E_{\\text{incomplete}}}","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"model-based-weighting-optional","dir":"Articles","previous_headings":"","what":"2️⃣ Model-Based Weighting (optional)","title":"Ratio Estimators","text":"can estimate selection/inclusion probabilities (e.g., model trip completeness roving intercept likelihood), use weighted ratio: R̂weighted=∑iwiCi∑iwiEi,wi=1/P(selecti). \\hat{R}_{\\text{weighted}} = \\frac{\\sum_i w_i C_i}{\\sum_i w_i E_i}, \\quad w_i = 1 / P(\\text{select}_i). useful hybrid designs sampling varies predictably across modes, times, sites.","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"sensitivity-analysis","dir":"Articles","previous_headings":"","what":"3️⃣ Sensitivity Analysis","title":"Ratio Estimators","text":"Compute: () R₁ complete , (b) R₂ incomplete (truncation), (c) combined estimator. differences small (e.g., < 5–10%), pooling assumptions may reasonable; document .","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"cautions","dir":"Articles","previous_headings":"","what":"Cautions","title":"Ratio Estimators","text":"apply R₁ unfiltered roving data — biased high due length-biased sampling. apply R₂ complete trips — bias direction depends effort variability. Always truncate short incomplete trips stabilize R₂ reduce small-denominator issues. bag limits frequently hit, cautious R₂ (ceiling effects can distort ratios).","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"implementation-sketch-r","dir":"Articles","previous_headings":"","what":"Implementation sketch (R)","title":"Ratio Estimators","text":"","code":"# R code example complete <- data %>% dplyr::filter(trip_complete == TRUE) incomplete <- data %>% dplyr::filter(trip_complete == FALSE, trip_length >= 0.5)  # 0.5 h = 30 min  r1 <- sum(complete$catch) / sum(complete$effort) r2 <- mean(incomplete$catch / incomplete$effort)  E1 <- sum(complete$effort) E2 <- sum(incomplete$effort)  R_combined <- (r1 * E1 + r2 * E2) / (E1 + E2)"},{"path":"/articles/ratio-estimators-guide.html","id":"variance-note","dir":"Articles","previous_headings":"","what":"Variance note","title":"Ratio Estimators","text":"Estimate SEs stratum appropriate formula (delta-method R₁; sample variance ratios R₂), combine via delta-method using effort-weight combination .","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"simulation-study","dir":"Articles","previous_headings":"","what":"Simulation Study","title":"Ratio Estimators","text":"theoretical results show estimator choice matters. large bias practice? truncation really help? Let’s demonstrate principles simulation, following approach Rasmussen et al. (1998) Pollock et al. (1997). ’ll simulate realistic fishing scenario compare estimator performance. Simulate traditional access point creel interview anglers finish. Now simulate roving interviews anglers intercepted trips. Run 1000 replications assess bias precision. Access Point Design: Estimator Performance estimator mean bias pct_bias se rmse r1 1.9953 -0.0069 -0.3452 0.4276 0.4274 r2 2.0081 0.0059 0.2955 0.4081 0.4079 Key Finding: access interviews, estimators approximately unbiased, ratio--means (R₁) typically slightly lower variance.  Access Point Design: Distribution Estimates. estimators center true value (dashed line), demonstrating unbiasedness. ratio--means (R₁) shows slightly tighter clustering, indicating lower variance. Roving Design: Estimator Performance estimator truncation mean bias pct_bias rmse Ratio Means truncation 1.9957 -0.0209 -1.0341 0.4985 Mean Ratios truncation 1.9909 -0.0256 -1.2698 0.4629 Ratio Means 30-min truncation 1.9966 -0.0199 -0.9880 0.5041 Mean Ratios 30-min truncation 2.0092 -0.0073 -0.3629 0.4400 Key Findings: R₁ (ratio--means) BIASED roving interviews 1. R₁ (ratio--means) BIASED roving interviews - estimate population catch rate R₂ (mean--ratios) without truncation approximately unbiased high variance 2. R₂ (mean--ratios) without truncation approximately unbiased high variance (unstable) R₂ truncation approximately unbiased lower variance RECOMMENDED 3. R₂ truncation approximately unbiased lower variance ✓ RECOMMENDED  Roving Design: Effect Truncation. R₁ (ratio--means) biased roving surveys regardless truncation. R₂ (mean--ratios) unbiased high variance without truncation; truncation reduces variance maintaining unbiasedness.","code":"# R code example #' Simulate a day of fishing with known parameters #' #' @param n_anglers Number of anglers fishing during the day #' @param mean_trip_hours Mean trip length (hours) #' @param mean_catch_rate Mean catch per hour (Poisson rate parameter) #' @param day_length_hours Length of fishing day #' @return List with population parameters and individual angler data simulate_fishing_day <- function(n_anglers = 100,                                  mean_trip_hours = 4,                                  mean_catch_rate = 2,                                  day_length_hours = 12) {    # Each angler's true catch rate (gamma-distributed for heterogeneity)   # Shape = 1, rate = 1/mean gives exponential with specified mean   # This creates variation in angler skill/success   alpha <- 1   beta <- 1 / mean_catch_rate   catch_rates <- rgamma(n_anglers, shape = alpha, rate = beta)    # Trip lengths (gamma-distributed)   shape_trip <- 4  # Controls variability   rate_trip <- shape_trip / mean_trip_hours   trip_lengths <- rgamma(n_anglers, shape = shape_trip, rate = rate_trip)   trip_lengths <- pmin(trip_lengths, day_length_hours)  # Can't exceed day length    # Generate catches for each angler (Poisson process)   # Expected catch = catch_rate * trip_length   completed_catch <- rpois(n_anglers, lambda = catch_rates * trip_lengths)    # True population parameters   total_effort <- sum(trip_lengths)   total_catch <- sum(completed_catch)   true_catch_rate <- total_catch / total_effort    # Return angler-level data   tibble(     angler_id = 1:n_anglers,     catch_rate_true = catch_rates,     trip_length = trip_lengths,     completed_catch = completed_catch,     true_population_rate = true_catch_rate,     total_effort = total_effort,     total_catch = total_catch   ) }  # Example fishing_day <- simulate_fishing_day(n_anglers = 100) head(fishing_day) # Code code example # A tibble: 6 × 7   angler_id catch_rate_true trip_length completed_catch true_population_rate       <int>           <dbl>       <dbl>           <int>                <dbl> 1         1           2.00         4.78               7                 2.15 2         2           2.26         1.56               5                 2.15 3         3           0.851        4.74               4                 2.15 4         4           1.03         6.06               5                 2.15 5         5           6.96         4.52              35                 2.15 6         6           0.627        5.59               3                 2.15 # ℹ 2 more variables: total_effort <dbl>, total_catch <int> # R code example # Summary of true population parameters cat(\"True Population Parameters:\\n\") # Code code example True Population Parameters: # R code example cat(\"  Total anglers:\", nrow(fishing_day), \"\\n\") # Code code example   Total anglers: 100 # R code example cat(\"  Total effort:\", round(fishing_day$total_effort[1], 1), \"hours\\n\") # Code code example   Total effort: 391.8 hours # R code example cat(\"  Total catch:\", fishing_day$total_catch[1], \"fish\\n\") # Code code example   Total catch: 844 fish # R code example cat(\"  True catch rate:\", round(fishing_day$true_population_rate[1], 3), \"fish/hour\\n\") # Code code example   True catch rate: 2.154 fish/hour # R code example #' Simulate access point interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Number of interviews to conduct #' @return Tibble with interview data sample_access_interviews <- function(fishing_day, n_interviews = 30) {   # Simple random sample (equal probability)   sampled <- fishing_day %>%     sample_n(size = min(n_interviews, nrow(fishing_day)), replace = FALSE) %>%     select(angler_id, completed_catch, trip_length, true_population_rate)    sampled }  # Single realization access_sample <- sample_access_interviews(fishing_day, n_interviews = 30) head(access_sample) # Code code example # A tibble: 6 × 4   angler_id completed_catch trip_length true_population_rate       <int>           <int>       <dbl>                <dbl> 1         1               7        4.78                 2.15 2        69               4        5.05                 2.15 3        79              14        6.27                 2.15 4        19               5        6.75                 2.15 5        12               1        4.72                 2.15 6        64               0        5.88                 2.15 # R code example # Calculate both estimators calculate_estimates <- function(interviews, truncate_minutes = NULL) {    # Apply truncation if specified (for roving surveys)   if (!is.null(truncate_minutes)) {     interviews <- interviews %>%       filter(trip_length >= truncate_minutes / 60)   }    n <- nrow(interviews)    # Ratio-of-means   r1 <- sum(interviews$completed_catch) / sum(interviews$trip_length)    # Mean-of-ratios   r2 <- mean(interviews$completed_catch / interviews$trip_length)    # Variance estimates (simplified)   # For R₁: use delta method (Taylor series approximation)   # Var(R₁) ≈ (1/n·E̅²) · Var(C - R₁·E)   # where residual = catch - estimated_rate × effort   r <- interviews$completed_catch   e <- interviews$trip_length   r_bar <- mean(r)   e_bar <- mean(e)   var_r1 <- (1 / (n * e_bar^2)) * var(r - r1 * e)   se_r1 <- sqrt(var_r1)    # For R₂: simple variance of the ratios   ratios <- interviews$completed_catch / interviews$trip_length   var_r2 <- var(ratios) / n   se_r2 <- sqrt(var_r2)    tibble(     n = n,     ratio_of_means = r1,     mean_of_ratios = r2,     se_r1 = se_r1,     se_r2 = se_r2,     true_rate = interviews$true_population_rate[1]   ) }  access_results <- calculate_estimates(access_sample) access_results # Code code example # A tibble: 1 × 6       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> 1    30           2.04           2.41 0.401 0.463      2.15 # R code example #' Simulate roving interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Target number of interviews #' @return Tibble with incomplete trip interview data sample_roving_interviews <- function(fishing_day, n_interviews = 30) {    # Length-biased sampling: probability of encounter ∝ trip duration   # P(interview angler i) = L_i / Σ L_j (normalized by total effort)   # Longer trips have higher chance of being encountered during roving   prob_intercept <- fishing_day$trip_length / sum(fishing_day$trip_length)    # Sample with probability proportional to size   sampled_indices <- sample(     1:nrow(fishing_day),     size = min(n_interviews, nrow(fishing_day)),     replace = FALSE,     prob = prob_intercept   )    sampled <- fishing_day[sampled_indices, ]    # For each intercepted angler, determine interview time   # Uniform on [0, trip_length] (on average, intercepted at midpoint)   sampled <- sampled %>%     mutate(       # Time fished when interviewed (uniform on [0, trip_length])       # On average, anglers are intercepted at midpoint of their trip       time_at_interview = runif(n(), min = 0, max = trip_length),        # Catch at interview time (incomplete trip)       # Poisson process: E[catch | time_t] = λ × t       # where λ = angler's true catch rate, t = time fished so far       catch_at_interview = rpois(n(), lambda = catch_rate_true * time_at_interview)     ) %>%     select(angler_id, catch_at_interview, time_at_interview,            completed_catch, trip_length, true_population_rate)    sampled }  roving_sample <- sample_roving_interviews(fishing_day, n_interviews = 30) head(roving_sample) # Code code example # A tibble: 6 × 6   angler_id catch_at_interview time_at_interview completed_catch trip_length       <int>              <int>             <dbl>           <int>       <dbl> 1        27                  1             2.57                2        5.27 2        37                  4             1.46               13        2.99 3        81                  0             0.326               3        3.86 4        32                  1             2.30                8        5.76 5        97                  6             3.54               10        4.81 6        28                  4             2.58                5        2.72 # ℹ 1 more variable: true_population_rate <dbl> # R code example # For roving, use incomplete data # Note: calculate_estimates() expects columns named 'completed_catch' and 'trip_length' roving_data <- roving_sample %>%   select(angler_id,          completed_catch = catch_at_interview,          trip_length = time_at_interview,          true_population_rate)  # No truncation roving_no_trunc <- calculate_estimates(roving_data, truncate_minutes = NULL)  # With truncation (30 minutes) roving_with_trunc <- calculate_estimates(roving_data, truncate_minutes = 30)  bind_rows(   roving_no_trunc %>% mutate(truncation = \"None\"),   roving_with_trunc %>% mutate(truncation = \"30 min\") ) # Code code example # A tibble: 2 × 7       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate truncation   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> <chr> 1    30           1.98           1.77 0.329 0.289      2.15 None 2    27           1.97           1.67 0.334 0.281      2.15 30 min # R code example run_simulation <- function(n_reps = 1000,                            n_anglers = 100,                            n_interviews = 30,                            interview_type = c(\"access\", \"roving\")) {    interview_type <- match.arg(interview_type)    results <- map_dfr(1:n_reps, function(rep) {     # Generate population     day <- simulate_fishing_day(n_anglers = n_anglers)     true_rate <- day$true_population_rate[1]      # Sample based on design     if (interview_type == \"access\") {       sample_data <- sample_access_interviews(day, n_interviews)       sample_data <- sample_data %>%         rename(catch = completed_catch, effort = trip_length)     } else {       sample_data <- sample_roving_interviews(day, n_interviews) %>%         rename(catch = catch_at_interview, effort = time_at_interview)     }      # Calculate estimators     # No truncation     r1_no <- sum(sample_data$catch) / sum(sample_data$effort)     r2_no <- mean(sample_data$catch / sample_data$effort)      # With truncation (30 min = 0.5 hr)     trunc_data <- sample_data %>% filter(effort >= 0.5)     if (nrow(trunc_data) > 0) {       r1_trunc <- sum(trunc_data$catch) / sum(trunc_data$effort)       r2_trunc <- mean(trunc_data$catch / trunc_data$effort)     } else {       r1_trunc <- NA       r2_trunc <- NA     }      tibble(       rep = rep,       true_rate = true_rate,       r1_no_trunc = r1_no,       r2_no_trunc = r2_no,       r1_with_trunc = r1_trunc,       r2_with_trunc = r2_trunc,       n_interviews = n_interviews,       n_after_trunc = nrow(trunc_data)     )   })    results %>%     mutate(design = interview_type) }  # Run simulations access_mc <- run_simulation(n_reps = 1000, interview_type = \"access\") roving_mc <- run_simulation(n_reps = 1000, interview_type = \"roving\") # R code example # Summary statistics access_summary <- access_mc %>%   summarise(     true_rate = mean(true_rate),      # Ratio of means (R₁)     r1_mean = mean(r1_no_trunc),     r1_bias = mean(r1_no_trunc - true_rate),     r1_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate),     r1_rmse = sqrt(mean((r1_no_trunc - true_rate)^2)),     r1_se = sd(r1_no_trunc),      # Mean of ratios (R₂)     r2_mean = mean(r2_no_trunc),     r2_bias = mean(r2_no_trunc - true_rate),     r2_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate),     r2_rmse = sqrt(mean((r2_no_trunc - true_rate)^2)),     r2_se = sd(r2_no_trunc)   )  access_summary %>%   pivot_longer(cols = -true_rate, names_to = c(\"estimator\", \"metric\"), names_sep = \"_\", values_to = \"value\", names_repair = \"minimal\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   select(estimator, mean, bias, pct, se, rmse) %>%   rename(pct_bias = pct) %>%   knitr::kable(digits = 4, caption = \"Access Point Design: Estimator Performance\") # R code example access_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc) %>%   pivot_longer(cols = c(r1_no_trunc, r2_no_trunc),                names_to = \"estimator\",                values_to = \"estimate\") %>%   mutate(     estimator = recode(estimator,       r1_no_trunc = \"Ratio of Means (R1)\",       r2_no_trunc = \"Mean of Ratios (R2)\"     ),     # NEW: HTML subscripts for facet strips     estimator_lab = recode(estimator,       \"Ratio of Means (R1)\" = \"R<sub>1<\/sub> (Ratio of Means)\",       \"Mean of Ratios (R2)\" = \"R<sub>2<\/sub> (Mean of Ratios)\"     )   ) %>%   ggplot(aes(x = estimate, fill = estimator)) +   geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +   geom_vline(aes(xintercept = mean(true_rate)), linetype = \"dashed\", size = 1) +   facet_wrap(~ estimator_lab, ncol = 1) +   labs(     title = \"Access Point Design: Sampling Distribution\",     subtitle = \"Dashed line = true population catch rate\",     x = \"Estimated Catch Rate (fish/hour)\",     y = \"Frequency\"   ) +   theme_minimal() +   theme(     legend.position = \"none\",     # NEW: render HTML in strip labels     strip.text = ggtext::element_markdown()   ) # R code example # Summary statistics roving_summary <- roving_mc %>%   summarise(     true_rate = mean(true_rate),      # R1 no truncation     r1_no_mean = mean(r1_no_trunc, na.rm = TRUE),     r1_no_bias = mean(r1_no_trunc - true_rate, na.rm = TRUE),     r1_no_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_no_rmse = sqrt(mean((r1_no_trunc - true_rate)^2, na.rm = TRUE)),      # R2 no truncation     r2_no_mean = mean(r2_no_trunc, na.rm = TRUE),     r2_no_bias = mean(r2_no_trunc - true_rate, na.rm = TRUE),     r2_no_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_no_rmse = sqrt(mean((r2_no_trunc - true_rate)^2, na.rm = TRUE)),      # R1 with truncation     r1_trunc_mean = mean(r1_with_trunc, na.rm = TRUE),     r1_trunc_bias = mean(r1_with_trunc - true_rate, na.rm = TRUE),     r1_trunc_pct_bias = 100 * mean((r1_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_trunc_rmse = sqrt(mean((r1_with_trunc - true_rate)^2, na.rm = TRUE)),      # R2 with truncation     r2_trunc_mean = mean(r2_with_trunc, na.rm = TRUE),     r2_trunc_bias = mean(r2_with_trunc - true_rate, na.rm = TRUE),     r2_trunc_pct_bias = 100 * mean((r2_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_trunc_rmse = sqrt(mean((r2_with_trunc - true_rate)^2, na.rm = TRUE))   )  roving_summary %>%   pivot_longer(cols = -true_rate,                names_to = c(\"estimator\", \"truncation\", \"metric\"),                names_pattern = \"([^_]+)_([^_]+)_(.*)\",                values_to = \"value\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   mutate(estimator = recode(estimator, r1 = \"Ratio of Means\", r2 = \"Mean of Ratios\"),          truncation = recode(truncation, no = \"No truncation\", trunc = \"30-min truncation\")) %>%   select(estimator, truncation, mean, bias, pct_bias, rmse) %>%   knitr::kable(digits = 4, caption = \"Roving Design: Estimator Performance\") # R code example  labels <- c(   \"r1\" = \"italic(R)[1]~'(Ratio~of~Means)'\",   \"r2\" = \"italic(R)[2]~'(Mean~of~Ratios)'\" )   roving_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc, r1_with_trunc, r2_with_trunc) %>%   pivot_longer(cols = -c(rep, true_rate),                names_to = \"estimator\",                values_to = \"estimate\") %>%   filter(!is.na(estimate)) %>%   mutate(     Estimator_lab = dplyr::case_when(       Estimator %in% c(\"R1\",\"Ratio of Means\",\"Ratio-of-Means\",\"R_1\") ~         \"R<sub>1<\/sub> (Ratio of Means)\",       Estimator %in% c(\"R2\",\"Mean of Ratios\",\"Mean-of-Ratios\",\"R_2\") ~         \"R<sub>2<\/sub> (Mean of Ratios)\",       TRUE ~ Estimator     ),     Truncation_lab = dplyr::case_when(       Truncation %in% c(\"30-Min Truncation\",\"30 min\",\"30min\",\"30\") ~         \"30-Min Truncation\",       TRUE ~ \"No Truncation\"     )   ) %>%   ggplot(aes(x = estimate, fill = Estimator)) +   # ... geoms ...   facet_grid(Estimator_lab ~ Truncation_lab, switch = \"y\") +   theme_minimal() +   theme(     legend.position = \"none\",     strip.text.x = ggtext::element_markdown(),     strip.text.y = ggtext::element_markdown()   )"},{"path":"/articles/ratio-estimators-guide.html","id":"simulation-setup","dir":"Articles","previous_headings":"","what":"Simulation Setup","title":"Ratio Estimators","text":"’ll simulate realistic fishing scenario compare estimator performance.","code":"# R code example #' Simulate a day of fishing with known parameters #' #' @param n_anglers Number of anglers fishing during the day #' @param mean_trip_hours Mean trip length (hours) #' @param mean_catch_rate Mean catch per hour (Poisson rate parameter) #' @param day_length_hours Length of fishing day #' @return List with population parameters and individual angler data simulate_fishing_day <- function(n_anglers = 100,                                  mean_trip_hours = 4,                                  mean_catch_rate = 2,                                  day_length_hours = 12) {    # Each angler's true catch rate (gamma-distributed for heterogeneity)   # Shape = 1, rate = 1/mean gives exponential with specified mean   # This creates variation in angler skill/success   alpha <- 1   beta <- 1 / mean_catch_rate   catch_rates <- rgamma(n_anglers, shape = alpha, rate = beta)    # Trip lengths (gamma-distributed)   shape_trip <- 4  # Controls variability   rate_trip <- shape_trip / mean_trip_hours   trip_lengths <- rgamma(n_anglers, shape = shape_trip, rate = rate_trip)   trip_lengths <- pmin(trip_lengths, day_length_hours)  # Can't exceed day length    # Generate catches for each angler (Poisson process)   # Expected catch = catch_rate * trip_length   completed_catch <- rpois(n_anglers, lambda = catch_rates * trip_lengths)    # True population parameters   total_effort <- sum(trip_lengths)   total_catch <- sum(completed_catch)   true_catch_rate <- total_catch / total_effort    # Return angler-level data   tibble(     angler_id = 1:n_anglers,     catch_rate_true = catch_rates,     trip_length = trip_lengths,     completed_catch = completed_catch,     true_population_rate = true_catch_rate,     total_effort = total_effort,     total_catch = total_catch   ) }  # Example fishing_day <- simulate_fishing_day(n_anglers = 100) head(fishing_day) # Code code example # A tibble: 6 × 7   angler_id catch_rate_true trip_length completed_catch true_population_rate       <int>           <dbl>       <dbl>           <int>                <dbl> 1         1           2.00         4.78               7                 2.15 2         2           2.26         1.56               5                 2.15 3         3           0.851        4.74               4                 2.15 4         4           1.03         6.06               5                 2.15 5         5           6.96         4.52              35                 2.15 6         6           0.627        5.59               3                 2.15 # ℹ 2 more variables: total_effort <dbl>, total_catch <int> # R code example # Summary of true population parameters cat(\"True Population Parameters:\\n\") # Code code example True Population Parameters: # R code example cat(\"  Total anglers:\", nrow(fishing_day), \"\\n\") # Code code example   Total anglers: 100 # R code example cat(\"  Total effort:\", round(fishing_day$total_effort[1], 1), \"hours\\n\") # Code code example   Total effort: 391.8 hours # R code example cat(\"  Total catch:\", fishing_day$total_catch[1], \"fish\\n\") # Code code example   Total catch: 844 fish # R code example cat(\"  True catch rate:\", round(fishing_day$true_population_rate[1], 3), \"fish/hour\\n\") # Code code example   True catch rate: 2.154 fish/hour"},{"path":"/articles/ratio-estimators-guide.html","id":"scenario-1-access-point-interviews-complete-trips","dir":"Articles","previous_headings":"","what":"Scenario 1: Access Point Interviews (Complete Trips)","title":"Ratio Estimators","text":"Simulate traditional access point creel interview anglers finish.","code":"# R code example #' Simulate access point interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Number of interviews to conduct #' @return Tibble with interview data sample_access_interviews <- function(fishing_day, n_interviews = 30) {   # Simple random sample (equal probability)   sampled <- fishing_day %>%     sample_n(size = min(n_interviews, nrow(fishing_day)), replace = FALSE) %>%     select(angler_id, completed_catch, trip_length, true_population_rate)    sampled }  # Single realization access_sample <- sample_access_interviews(fishing_day, n_interviews = 30) head(access_sample) # Code code example # A tibble: 6 × 4   angler_id completed_catch trip_length true_population_rate       <int>           <int>       <dbl>                <dbl> 1         1               7        4.78                 2.15 2        69               4        5.05                 2.15 3        79              14        6.27                 2.15 4        19               5        6.75                 2.15 5        12               1        4.72                 2.15 6        64               0        5.88                 2.15 # R code example # Calculate both estimators calculate_estimates <- function(interviews, truncate_minutes = NULL) {    # Apply truncation if specified (for roving surveys)   if (!is.null(truncate_minutes)) {     interviews <- interviews %>%       filter(trip_length >= truncate_minutes / 60)   }    n <- nrow(interviews)    # Ratio-of-means   r1 <- sum(interviews$completed_catch) / sum(interviews$trip_length)    # Mean-of-ratios   r2 <- mean(interviews$completed_catch / interviews$trip_length)    # Variance estimates (simplified)   # For R₁: use delta method (Taylor series approximation)   # Var(R₁) ≈ (1/n·E̅²) · Var(C - R₁·E)   # where residual = catch - estimated_rate × effort   r <- interviews$completed_catch   e <- interviews$trip_length   r_bar <- mean(r)   e_bar <- mean(e)   var_r1 <- (1 / (n * e_bar^2)) * var(r - r1 * e)   se_r1 <- sqrt(var_r1)    # For R₂: simple variance of the ratios   ratios <- interviews$completed_catch / interviews$trip_length   var_r2 <- var(ratios) / n   se_r2 <- sqrt(var_r2)    tibble(     n = n,     ratio_of_means = r1,     mean_of_ratios = r2,     se_r1 = se_r1,     se_r2 = se_r2,     true_rate = interviews$true_population_rate[1]   ) }  access_results <- calculate_estimates(access_sample) access_results # Code code example # A tibble: 1 × 6       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> 1    30           2.04           2.41 0.401 0.463      2.15"},{"path":"/articles/ratio-estimators-guide.html","id":"scenario-2-roving-interviews-incomplete-trips","dir":"Articles","previous_headings":"","what":"Scenario 2: Roving Interviews (Incomplete Trips)","title":"Ratio Estimators","text":"Now simulate roving interviews anglers intercepted trips.","code":"# R code example #' Simulate roving interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Target number of interviews #' @return Tibble with incomplete trip interview data sample_roving_interviews <- function(fishing_day, n_interviews = 30) {    # Length-biased sampling: probability of encounter ∝ trip duration   # P(interview angler i) = L_i / Σ L_j (normalized by total effort)   # Longer trips have higher chance of being encountered during roving   prob_intercept <- fishing_day$trip_length / sum(fishing_day$trip_length)    # Sample with probability proportional to size   sampled_indices <- sample(     1:nrow(fishing_day),     size = min(n_interviews, nrow(fishing_day)),     replace = FALSE,     prob = prob_intercept   )    sampled <- fishing_day[sampled_indices, ]    # For each intercepted angler, determine interview time   # Uniform on [0, trip_length] (on average, intercepted at midpoint)   sampled <- sampled %>%     mutate(       # Time fished when interviewed (uniform on [0, trip_length])       # On average, anglers are intercepted at midpoint of their trip       time_at_interview = runif(n(), min = 0, max = trip_length),        # Catch at interview time (incomplete trip)       # Poisson process: E[catch | time_t] = λ × t       # where λ = angler's true catch rate, t = time fished so far       catch_at_interview = rpois(n(), lambda = catch_rate_true * time_at_interview)     ) %>%     select(angler_id, catch_at_interview, time_at_interview,            completed_catch, trip_length, true_population_rate)    sampled }  roving_sample <- sample_roving_interviews(fishing_day, n_interviews = 30) head(roving_sample) # Code code example # A tibble: 6 × 6   angler_id catch_at_interview time_at_interview completed_catch trip_length       <int>              <int>             <dbl>           <int>       <dbl> 1        27                  1             2.57                2        5.27 2        37                  4             1.46               13        2.99 3        81                  0             0.326               3        3.86 4        32                  1             2.30                8        5.76 5        97                  6             3.54               10        4.81 6        28                  4             2.58                5        2.72 # ℹ 1 more variable: true_population_rate <dbl> # R code example # For roving, use incomplete data # Note: calculate_estimates() expects columns named 'completed_catch' and 'trip_length' roving_data <- roving_sample %>%   select(angler_id,          completed_catch = catch_at_interview,          trip_length = time_at_interview,          true_population_rate)  # No truncation roving_no_trunc <- calculate_estimates(roving_data, truncate_minutes = NULL)  # With truncation (30 minutes) roving_with_trunc <- calculate_estimates(roving_data, truncate_minutes = 30)  bind_rows(   roving_no_trunc %>% mutate(truncation = \"None\"),   roving_with_trunc %>% mutate(truncation = \"30 min\") ) # Code code example # A tibble: 2 × 7       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate truncation   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> <chr> 1    30           1.98           1.77 0.329 0.289      2.15 None 2    27           1.97           1.67 0.334 0.281      2.15 30 min"},{"path":"/articles/ratio-estimators-guide.html","id":"monte-carlo-simulation","dir":"Articles","previous_headings":"","what":"Monte Carlo Simulation","title":"Ratio Estimators","text":"Run 1000 replications assess bias precision.","code":"# R code example run_simulation <- function(n_reps = 1000,                            n_anglers = 100,                            n_interviews = 30,                            interview_type = c(\"access\", \"roving\")) {    interview_type <- match.arg(interview_type)    results <- map_dfr(1:n_reps, function(rep) {     # Generate population     day <- simulate_fishing_day(n_anglers = n_anglers)     true_rate <- day$true_population_rate[1]      # Sample based on design     if (interview_type == \"access\") {       sample_data <- sample_access_interviews(day, n_interviews)       sample_data <- sample_data %>%         rename(catch = completed_catch, effort = trip_length)     } else {       sample_data <- sample_roving_interviews(day, n_interviews) %>%         rename(catch = catch_at_interview, effort = time_at_interview)     }      # Calculate estimators     # No truncation     r1_no <- sum(sample_data$catch) / sum(sample_data$effort)     r2_no <- mean(sample_data$catch / sample_data$effort)      # With truncation (30 min = 0.5 hr)     trunc_data <- sample_data %>% filter(effort >= 0.5)     if (nrow(trunc_data) > 0) {       r1_trunc <- sum(trunc_data$catch) / sum(trunc_data$effort)       r2_trunc <- mean(trunc_data$catch / trunc_data$effort)     } else {       r1_trunc <- NA       r2_trunc <- NA     }      tibble(       rep = rep,       true_rate = true_rate,       r1_no_trunc = r1_no,       r2_no_trunc = r2_no,       r1_with_trunc = r1_trunc,       r2_with_trunc = r2_trunc,       n_interviews = n_interviews,       n_after_trunc = nrow(trunc_data)     )   })    results %>%     mutate(design = interview_type) }  # Run simulations access_mc <- run_simulation(n_reps = 1000, interview_type = \"access\") roving_mc <- run_simulation(n_reps = 1000, interview_type = \"roving\")"},{"path":"/articles/ratio-estimators-guide.html","id":"results-access-point-design","dir":"Articles","previous_headings":"","what":"Results: Access Point Design","title":"Ratio Estimators","text":"Access Point Design: Estimator Performance estimator mean bias pct_bias se rmse r1 1.9953 -0.0069 -0.3452 0.4276 0.4274 r2 2.0081 0.0059 0.2955 0.4081 0.4079 Key Finding: access interviews, estimators approximately unbiased, ratio--means (R₁) typically slightly lower variance.  Access Point Design: Distribution Estimates. estimators center true value (dashed line), demonstrating unbiasedness. ratio--means (R₁) shows slightly tighter clustering, indicating lower variance.","code":"# R code example # Summary statistics access_summary <- access_mc %>%   summarise(     true_rate = mean(true_rate),      # Ratio of means (R₁)     r1_mean = mean(r1_no_trunc),     r1_bias = mean(r1_no_trunc - true_rate),     r1_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate),     r1_rmse = sqrt(mean((r1_no_trunc - true_rate)^2)),     r1_se = sd(r1_no_trunc),      # Mean of ratios (R₂)     r2_mean = mean(r2_no_trunc),     r2_bias = mean(r2_no_trunc - true_rate),     r2_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate),     r2_rmse = sqrt(mean((r2_no_trunc - true_rate)^2)),     r2_se = sd(r2_no_trunc)   )  access_summary %>%   pivot_longer(cols = -true_rate, names_to = c(\"estimator\", \"metric\"), names_sep = \"_\", values_to = \"value\", names_repair = \"minimal\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   select(estimator, mean, bias, pct, se, rmse) %>%   rename(pct_bias = pct) %>%   knitr::kable(digits = 4, caption = \"Access Point Design: Estimator Performance\") # R code example access_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc) %>%   pivot_longer(cols = c(r1_no_trunc, r2_no_trunc),                names_to = \"estimator\",                values_to = \"estimate\") %>%   mutate(     estimator = recode(estimator,       r1_no_trunc = \"Ratio of Means (R1)\",       r2_no_trunc = \"Mean of Ratios (R2)\"     ),     # NEW: HTML subscripts for facet strips     estimator_lab = recode(estimator,       \"Ratio of Means (R1)\" = \"R<sub>1<\/sub> (Ratio of Means)\",       \"Mean of Ratios (R2)\" = \"R<sub>2<\/sub> (Mean of Ratios)\"     )   ) %>%   ggplot(aes(x = estimate, fill = estimator)) +   geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +   geom_vline(aes(xintercept = mean(true_rate)), linetype = \"dashed\", size = 1) +   facet_wrap(~ estimator_lab, ncol = 1) +   labs(     title = \"Access Point Design: Sampling Distribution\",     subtitle = \"Dashed line = true population catch rate\",     x = \"Estimated Catch Rate (fish/hour)\",     y = \"Frequency\"   ) +   theme_minimal() +   theme(     legend.position = \"none\",     # NEW: render HTML in strip labels     strip.text = ggtext::element_markdown()   )"},{"path":"/articles/ratio-estimators-guide.html","id":"results-roving-design","dir":"Articles","previous_headings":"","what":"Results: Roving Design","title":"Ratio Estimators","text":"Roving Design: Estimator Performance estimator truncation mean bias pct_bias rmse Ratio Means truncation 1.9957 -0.0209 -1.0341 0.4985 Mean Ratios truncation 1.9909 -0.0256 -1.2698 0.4629 Ratio Means 30-min truncation 1.9966 -0.0199 -0.9880 0.5041 Mean Ratios 30-min truncation 2.0092 -0.0073 -0.3629 0.4400 Key Findings: R₁ (ratio--means) BIASED roving interviews 1. R₁ (ratio--means) BIASED roving interviews - estimate population catch rate R₂ (mean--ratios) without truncation approximately unbiased high variance 2. R₂ (mean--ratios) without truncation approximately unbiased high variance (unstable) R₂ truncation approximately unbiased lower variance RECOMMENDED 3. R₂ truncation approximately unbiased lower variance ✓ RECOMMENDED  Roving Design: Effect Truncation. R₁ (ratio--means) biased roving surveys regardless truncation. R₂ (mean--ratios) unbiased high variance without truncation; truncation reduces variance maintaining unbiasedness.","code":"# R code example # Summary statistics roving_summary <- roving_mc %>%   summarise(     true_rate = mean(true_rate),      # R1 no truncation     r1_no_mean = mean(r1_no_trunc, na.rm = TRUE),     r1_no_bias = mean(r1_no_trunc - true_rate, na.rm = TRUE),     r1_no_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_no_rmse = sqrt(mean((r1_no_trunc - true_rate)^2, na.rm = TRUE)),      # R2 no truncation     r2_no_mean = mean(r2_no_trunc, na.rm = TRUE),     r2_no_bias = mean(r2_no_trunc - true_rate, na.rm = TRUE),     r2_no_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_no_rmse = sqrt(mean((r2_no_trunc - true_rate)^2, na.rm = TRUE)),      # R1 with truncation     r1_trunc_mean = mean(r1_with_trunc, na.rm = TRUE),     r1_trunc_bias = mean(r1_with_trunc - true_rate, na.rm = TRUE),     r1_trunc_pct_bias = 100 * mean((r1_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_trunc_rmse = sqrt(mean((r1_with_trunc - true_rate)^2, na.rm = TRUE)),      # R2 with truncation     r2_trunc_mean = mean(r2_with_trunc, na.rm = TRUE),     r2_trunc_bias = mean(r2_with_trunc - true_rate, na.rm = TRUE),     r2_trunc_pct_bias = 100 * mean((r2_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_trunc_rmse = sqrt(mean((r2_with_trunc - true_rate)^2, na.rm = TRUE))   )  roving_summary %>%   pivot_longer(cols = -true_rate,                names_to = c(\"estimator\", \"truncation\", \"metric\"),                names_pattern = \"([^_]+)_([^_]+)_(.*)\",                values_to = \"value\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   mutate(estimator = recode(estimator, r1 = \"Ratio of Means\", r2 = \"Mean of Ratios\"),          truncation = recode(truncation, no = \"No truncation\", trunc = \"30-min truncation\")) %>%   select(estimator, truncation, mean, bias, pct_bias, rmse) %>%   knitr::kable(digits = 4, caption = \"Roving Design: Estimator Performance\") # R code example  labels <- c(   \"r1\" = \"italic(R)[1]~'(Ratio~of~Means)'\",   \"r2\" = \"italic(R)[2]~'(Mean~of~Ratios)'\" )   roving_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc, r1_with_trunc, r2_with_trunc) %>%   pivot_longer(cols = -c(rep, true_rate),                names_to = \"estimator\",                values_to = \"estimate\") %>%   filter(!is.na(estimate)) %>%   mutate(     Estimator_lab = dplyr::case_when(       Estimator %in% c(\"R1\",\"Ratio of Means\",\"Ratio-of-Means\",\"R_1\") ~         \"R<sub>1<\/sub> (Ratio of Means)\",       Estimator %in% c(\"R2\",\"Mean of Ratios\",\"Mean-of-Ratios\",\"R_2\") ~         \"R<sub>2<\/sub> (Mean of Ratios)\",       TRUE ~ Estimator     ),     Truncation_lab = dplyr::case_when(       Truncation %in% c(\"30-Min Truncation\",\"30 min\",\"30min\",\"30\") ~         \"30-Min Truncation\",       TRUE ~ \"No Truncation\"     )   ) %>%   ggplot(aes(x = estimate, fill = Estimator)) +   # ... geoms ...   facet_grid(Estimator_lab ~ Truncation_lab, switch = \"y\") +   theme_minimal() +   theme(     legend.position = \"none\",     strip.text.x = ggtext::element_markdown(),     strip.text.y = ggtext::element_markdown()   )"},{"path":"/articles/ratio-estimators-guide.html","id":"practical-implementation-with-tidycreel","dir":"Articles","previous_headings":"","what":"Practical Implementation with tidycreel","title":"Ratio Estimators","text":"","code":"# R code example # Assuming you have complete-trip interview data interviews_complete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 8),   hours_fished = rgamma(100, shape = 4, rate = 1),   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # Create survey design svy_interviews <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_complete )  # Use RATIO-OF-MEANS (default and recommended) cpue_access <- est_cpue(   design = svy_interviews,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"ratio_of_means\"  # ✓ Correct for access interviews )  cpue_access # R code example # Assuming you have incomplete-trip interview data interviews_incomplete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 4),  # Catch so far   hours_fished = runif(100, min = 0.2, max = 6),  # Time so far   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # IMPORTANT: Truncate short trips before analysis interviews_truncated <- interviews_incomplete %>%   filter(hours_fished >= 0.5)  # Remove trips < 30 minutes  # Create survey design svy_roving <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_truncated )  # Use MEAN-OF-RATIOS for roving interviews cpue_roving <- est_cpue(   design = svy_roving,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"mean_of_ratios\"  # ✓ Correct for roving interviews )  cpue_roving"},{"path":"/articles/ratio-estimators-guide.html","id":"access-point-survey-example","dir":"Articles","previous_headings":"","what":"Access Point Survey Example","title":"Ratio Estimators","text":"","code":"# R code example # Assuming you have complete-trip interview data interviews_complete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 8),   hours_fished = rgamma(100, shape = 4, rate = 1),   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # Create survey design svy_interviews <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_complete )  # Use RATIO-OF-MEANS (default and recommended) cpue_access <- est_cpue(   design = svy_interviews,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"ratio_of_means\"  # ✓ Correct for access interviews )  cpue_access"},{"path":"/articles/ratio-estimators-guide.html","id":"roving-survey-example","dir":"Articles","previous_headings":"","what":"Roving Survey Example","title":"Ratio Estimators","text":"","code":"# R code example # Assuming you have incomplete-trip interview data interviews_incomplete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 4),  # Catch so far   hours_fished = runif(100, min = 0.2, max = 6),  # Time so far   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # IMPORTANT: Truncate short trips before analysis interviews_truncated <- interviews_incomplete %>%   filter(hours_fished >= 0.5)  # Remove trips < 30 minutes  # Create survey design svy_roving <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_truncated )  # Use MEAN-OF-RATIOS for roving interviews cpue_roving <- est_cpue(   design = svy_roving,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"mean_of_ratios\"  # ✓ Correct for roving interviews )  cpue_roving"},{"path":"/articles/ratio-estimators-guide.html","id":"variance-estimation","dir":"Articles","previous_headings":"","what":"Variance Estimation","title":"Ratio Estimators","text":"ratio--means survey weights, survey package automatically uses delta method: Note: variance formulas assume sampling infinite (large) population. sample size substantial relative total number anglers (n/N > 5%), may want apply finite population correction (FPC): multiply variance (1 - n/N). However, creel surveys population potential anglers large, correction negligible. Var(R̂1)≈1nE‾2Var(C−R̂1E)\\text{Var}(\\hat{R}_1) \\approx \\frac{1}{n\\bar{E}^2} \\text{Var}(C - \\hat{R}_1 E) CC = catch, EE = effort. mean--ratios, variance straightforward: Var(R̂2)=1nVar(CjEj)\\text{Var}(\\hat{R}_2) = \\frac{1}{n} \\text{Var}\\left(\\frac{C_j}{E_j}\\right)","code":"# R code example # survey::svyratio() provides proper variance cpue_result <- est_cpue(design = svy_interviews, mode = \"ratio_of_means\")  # Standard error is included cpue_result$se  # 95% confidence interval cpue_result$ci_low cpue_result$ci_high # R code example # survey::svymean() on the ratio variable cpue_roving <- est_cpue(design = svy_roving, mode = \"mean_of_ratios\")  # Standard error and CIs included cpue_roving$se cpue_roving$ci_low cpue_roving$ci_high"},{"path":"/articles/ratio-estimators-guide.html","id":"access-point-ratio-of-means","dir":"Articles","previous_headings":"","what":"Access Point (Ratio-of-Means)","title":"Ratio Estimators","text":"ratio--means survey weights, survey package automatically uses delta method: Note: variance formulas assume sampling infinite (large) population. sample size substantial relative total number anglers (n/N > 5%), may want apply finite population correction (FPC): multiply variance (1 - n/N). However, creel surveys population potential anglers large, correction negligible. Var(R̂1)≈1nE‾2Var(C−R̂1E)\\text{Var}(\\hat{R}_1) \\approx \\frac{1}{n\\bar{E}^2} \\text{Var}(C - \\hat{R}_1 E) CC = catch, EE = effort.","code":"# R code example # survey::svyratio() provides proper variance cpue_result <- est_cpue(design = svy_interviews, mode = \"ratio_of_means\")  # Standard error is included cpue_result$se  # 95% confidence interval cpue_result$ci_low cpue_result$ci_high"},{"path":"/articles/ratio-estimators-guide.html","id":"roving-mean-of-ratios-with-truncation","dir":"Articles","previous_headings":"","what":"Roving (Mean-of-Ratios with Truncation)","title":"Ratio Estimators","text":"mean--ratios, variance straightforward: Var(R̂2)=1nVar(CjEj)\\text{Var}(\\hat{R}_2) = \\frac{1}{n} \\text{Var}\\left(\\frac{C_j}{E_j}\\right)","code":"# R code example # survey::svymean() on the ratio variable cpue_roving <- est_cpue(design = svy_roving, mode = \"mean_of_ratios\")  # Standard error and CIs included cpue_roving$se cpue_roving$ci_low cpue_roving$ci_high"},{"path":"/articles/ratio-estimators-guide.html","id":"special-considerations","dir":"Articles","previous_headings":"","what":"Special Considerations","title":"Ratio Estimators","text":"⚠️ CRITICAL WARNING: Roving surveys can produce severe negative bias (underestimation 20-50%+) bag limits low (≤5 fish) anglers comply leaving immediately upon reaching limit. Problem: anglers leave immediately catching limit, roving clerk encounter unsuccessful anglers, leading severe underestimation. Example simulation (bag limit = 2 fish): Roving Bias Different Bag Limits bag_limit true_rate mean_estimate bias pct_bias 2 2.010 0.341 -1.668 -83.017 5 2.001 0.655 -1.346 -67.286 10 2.003 1.021 -0.982 -49.014 Recommendation: bag limits low (≤5 fish) compliance high, use access point interviews instead roving. catch rates change systematically trips (e.g., learning curve, time--day effects), roving interviews may biased. Check : Comparing incomplete-trip catch rates complete-trip catch rates Looking patterns catch rate vs. time--day nonstationary: Consider access point interviews model time-varying catch rate.","code":"# R code example simulate_with_bag_limit <- function(n_reps = 500, bag_limit = 2) {   map_dfr(1:n_reps, function(rep) {     # Simulate fishing day     day <- simulate_fishing_day(n_anglers = 100)     true_rate <- day$true_population_rate[1]      # Apply bag limit: anglers stop when limit reached     day_limited <- day %>%       mutate(         # Time to reach bag limit (exponential waiting time)         time_to_limit = ifelse(catch_rate_true > 0,                                bag_limit / catch_rate_true,                                Inf),         # Actual trip length (stop at limit or planned end, whichever comes first)         actual_trip_length = pmin(trip_length, time_to_limit),         # Actual catch (capped at bag limit)         actual_catch = pmin(completed_catch, bag_limit),         # Did angler reach bag limit before planned trip end?         reached_limit = (time_to_limit < trip_length)       )      # Roving interviews can only encounter anglers still on-site     # Those who reached bag limit before their planned trip end have already left     # Only those who haven't reached the limit OR reached it at/after planned end are available     still_fishing <- day_limited %>%       filter(!reached_limit)      if (nrow(still_fishing) > 10) {       # Sample from those still fishing       sample_data <- sample_roving_interviews(still_fishing, n_interviews = 30) %>%         rename(catch = catch_at_interview, effort = time_at_interview) %>%         filter(effort >= 0.5)        if (nrow(sample_data) > 0) {         r2 <- mean(sample_data$catch / sample_data$effort)         return(tibble(rep = rep, true_rate = true_rate, estimated_rate = r2,                      bag_limit = bag_limit))       }     }      tibble(rep = rep, true_rate = true_rate, estimated_rate = NA, bag_limit = bag_limit)   }) }  bag_limit_results <- bind_rows(   simulate_with_bag_limit(bag_limit = 2),   simulate_with_bag_limit(bag_limit = 5),   simulate_with_bag_limit(bag_limit = 10) )  bag_limit_summary <- bag_limit_results %>%   filter(!is.na(estimated_rate)) %>%   group_by(bag_limit) %>%   summarise(     true_rate = mean(true_rate),     mean_estimate = mean(estimated_rate),     bias = mean(estimated_rate - true_rate),     pct_bias = 100 * mean((estimated_rate - true_rate) / true_rate)   )  bag_limit_summary %>%   knitr::kable(digits = 3, caption = \"Roving Bias Under Different Bag Limits\")"},{"path":"/articles/ratio-estimators-guide.html","id":"bag-limits","dir":"Articles","previous_headings":"","what":"Bag Limits","title":"Ratio Estimators","text":"⚠️ CRITICAL WARNING: Roving surveys can produce severe negative bias (underestimation 20-50%+) bag limits low (≤5 fish) anglers comply leaving immediately upon reaching limit. Problem: anglers leave immediately catching limit, roving clerk encounter unsuccessful anglers, leading severe underestimation. Example simulation (bag limit = 2 fish): Roving Bias Different Bag Limits bag_limit true_rate mean_estimate bias pct_bias 2 2.010 0.341 -1.668 -83.017 5 2.001 0.655 -1.346 -67.286 10 2.003 1.021 -0.982 -49.014 Recommendation: bag limits low (≤5 fish) compliance high, use access point interviews instead roving.","code":"# R code example simulate_with_bag_limit <- function(n_reps = 500, bag_limit = 2) {   map_dfr(1:n_reps, function(rep) {     # Simulate fishing day     day <- simulate_fishing_day(n_anglers = 100)     true_rate <- day$true_population_rate[1]      # Apply bag limit: anglers stop when limit reached     day_limited <- day %>%       mutate(         # Time to reach bag limit (exponential waiting time)         time_to_limit = ifelse(catch_rate_true > 0,                                bag_limit / catch_rate_true,                                Inf),         # Actual trip length (stop at limit or planned end, whichever comes first)         actual_trip_length = pmin(trip_length, time_to_limit),         # Actual catch (capped at bag limit)         actual_catch = pmin(completed_catch, bag_limit),         # Did angler reach bag limit before planned trip end?         reached_limit = (time_to_limit < trip_length)       )      # Roving interviews can only encounter anglers still on-site     # Those who reached bag limit before their planned trip end have already left     # Only those who haven't reached the limit OR reached it at/after planned end are available     still_fishing <- day_limited %>%       filter(!reached_limit)      if (nrow(still_fishing) > 10) {       # Sample from those still fishing       sample_data <- sample_roving_interviews(still_fishing, n_interviews = 30) %>%         rename(catch = catch_at_interview, effort = time_at_interview) %>%         filter(effort >= 0.5)        if (nrow(sample_data) > 0) {         r2 <- mean(sample_data$catch / sample_data$effort)         return(tibble(rep = rep, true_rate = true_rate, estimated_rate = r2,                      bag_limit = bag_limit))       }     }      tibble(rep = rep, true_rate = true_rate, estimated_rate = NA, bag_limit = bag_limit)   }) }  bag_limit_results <- bind_rows(   simulate_with_bag_limit(bag_limit = 2),   simulate_with_bag_limit(bag_limit = 5),   simulate_with_bag_limit(bag_limit = 10) )  bag_limit_summary <- bag_limit_results %>%   filter(!is.na(estimated_rate)) %>%   group_by(bag_limit) %>%   summarise(     true_rate = mean(true_rate),     mean_estimate = mean(estimated_rate),     bias = mean(estimated_rate - true_rate),     pct_bias = 100 * mean((estimated_rate - true_rate) / true_rate)   )  bag_limit_summary %>%   knitr::kable(digits = 3, caption = \"Roving Bias Under Different Bag Limits\")"},{"path":"/articles/ratio-estimators-guide.html","id":"nonstationary-catch-rates","dir":"Articles","previous_headings":"","what":"Nonstationary Catch Rates","title":"Ratio Estimators","text":"catch rates change systematically trips (e.g., learning curve, time--day effects), roving interviews may biased. Check : Comparing incomplete-trip catch rates complete-trip catch rates Looking patterns catch rate vs. time--day nonstationary: Consider access point interviews model time-varying catch rate.","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"summary-practical-guidelines","dir":"Articles","previous_headings":"","what":"Summary: Practical Guidelines","title":"Ratio Estimators","text":"Survey Type Interview Type Recommended Estimator Function Call Access point Complete trips Ratio--means (R₁) est_cpue(…, mode = “ratio_of_means”) Roving Incomplete trips Mean--ratios (R₂) truncation est_cpue(…, mode = “mean_of_ratios”) + filter short trips Complemented (aerial-access) Complete trips Ratio--means (R₁) est_cpue(…, mode = “ratio_of_means”) Complemented (aerial-roving) Incomplete trips Mean--ratios (R₂) truncation est_cpue(…, mode = “mean_of_ratios”) + filter surveys: Check missing data catch effort - Check missing data catch effort Verify effort > 0 interviews - Verify effort > 0 interviews Check outliers (data entry errors) - Check outliers (data entry errors) ROVING surveys specifically: Truncate short trips (< 20-30 minutes) - Truncate short trips (< 20-30 minutes) Check bag limit compliance (may cause bias) - Check bag limit compliance (may cause bias) Verify catch rate stationarity (possible) - Verify catch rate stationarity (possible) Use proper survey weights svydesign() - Use proper survey weights svydesign() Include stratification variables - Include stratification variables Use svyratio() ratio--means - Use svyratio() ratio--means Use svymean() catch/effort ratio mean--ratios - Use svymean() catch/effort ratio mean--ratios Report standard errors confidence intervals - Report standard errors confidence intervals","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"decision-rules","dir":"Articles","previous_headings":"","what":"Decision Rules","title":"Ratio Estimators","text":"Survey Type Interview Type Recommended Estimator Function Call Access point Complete trips Ratio--means (R₁) est_cpue(…, mode = “ratio_of_means”) Roving Incomplete trips Mean--ratios (R₂) truncation est_cpue(…, mode = “mean_of_ratios”) + filter short trips Complemented (aerial-access) Complete trips Ratio--means (R₁) est_cpue(…, mode = “ratio_of_means”) Complemented (aerial-roving) Incomplete trips Mean--ratios (R₂) truncation est_cpue(…, mode = “mean_of_ratios”) + filter","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"pre-processing-checklist","dir":"Articles","previous_headings":"","what":"Pre-processing Checklist","title":"Ratio Estimators","text":"surveys: Check missing data catch effort - Check missing data catch effort Verify effort > 0 interviews - Verify effort > 0 interviews Check outliers (data entry errors) - Check outliers (data entry errors) ROVING surveys specifically: Truncate short trips (< 20-30 minutes) - Truncate short trips (< 20-30 minutes) Check bag limit compliance (may cause bias) - Check bag limit compliance (may cause bias) Verify catch rate stationarity (possible) - Verify catch rate stationarity (possible)","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"variance-estimation-checklist","dir":"Articles","previous_headings":"","what":"Variance Estimation Checklist","title":"Ratio Estimators","text":"Use proper survey weights svydesign() - Use proper survey weights svydesign() Include stratification variables - Include stratification variables Use svyratio() ratio--means - Use svyratio() ratio--means Use svymean() catch/effort ratio mean--ratios - Use svymean() catch/effort ratio mean--ratios Report standard errors confidence intervals - Report standard errors confidence intervals","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Ratio Estimators","text":"Pollock, K.H., Hoenig, J.M., Jones, C.M., Robson, D.S., & Greene, C.J. (1997). Catch rate estimation roving access point surveys. North American Journal Fisheries Management, 17(1), 11-19. Pollock, K.H., Hoenig, J.M., Jones, C.M., Robson, D.S., & Greene, C.J. (1997). Catch rate estimation roving access point surveys. North American Journal Fisheries Management , 17(1), 11-19. Rasmussen, P.W., Staggs, M.D., Beard, T.D., & Newman, S.P. (1998). Bias confidence interval coverage creel survey estimators evaluated simulation. Transactions American Fisheries Society, 127(3), 469-480. Rasmussen, P.W., Staggs, M.D., Beard, T.D., & Newman, S.P. (1998). Bias confidence interval coverage creel survey estimators evaluated simulation. Transactions American Fisheries Society , 127(3), 469-480. Jones, C.M., Robson, D.S., Lakkis, H.D., & Kressel, J. (1995). Properties catch rates used analysis angler surveys. Transactions American Fisheries Society, 124(6), 911-928. Jones, C.M., Robson, D.S., Lakkis, H.D., & Kressel, J. (1995). Properties catch rates used analysis angler surveys. Transactions American Fisheries Society , 124(6), 911-928. Lumley, T. (2004). Analysis complex survey samples. Journal Statistical Software, 9(1), 1-19. Lumley, T. (2004). Analysis complex survey samples. Journal Statistical Software , 9(1), 1-19.","code":""},{"path":"/articles/ratio-estimators-guide.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Ratio Estimators","text":"choice ratio--means mean--ratios depends fundamentally survey design: Access point interviews ratio--means - Access point interviews → Use ratio--means Roving interviews mean--ratios truncation - Roving interviews → Use mean--ratios truncation tidycreel package implements estimators proper variance estimation survey package. following decision rules vignette, can ensure catch rate estimates unbiased confidence intervals correct coverage.","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"One common questions creel survey analysis : “use ratio--means mean--ratios estimate catch rate?” vignette answers question : Decision rules based survey design type Simulation demonstrations showing estimator performance Practical guidance variance estimation Clear examples using tidycreel","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"quick-answer-decision-tree","dir":"Articles","previous_headings":"","what":"Quick Answer: Decision Tree","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"","code":"┌─────────────────────────────────────────────┐ │   What type of interviews do you have?      │ └─────────────────┬───────────────────────────┘                   │         ┌─────────┴─────────┐         │                   │     ┌───▼──────┐          ┌───▼────────┐     │ ACCESS   │          │ ROVING     │     │(Complete │          │(Incomplete │     │ trips)   │          │  trips)    │     └───┬──────┘          └───┬────────┘         │                     │         │                     │     ┌───▼─────────────────┐   │     │ Use RATIO-OF-MEANS  │   │     │  R₁ = Σcatch/Σeffort│   │     │                     │   │     │ Why? Each angler    │   │     │ has equal sampling  │   │     │ probability.        │   │     │                     │   │     │ ✓ Unbiased          │   │     │ ✓ Finite variance   │   │     └─────────────────────┘   │                               │                   ┌───────────▼────────────────┐                   │ Use MEAN-OF-RATIOS         │                   │  R₂ = (1/n)Σ(catch/effort) │                   │                            │                   │ IMPORTANT: Truncate short  │                   │ trips (< 20-30 minutes)    │                   │                            │                   │ Why? Sampling probability  │                   │ ∝ trip length. R₁ would    │                   │ give biased estimate.      │                   │                            │                   │ ⚠ Avoid if bag limits      │                   │   are low & easily obtained│                   └────────────────────────────┘"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"theoretical-background","dir":"Articles","previous_headings":"","what":"Theoretical Background","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Sampling Design: Interviews conducted anglers complete trips anglers equal probability interviewed P(interviewed) = constant, regardless trip length Appropriate Estimator: Ratio--Means (R₁) [_1 = ] (C_j^) = total catch completed trip (L_j^) = total trip length completion. Expected Value: [E(_1) ] ✓ want total catch estimation! Sampling Design: Interviews conducted fishing trips Sampling probability ∝ trip length Longer trips likely encountered Appropriate Estimator: Mean--Ratios (R₂) Truncation [2 = {j=1}^{n} ] (C_j) = catch time interview (L_j) = elapsed time interview. truncation: include interviews (L_j > L_{min}) (typically 20-30 minutes). Expected Value: [E(_2) ] ✓ Correct roving interviews! use R₁ roving? ratio--means roving interviews : [E(_1^{roving}) ] weighted average weights = (trip length)², estimate population catch rate! matters: Real creel surveys often produce mix completed (access-point) incomplete (roving/intercept) interviews. Estimator choice must follow inclusion probability, just trip status, avoid bias. inclusion probability differs design (equal-probability access points vs. length-biased roving), pooling interviews applying single estimator can introduce bias. Treat designs according sampling properties. Treat complete incomplete interviews two strata, combine effort weighting: Complete trips (access point): use Ratio--Means (R₁ = ΣC / ΣE). Incomplete trips (roving): use Mean--Ratios (R₂ = (1/n) Σ(C/E)) truncation short trips (e.g., < 20–30 min). Effort-weighted combination: R̂combined=R1Ecomplete+R2EincompleteEcomplete+Eincomplete \\hat{R}_{\\text{combined}} = \\frac{R_1 E_{\\text{complete}} + R_2 E_{\\text{incomplete}}}{E_{\\text{complete}} + E_{\\text{incomplete}}} can estimate selection/inclusion probabilities (e.g., model trip completeness roving intercept likelihood), use weighted ratio: R̂weighted=∑iwiCi∑iwiEi,wi=1/P(selecti). \\hat{R}_{\\text{weighted}} = \\frac{\\sum_i w_i C_i}{\\sum_i w_i E_i}, \\quad w_i = 1 / P(\\text{select}_i). useful hybrid designs sampling varies predictably across modes, times, sites. Compute: () R₁ complete , (b) R₂ incomplete (truncation), (c) combined estimator. differences small (e.g., < 5–10%), pooling assumptions may reasonable; document . apply R₁ unfiltered roving data — biased high due length-biased sampling. apply R₂ complete trips — bias direction depends effort variability. Always truncate short incomplete trips stabilize R₂ reduce small-denominator issues. bag limits frequently hit, cautious R₂ (ceiling effects can distort ratios). Estimate SEs stratum appropriate formula (delta-method R₁; sample variance ratios R₂), combine via delta-method using effort-weight combination .","code":"complete <- data %>% dplyr::filter(trip_complete == TRUE) incomplete <- data %>% dplyr::filter(trip_complete == FALSE, trip_length >= 0.5)  # 0.5 h = 30 min  r1 <- sum(complete$catch) / sum(complete$effort) r2 <- mean(incomplete$catch / incomplete$effort)  E1 <- sum(complete$effort) E2 <- sum(incomplete$effort)  R_combined <- (r1 * E1 + r2 * E2) / (E1 + E2)"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"access-point-complete-trip-interviews","dir":"Articles","previous_headings":"","what":"Access Point (Complete Trip) Interviews","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Sampling Design: Interviews conducted anglers complete trips anglers equal probability interviewed P(interviewed) = constant, regardless trip length Appropriate Estimator: Ratio--Means (R₁) [_1 = ] (C_j^) = total catch completed trip (L_j^) = total trip length completion. Expected Value: [E(_1) ] ✓ want total catch estimation!","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"roving-incomplete-trip-interviews","dir":"Articles","previous_headings":"","what":"Roving (Incomplete Trip) Interviews","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Sampling Design: Interviews conducted fishing trips Sampling probability ∝ trip length Longer trips likely encountered Appropriate Estimator: Mean--Ratios (R₂) Truncation [2 = {j=1}^{n} ] (C_j) = catch time interview (L_j) = elapsed time interview. truncation: include interviews (L_j > L_{min}) (typically 20-30 minutes). Expected Value: [E(_2) ] ✓ Correct roving interviews! use R₁ roving? ratio--means roving interviews : [E(_1^{roving}) ] weighted average weights = (trip length)², estimate population catch rate!","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"handling-mixed-complete-and-incomplete-trips","dir":"Articles","previous_headings":"","what":"Handling Mixed Complete and Incomplete Trips","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"matters: Real creel surveys often produce mix completed (access-point) incomplete (roving/intercept) interviews. Estimator choice must follow inclusion probability, just trip status, avoid bias. inclusion probability differs design (equal-probability access points vs. length-biased roving), pooling interviews applying single estimator can introduce bias. Treat designs according sampling properties. Treat complete incomplete interviews two strata, combine effort weighting: Complete trips (access point): use Ratio--Means (R₁ = ΣC / ΣE). Incomplete trips (roving): use Mean--Ratios (R₂ = (1/n) Σ(C/E)) truncation short trips (e.g., < 20–30 min). Effort-weighted combination: R̂combined=R1Ecomplete+R2EincompleteEcomplete+Eincomplete \\hat{R}_{\\text{combined}} = \\frac{R_1 E_{\\text{complete}} + R_2 E_{\\text{incomplete}}}{E_{\\text{complete}} + E_{\\text{incomplete}}} can estimate selection/inclusion probabilities (e.g., model trip completeness roving intercept likelihood), use weighted ratio: R̂weighted=∑iwiCi∑iwiEi,wi=1/P(selecti). \\hat{R}_{\\text{weighted}} = \\frac{\\sum_i w_i C_i}{\\sum_i w_i E_i}, \\quad w_i = 1 / P(\\text{select}_i). useful hybrid designs sampling varies predictably across modes, times, sites. Compute: () R₁ complete , (b) R₂ incomplete (truncation), (c) combined estimator. differences small (e.g., < 5–10%), pooling assumptions may reasonable; document . apply R₁ unfiltered roving data — biased high due length-biased sampling. apply R₂ complete trips — bias direction depends effort variability. Always truncate short incomplete trips stabilize R₂ reduce small-denominator issues. bag limits frequently hit, cautious R₂ (ceiling effects can distort ratios). Estimate SEs stratum appropriate formula (delta-method R₁; sample variance ratios R₂), combine via delta-method using effort-weight combination .","code":"complete <- data %>% dplyr::filter(trip_complete == TRUE) incomplete <- data %>% dplyr::filter(trip_complete == FALSE, trip_length >= 0.5)  # 0.5 h = 30 min  r1 <- sum(complete$catch) / sum(complete$effort) r2 <- mean(incomplete$catch / incomplete$effort)  E1 <- sum(complete$effort) E2 <- sum(incomplete$effort)  R_combined <- (r1 * E1 + r2 * E2) / (E1 + E2)"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"simulation-study","dir":"Articles","previous_headings":"","what":"Simulation Study","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"theoretical results show estimator choice matters. large bias practice? truncation really help? Let’s demonstrate principles simulation, following approach Rasmussen et al. (1998) Pollock et al. (1997). ’ll simulate realistic fishing scenario compare estimator performance. Simulate traditional access point creel interview anglers finish. Now simulate roving interviews anglers intercepted trips. Run 1000 replications assess bias precision. Access Point Design: Estimator Performance Key Finding: access interviews, estimators approximately unbiased, ratio--means (R₁) typically slightly lower variance.  Access Point Design: Distribution Estimates. estimators center true value (dashed line), demonstrating unbiasedness. ratio--means (R₁) shows slightly tighter clustering, indicating lower variance. Roving Design: Estimator Performance Key Findings: R₁ (ratio--means) BIASED roving interviews - estimate population catch rate R₂ (mean--ratios) without truncation approximately unbiased high variance (unstable) R₂ truncation approximately unbiased lower variance ✓ RECOMMENDED  Roving Design: Effect Truncation. R₁ (ratio--means) biased roving surveys regardless truncation. R₂ (mean--ratios) unbiased high variance without truncation; truncation reduces variance maintaining unbiasedness.","code":"#' Simulate a day of fishing with known parameters #' #' @param n_anglers Number of anglers fishing during the day #' @param mean_trip_hours Mean trip length (hours) #' @param mean_catch_rate Mean catch per hour (Poisson rate parameter) #' @param day_length_hours Length of fishing day #' @return List with population parameters and individual angler data simulate_fishing_day <- function(n_anglers = 100,                                  mean_trip_hours = 4,                                  mean_catch_rate = 2,                                  day_length_hours = 12) {    # Each angler's true catch rate (gamma-distributed for heterogeneity)   # Shape = 1, rate = 1/mean gives exponential with specified mean   # This creates variation in angler skill/success   alpha <- 1   beta <- 1 / mean_catch_rate   catch_rates <- rgamma(n_anglers, shape = alpha, rate = beta)    # Trip lengths (gamma-distributed)   shape_trip <- 4  # Controls variability   rate_trip <- shape_trip / mean_trip_hours   trip_lengths <- rgamma(n_anglers, shape = shape_trip, rate = rate_trip)   trip_lengths <- pmin(trip_lengths, day_length_hours)  # Can't exceed day length    # Generate catches for each angler (Poisson process)   # Expected catch = catch_rate * trip_length   completed_catch <- rpois(n_anglers, lambda = catch_rates * trip_lengths)    # True population parameters   total_effort <- sum(trip_lengths)   total_catch <- sum(completed_catch)   true_catch_rate <- total_catch / total_effort    # Return angler-level data   tibble(     angler_id = 1:n_anglers,     catch_rate_true = catch_rates,     trip_length = trip_lengths,     completed_catch = completed_catch,     true_population_rate = true_catch_rate,     total_effort = total_effort,     total_catch = total_catch   ) }  # Example fishing_day <- simulate_fishing_day(n_anglers = 100) head(fishing_day) # A tibble: 6 × 7   angler_id catch_rate_true trip_length completed_catch true_population_rate       <int>           <dbl>       <dbl>           <int>                <dbl> 1         1           2.00         4.78               7                 2.15 2         2           2.26         1.56               5                 2.15 3         3           0.851        4.74               4                 2.15 4         4           1.03         6.06               5                 2.15 5         5           6.96         4.52              35                 2.15 6         6           0.627        5.59               3                 2.15 # ℹ 2 more variables: total_effort <dbl>, total_catch <int> # Summary of true population parameters cat(\"True Population Parameters:\\n\") True Population Parameters: cat(\"  Total anglers:\", nrow(fishing_day), \"\\n\") Total anglers: 100 cat(\"  Total effort:\", round(fishing_day$total_effort[1], 1), \"hours\\n\") Total effort: 391.8 hours cat(\"  Total catch:\", fishing_day$total_catch[1], \"fish\\n\") Total catch: 844 fish cat(\"  True catch rate:\", round(fishing_day$true_population_rate[1], 3), \"fish/hour\\n\") True catch rate: 2.154 fish/hour #' Simulate access point interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Number of interviews to conduct #' @return Tibble with interview data sample_access_interviews <- function(fishing_day, n_interviews = 30) {   # Simple random sample (equal probability)   sampled <- fishing_day %>%     sample_n(size = min(n_interviews, nrow(fishing_day)), replace = FALSE) %>%     select(angler_id, completed_catch, trip_length, true_population_rate)    sampled }  # Single realization access_sample <- sample_access_interviews(fishing_day, n_interviews = 30) head(access_sample) # A tibble: 6 × 4   angler_id completed_catch trip_length true_population_rate       <int>           <int>       <dbl>                <dbl> 1         1               7        4.78                 2.15 2        69               4        5.05                 2.15 3        79              14        6.27                 2.15 4        19               5        6.75                 2.15 5        12               1        4.72                 2.15 6        64               0        5.88                 2.15 # Calculate both estimators calculate_estimates <- function(interviews, truncate_minutes = NULL) {    # Apply truncation if specified (for roving surveys)   if (!is.null(truncate_minutes)) {     interviews <- interviews %>%       filter(trip_length >= truncate_minutes / 60)   }    n <- nrow(interviews)    # Ratio-of-means   r1 <- sum(interviews$completed_catch) / sum(interviews$trip_length)    # Mean-of-ratios   r2 <- mean(interviews$completed_catch / interviews$trip_length)    # Variance estimates (simplified)   # For R1: use delta method (Taylor series approximation)   # Var(R₁) ≈ (1/n·E̅²) · Var(C - R₁·E)   # where residual = catch - estimated_rate × effort   r <- interviews$completed_catch   e <- interviews$trip_length   r_bar <- mean(r)   e_bar <- mean(e)   var_r1 <- (1 / (n * e_bar^2)) * var(r - r1 * e)   se_r1 <- sqrt(var_r1)    # For R2: simple variance of the ratios   ratios <- interviews$completed_catch / interviews$trip_length   var_r2 <- var(ratios) / n   se_r2 <- sqrt(var_r2)    tibble(     n = n,     ratio_of_means = r1,     mean_of_ratios = r2,     se_r1 = se_r1,     se_r2 = se_r2,     true_rate = interviews$true_population_rate[1]   ) }  access_results <- calculate_estimates(access_sample) access_results # A tibble: 1 × 6       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> 1    30           2.04           2.41 0.401 0.463      2.15 #' Simulate roving interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Target number of interviews #' @return Tibble with incomplete trip interview data sample_roving_interviews <- function(fishing_day, n_interviews = 30) {    # Length-biased sampling: probability of encounter ∝ trip duration   # P(interview angler i) = L_i / Σ L_j (normalized by total effort)   # Longer trips have higher chance of being encountered during roving   prob_intercept <- fishing_day$trip_length / sum(fishing_day$trip_length)    # Sample with probability proportional to size   sampled_indices <- sample(     1:nrow(fishing_day),     size = min(n_interviews, nrow(fishing_day)),     replace = FALSE,     prob = prob_intercept   )    sampled <- fishing_day[sampled_indices, ]    # For each intercepted angler, determine interview time   # Uniform on [0, trip_length] (on average, intercepted at midpoint)   sampled <- sampled %>%     mutate(       # Time fished when interviewed (uniform on [0, trip_length])       # On average, anglers are intercepted at midpoint of their trip       time_at_interview = runif(n(), min = 0, max = trip_length),        # Catch at interview time (incomplete trip)       # Poisson process: E[catch | time_t] = λ × t       # where λ = angler's true catch rate, t = time fished so far       catch_at_interview = rpois(n(), lambda = catch_rate_true * time_at_interview)     ) %>%     select(angler_id, catch_at_interview, time_at_interview,            completed_catch, trip_length, true_population_rate)    sampled }  roving_sample <- sample_roving_interviews(fishing_day, n_interviews = 30) head(roving_sample) # A tibble: 6 × 6   angler_id catch_at_interview time_at_interview completed_catch trip_length       <int>              <int>             <dbl>           <int>       <dbl> 1        27                  1             2.57                2        5.27 2        37                  4             1.46               13        2.99 3        81                  0             0.326               3        3.86 4        32                  1             2.30                8        5.76 5        97                  6             3.54               10        4.81 6        28                  4             2.58                5        2.72 # ℹ 1 more variable: true_population_rate <dbl> # For roving, use incomplete data # Note: calculate_estimates() expects columns named 'completed_catch' and 'trip_length' roving_data <- roving_sample %>%   select(angler_id,          completed_catch = catch_at_interview,          trip_length = time_at_interview,          true_population_rate)  # No truncation roving_no_trunc <- calculate_estimates(roving_data, truncate_minutes = NULL)  # With truncation (30 minutes) roving_with_trunc <- calculate_estimates(roving_data, truncate_minutes = 30)  bind_rows(   roving_no_trunc %>% mutate(truncation = \"None\"),   roving_with_trunc %>% mutate(truncation = \"30 min\") ) # A tibble: 2 × 7       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate truncation   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> <chr> 1    30           1.98           1.77 0.329 0.289      2.15 None 2    27           1.97           1.67 0.334 0.281      2.15 30 min run_simulation <- function(n_reps = 1000,                            n_anglers = 100,                            n_interviews = 30,                            interview_type = c(\"access\", \"roving\")) {    interview_type <- match.arg(interview_type)    results <- map_dfr(1:n_reps, function(rep) {     # Generate population     day <- simulate_fishing_day(n_anglers = n_anglers)     true_rate <- day$true_population_rate[1]      # Sample based on design     if (interview_type == \"access\") {       sample_data <- sample_access_interviews(day, n_interviews)       sample_data <- sample_data %>%         rename(catch = completed_catch, effort = trip_length)     } else {       sample_data <- sample_roving_interviews(day, n_interviews) %>%         rename(catch = catch_at_interview, effort = time_at_interview)     }      # Calculate estimators     # No truncation     r1_no <- sum(sample_data$catch) / sum(sample_data$effort)     r2_no <- mean(sample_data$catch / sample_data$effort)      # With truncation (30 min = 0.5 hr)     trunc_data <- sample_data %>% filter(effort >= 0.5)     if (nrow(trunc_data) > 0) {       r1_trunc <- sum(trunc_data$catch) / sum(trunc_data$effort)       r2_trunc <- mean(trunc_data$catch / trunc_data$effort)     } else {       r1_trunc <- NA       r2_trunc <- NA     }      tibble(       rep = rep,       true_rate = true_rate,       r1_no_trunc = r1_no,       r2_no_trunc = r2_no,       r1_with_trunc = r1_trunc,       r2_with_trunc = r2_trunc,       n_interviews = n_interviews,       n_after_trunc = nrow(trunc_data)     )   })    results %>%     mutate(design = interview_type) }  # Run simulations access_mc <- run_simulation(n_reps = 1000, interview_type = \"access\") roving_mc <- run_simulation(n_reps = 1000, interview_type = \"roving\") # Summary statistics access_summary <- access_mc %>%   summarise(     true_rate = mean(true_rate),      # Ratio of means (R1)     r1_mean = mean(r1_no_trunc),     r1_bias = mean(r1_no_trunc - true_rate),     r1_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate),     r1_rmse = sqrt(mean((r1_no_trunc - true_rate)^2)),     r1_se = sd(r1_no_trunc),      # Mean of ratios (R2)     r2_mean = mean(r2_no_trunc),     r2_bias = mean(r2_no_trunc - true_rate),     r2_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate),     r2_rmse = sqrt(mean((r2_no_trunc - true_rate)^2)),     r2_se = sd(r2_no_trunc)   )  access_summary %>%   pivot_longer(cols = -true_rate, names_to = c(\"estimator\", \"metric\"), names_sep = \"_\", values_to = \"value\", names_repair = \"minimal\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   select(estimator, mean, bias, pct, se, rmse) %>%   rename(pct_bias = pct) %>%   knitr::kable(digits = 4, caption = \"Access Point Design: Estimator Performance\") access_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc) %>%   pivot_longer(cols = c(r1_no_trunc, r2_no_trunc),                names_to = \"estimator\",                values_to = \"estimate\") %>%   mutate(estimator = recode(estimator,                             r1_no_trunc = \"Ratio of Means (R₁)\",                             r2_no_trunc = \"Mean of Ratios (R₂)\")) %>%   ggplot(aes(x = estimate, fill = estimator)) +   geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +   geom_vline(aes(xintercept = mean(true_rate)), linetype = \"dashed\", size = 1) +   facet_wrap(~estimator, ncol = 1) +   labs(title = \"Access Point Design: Sampling Distribution\",        subtitle = \"Dashed line = true population catch rate\",        x = \"Estimated Catch Rate (fish/hour)\",        y = \"Frequency\") +   theme_minimal() +   theme(legend.position = \"none\") # Summary statistics roving_summary <- roving_mc %>%   summarise(     true_rate = mean(true_rate),      # R1 no truncation     r1_no_mean = mean(r1_no_trunc, na.rm = TRUE),     r1_no_bias = mean(r1_no_trunc - true_rate, na.rm = TRUE),     r1_no_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_no_rmse = sqrt(mean((r1_no_trunc - true_rate)^2, na.rm = TRUE)),      # R2 no truncation     r2_no_mean = mean(r2_no_trunc, na.rm = TRUE),     r2_no_bias = mean(r2_no_trunc - true_rate, na.rm = TRUE),     r2_no_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_no_rmse = sqrt(mean((r2_no_trunc - true_rate)^2, na.rm = TRUE)),      # R1 with truncation     r1_trunc_mean = mean(r1_with_trunc, na.rm = TRUE),     r1_trunc_bias = mean(r1_with_trunc - true_rate, na.rm = TRUE),     r1_trunc_pct_bias = 100 * mean((r1_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_trunc_rmse = sqrt(mean((r1_with_trunc - true_rate)^2, na.rm = TRUE)),      # R2 with truncation     r2_trunc_mean = mean(r2_with_trunc, na.rm = TRUE),     r2_trunc_bias = mean(r2_with_trunc - true_rate, na.rm = TRUE),     r2_trunc_pct_bias = 100 * mean((r2_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_trunc_rmse = sqrt(mean((r2_with_trunc - true_rate)^2, na.rm = TRUE))   )  roving_summary %>%   pivot_longer(cols = -true_rate,                names_to = c(\"estimator\", \"truncation\", \"metric\"),                names_pattern = \"([^_]+)_([^_]+)_(.*)\",                values_to = \"value\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   mutate(estimator = recode(estimator, r1 = \"Ratio of Means\", r2 = \"Mean of Ratios\"),          truncation = recode(truncation, no = \"No truncation\", trunc = \"30-min truncation\")) %>%   select(estimator, truncation, mean, bias, pct_bias, rmse) %>%   knitr::kable(digits = 4, caption = \"Roving Design: Estimator Performance\") roving_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc, r1_with_trunc, r2_with_trunc) %>%   pivot_longer(cols = -c(rep, true_rate),                names_to = \"estimator\",                values_to = \"estimate\") %>%   filter(!is.na(estimate)) %>%   mutate(     estimator_type = ifelse(grepl(\"r1\", estimator), \"Ratio of Means (R₁)\", \"Mean of Ratios (R₂)\"),     truncation = ifelse(grepl(\"no_trunc\", estimator), \"No Truncation\", \"30-Min Truncation\")   ) %>%   ggplot(aes(x = estimate, fill = truncation)) +   geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +   geom_vline(aes(xintercept = mean(true_rate)), linetype = \"dashed\", size = 1) +   facet_grid(estimator_type ~ truncation, scales = \"free_y\") +   labs(title = \"Roving Design: Impact of Estimator Choice and Truncation\",        subtitle = \"Dashed line = true population catch rate\",        x = \"Estimated Catch Rate (fish/hour)\",        y = \"Frequency\",        fill = \"Truncation\") +   theme_minimal() +   theme(legend.position = \"bottom\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"simulation-setup","dir":"Articles","previous_headings":"","what":"Simulation Setup","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"’ll simulate realistic fishing scenario compare estimator performance.","code":"#' Simulate a day of fishing with known parameters #' #' @param n_anglers Number of anglers fishing during the day #' @param mean_trip_hours Mean trip length (hours) #' @param mean_catch_rate Mean catch per hour (Poisson rate parameter) #' @param day_length_hours Length of fishing day #' @return List with population parameters and individual angler data simulate_fishing_day <- function(n_anglers = 100,                                  mean_trip_hours = 4,                                  mean_catch_rate = 2,                                  day_length_hours = 12) {    # Each angler's true catch rate (gamma-distributed for heterogeneity)   # Shape = 1, rate = 1/mean gives exponential with specified mean   # This creates variation in angler skill/success   alpha <- 1   beta <- 1 / mean_catch_rate   catch_rates <- rgamma(n_anglers, shape = alpha, rate = beta)    # Trip lengths (gamma-distributed)   shape_trip <- 4  # Controls variability   rate_trip <- shape_trip / mean_trip_hours   trip_lengths <- rgamma(n_anglers, shape = shape_trip, rate = rate_trip)   trip_lengths <- pmin(trip_lengths, day_length_hours)  # Can't exceed day length    # Generate catches for each angler (Poisson process)   # Expected catch = catch_rate * trip_length   completed_catch <- rpois(n_anglers, lambda = catch_rates * trip_lengths)    # True population parameters   total_effort <- sum(trip_lengths)   total_catch <- sum(completed_catch)   true_catch_rate <- total_catch / total_effort    # Return angler-level data   tibble(     angler_id = 1:n_anglers,     catch_rate_true = catch_rates,     trip_length = trip_lengths,     completed_catch = completed_catch,     true_population_rate = true_catch_rate,     total_effort = total_effort,     total_catch = total_catch   ) }  # Example fishing_day <- simulate_fishing_day(n_anglers = 100) head(fishing_day) # A tibble: 6 × 7   angler_id catch_rate_true trip_length completed_catch true_population_rate       <int>           <dbl>       <dbl>           <int>                <dbl> 1         1           2.00         4.78               7                 2.15 2         2           2.26         1.56               5                 2.15 3         3           0.851        4.74               4                 2.15 4         4           1.03         6.06               5                 2.15 5         5           6.96         4.52              35                 2.15 6         6           0.627        5.59               3                 2.15 # ℹ 2 more variables: total_effort <dbl>, total_catch <int> # Summary of true population parameters cat(\"True Population Parameters:\\n\") True Population Parameters: cat(\"  Total anglers:\", nrow(fishing_day), \"\\n\") Total anglers: 100 cat(\"  Total effort:\", round(fishing_day$total_effort[1], 1), \"hours\\n\") Total effort: 391.8 hours cat(\"  Total catch:\", fishing_day$total_catch[1], \"fish\\n\") Total catch: 844 fish cat(\"  True catch rate:\", round(fishing_day$true_population_rate[1], 3), \"fish/hour\\n\") True catch rate: 2.154 fish/hour"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"scenario-1-access-point-interviews-complete-trips","dir":"Articles","previous_headings":"","what":"Scenario 1: Access Point Interviews (Complete Trips)","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Simulate traditional access point creel interview anglers finish.","code":"#' Simulate access point interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Number of interviews to conduct #' @return Tibble with interview data sample_access_interviews <- function(fishing_day, n_interviews = 30) {   # Simple random sample (equal probability)   sampled <- fishing_day %>%     sample_n(size = min(n_interviews, nrow(fishing_day)), replace = FALSE) %>%     select(angler_id, completed_catch, trip_length, true_population_rate)    sampled }  # Single realization access_sample <- sample_access_interviews(fishing_day, n_interviews = 30) head(access_sample) # A tibble: 6 × 4   angler_id completed_catch trip_length true_population_rate       <int>           <int>       <dbl>                <dbl> 1         1               7        4.78                 2.15 2        69               4        5.05                 2.15 3        79              14        6.27                 2.15 4        19               5        6.75                 2.15 5        12               1        4.72                 2.15 6        64               0        5.88                 2.15 # Calculate both estimators calculate_estimates <- function(interviews, truncate_minutes = NULL) {    # Apply truncation if specified (for roving surveys)   if (!is.null(truncate_minutes)) {     interviews <- interviews %>%       filter(trip_length >= truncate_minutes / 60)   }    n <- nrow(interviews)    # Ratio-of-means   r1 <- sum(interviews$completed_catch) / sum(interviews$trip_length)    # Mean-of-ratios   r2 <- mean(interviews$completed_catch / interviews$trip_length)    # Variance estimates (simplified)   # For R1: use delta method (Taylor series approximation)   # Var(R₁) ≈ (1/n·E̅²) · Var(C - R₁·E)   # where residual = catch - estimated_rate × effort   r <- interviews$completed_catch   e <- interviews$trip_length   r_bar <- mean(r)   e_bar <- mean(e)   var_r1 <- (1 / (n * e_bar^2)) * var(r - r1 * e)   se_r1 <- sqrt(var_r1)    # For R2: simple variance of the ratios   ratios <- interviews$completed_catch / interviews$trip_length   var_r2 <- var(ratios) / n   se_r2 <- sqrt(var_r2)    tibble(     n = n,     ratio_of_means = r1,     mean_of_ratios = r2,     se_r1 = se_r1,     se_r2 = se_r2,     true_rate = interviews$true_population_rate[1]   ) }  access_results <- calculate_estimates(access_sample) access_results # A tibble: 1 × 6       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> 1    30           2.04           2.41 0.401 0.463      2.15"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"scenario-2-roving-interviews-incomplete-trips","dir":"Articles","previous_headings":"","what":"Scenario 2: Roving Interviews (Incomplete Trips)","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Now simulate roving interviews anglers intercepted trips.","code":"#' Simulate roving interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Target number of interviews #' @return Tibble with incomplete trip interview data sample_roving_interviews <- function(fishing_day, n_interviews = 30) {    # Length-biased sampling: probability of encounter ∝ trip duration   # P(interview angler i) = L_i / Σ L_j (normalized by total effort)   # Longer trips have higher chance of being encountered during roving   prob_intercept <- fishing_day$trip_length / sum(fishing_day$trip_length)    # Sample with probability proportional to size   sampled_indices <- sample(     1:nrow(fishing_day),     size = min(n_interviews, nrow(fishing_day)),     replace = FALSE,     prob = prob_intercept   )    sampled <- fishing_day[sampled_indices, ]    # For each intercepted angler, determine interview time   # Uniform on [0, trip_length] (on average, intercepted at midpoint)   sampled <- sampled %>%     mutate(       # Time fished when interviewed (uniform on [0, trip_length])       # On average, anglers are intercepted at midpoint of their trip       time_at_interview = runif(n(), min = 0, max = trip_length),        # Catch at interview time (incomplete trip)       # Poisson process: E[catch | time_t] = λ × t       # where λ = angler's true catch rate, t = time fished so far       catch_at_interview = rpois(n(), lambda = catch_rate_true * time_at_interview)     ) %>%     select(angler_id, catch_at_interview, time_at_interview,            completed_catch, trip_length, true_population_rate)    sampled }  roving_sample <- sample_roving_interviews(fishing_day, n_interviews = 30) head(roving_sample) # A tibble: 6 × 6   angler_id catch_at_interview time_at_interview completed_catch trip_length       <int>              <int>             <dbl>           <int>       <dbl> 1        27                  1             2.57                2        5.27 2        37                  4             1.46               13        2.99 3        81                  0             0.326               3        3.86 4        32                  1             2.30                8        5.76 5        97                  6             3.54               10        4.81 6        28                  4             2.58                5        2.72 # ℹ 1 more variable: true_population_rate <dbl> # For roving, use incomplete data # Note: calculate_estimates() expects columns named 'completed_catch' and 'trip_length' roving_data <- roving_sample %>%   select(angler_id,          completed_catch = catch_at_interview,          trip_length = time_at_interview,          true_population_rate)  # No truncation roving_no_trunc <- calculate_estimates(roving_data, truncate_minutes = NULL)  # With truncation (30 minutes) roving_with_trunc <- calculate_estimates(roving_data, truncate_minutes = 30)  bind_rows(   roving_no_trunc %>% mutate(truncation = \"None\"),   roving_with_trunc %>% mutate(truncation = \"30 min\") ) # A tibble: 2 × 7       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate truncation   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> <chr> 1    30           1.98           1.77 0.329 0.289      2.15 None 2    27           1.97           1.67 0.334 0.281      2.15 30 min"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"monte-carlo-simulation","dir":"Articles","previous_headings":"","what":"Monte Carlo Simulation","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Run 1000 replications assess bias precision.","code":"run_simulation <- function(n_reps = 1000,                            n_anglers = 100,                            n_interviews = 30,                            interview_type = c(\"access\", \"roving\")) {    interview_type <- match.arg(interview_type)    results <- map_dfr(1:n_reps, function(rep) {     # Generate population     day <- simulate_fishing_day(n_anglers = n_anglers)     true_rate <- day$true_population_rate[1]      # Sample based on design     if (interview_type == \"access\") {       sample_data <- sample_access_interviews(day, n_interviews)       sample_data <- sample_data %>%         rename(catch = completed_catch, effort = trip_length)     } else {       sample_data <- sample_roving_interviews(day, n_interviews) %>%         rename(catch = catch_at_interview, effort = time_at_interview)     }      # Calculate estimators     # No truncation     r1_no <- sum(sample_data$catch) / sum(sample_data$effort)     r2_no <- mean(sample_data$catch / sample_data$effort)      # With truncation (30 min = 0.5 hr)     trunc_data <- sample_data %>% filter(effort >= 0.5)     if (nrow(trunc_data) > 0) {       r1_trunc <- sum(trunc_data$catch) / sum(trunc_data$effort)       r2_trunc <- mean(trunc_data$catch / trunc_data$effort)     } else {       r1_trunc <- NA       r2_trunc <- NA     }      tibble(       rep = rep,       true_rate = true_rate,       r1_no_trunc = r1_no,       r2_no_trunc = r2_no,       r1_with_trunc = r1_trunc,       r2_with_trunc = r2_trunc,       n_interviews = n_interviews,       n_after_trunc = nrow(trunc_data)     )   })    results %>%     mutate(design = interview_type) }  # Run simulations access_mc <- run_simulation(n_reps = 1000, interview_type = \"access\") roving_mc <- run_simulation(n_reps = 1000, interview_type = \"roving\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"results-access-point-design","dir":"Articles","previous_headings":"","what":"Results: Access Point Design","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Access Point Design: Estimator Performance Key Finding: access interviews, estimators approximately unbiased, ratio--means (R₁) typically slightly lower variance.  Access Point Design: Distribution Estimates. estimators center true value (dashed line), demonstrating unbiasedness. ratio--means (R₁) shows slightly tighter clustering, indicating lower variance.","code":"# Summary statistics access_summary <- access_mc %>%   summarise(     true_rate = mean(true_rate),      # Ratio of means (R1)     r1_mean = mean(r1_no_trunc),     r1_bias = mean(r1_no_trunc - true_rate),     r1_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate),     r1_rmse = sqrt(mean((r1_no_trunc - true_rate)^2)),     r1_se = sd(r1_no_trunc),      # Mean of ratios (R2)     r2_mean = mean(r2_no_trunc),     r2_bias = mean(r2_no_trunc - true_rate),     r2_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate),     r2_rmse = sqrt(mean((r2_no_trunc - true_rate)^2)),     r2_se = sd(r2_no_trunc)   )  access_summary %>%   pivot_longer(cols = -true_rate, names_to = c(\"estimator\", \"metric\"), names_sep = \"_\", values_to = \"value\", names_repair = \"minimal\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   select(estimator, mean, bias, pct, se, rmse) %>%   rename(pct_bias = pct) %>%   knitr::kable(digits = 4, caption = \"Access Point Design: Estimator Performance\") access_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc) %>%   pivot_longer(cols = c(r1_no_trunc, r2_no_trunc),                names_to = \"estimator\",                values_to = \"estimate\") %>%   mutate(estimator = recode(estimator,                             r1_no_trunc = \"Ratio of Means (R₁)\",                             r2_no_trunc = \"Mean of Ratios (R₂)\")) %>%   ggplot(aes(x = estimate, fill = estimator)) +   geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +   geom_vline(aes(xintercept = mean(true_rate)), linetype = \"dashed\", size = 1) +   facet_wrap(~estimator, ncol = 1) +   labs(title = \"Access Point Design: Sampling Distribution\",        subtitle = \"Dashed line = true population catch rate\",        x = \"Estimated Catch Rate (fish/hour)\",        y = \"Frequency\") +   theme_minimal() +   theme(legend.position = \"none\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"results-roving-design","dir":"Articles","previous_headings":"","what":"Results: Roving Design","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Roving Design: Estimator Performance Key Findings: R₁ (ratio--means) BIASED roving interviews - estimate population catch rate R₂ (mean--ratios) without truncation approximately unbiased high variance (unstable) R₂ truncation approximately unbiased lower variance ✓ RECOMMENDED  Roving Design: Effect Truncation. R₁ (ratio--means) biased roving surveys regardless truncation. R₂ (mean--ratios) unbiased high variance without truncation; truncation reduces variance maintaining unbiasedness.","code":"# Summary statistics roving_summary <- roving_mc %>%   summarise(     true_rate = mean(true_rate),      # R1 no truncation     r1_no_mean = mean(r1_no_trunc, na.rm = TRUE),     r1_no_bias = mean(r1_no_trunc - true_rate, na.rm = TRUE),     r1_no_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_no_rmse = sqrt(mean((r1_no_trunc - true_rate)^2, na.rm = TRUE)),      # R2 no truncation     r2_no_mean = mean(r2_no_trunc, na.rm = TRUE),     r2_no_bias = mean(r2_no_trunc - true_rate, na.rm = TRUE),     r2_no_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_no_rmse = sqrt(mean((r2_no_trunc - true_rate)^2, na.rm = TRUE)),      # R1 with truncation     r1_trunc_mean = mean(r1_with_trunc, na.rm = TRUE),     r1_trunc_bias = mean(r1_with_trunc - true_rate, na.rm = TRUE),     r1_trunc_pct_bias = 100 * mean((r1_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_trunc_rmse = sqrt(mean((r1_with_trunc - true_rate)^2, na.rm = TRUE)),      # R2 with truncation     r2_trunc_mean = mean(r2_with_trunc, na.rm = TRUE),     r2_trunc_bias = mean(r2_with_trunc - true_rate, na.rm = TRUE),     r2_trunc_pct_bias = 100 * mean((r2_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_trunc_rmse = sqrt(mean((r2_with_trunc - true_rate)^2, na.rm = TRUE))   )  roving_summary %>%   pivot_longer(cols = -true_rate,                names_to = c(\"estimator\", \"truncation\", \"metric\"),                names_pattern = \"([^_]+)_([^_]+)_(.*)\",                values_to = \"value\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   mutate(estimator = recode(estimator, r1 = \"Ratio of Means\", r2 = \"Mean of Ratios\"),          truncation = recode(truncation, no = \"No truncation\", trunc = \"30-min truncation\")) %>%   select(estimator, truncation, mean, bias, pct_bias, rmse) %>%   knitr::kable(digits = 4, caption = \"Roving Design: Estimator Performance\") roving_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc, r1_with_trunc, r2_with_trunc) %>%   pivot_longer(cols = -c(rep, true_rate),                names_to = \"estimator\",                values_to = \"estimate\") %>%   filter(!is.na(estimate)) %>%   mutate(     estimator_type = ifelse(grepl(\"r1\", estimator), \"Ratio of Means (R₁)\", \"Mean of Ratios (R₂)\"),     truncation = ifelse(grepl(\"no_trunc\", estimator), \"No Truncation\", \"30-Min Truncation\")   ) %>%   ggplot(aes(x = estimate, fill = truncation)) +   geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +   geom_vline(aes(xintercept = mean(true_rate)), linetype = \"dashed\", size = 1) +   facet_grid(estimator_type ~ truncation, scales = \"free_y\") +   labs(title = \"Roving Design: Impact of Estimator Choice and Truncation\",        subtitle = \"Dashed line = true population catch rate\",        x = \"Estimated Catch Rate (fish/hour)\",        y = \"Frequency\",        fill = \"Truncation\") +   theme_minimal() +   theme(legend.position = \"bottom\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"practical-implementation-with-tidycreel","dir":"Articles","previous_headings":"","what":"Practical Implementation with tidycreel","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"","code":"# Assuming you have complete-trip interview data interviews_complete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 8),   hours_fished = rgamma(100, shape = 4, rate = 1),   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # Create survey design svy_interviews <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_complete )  # Use RATIO-OF-MEANS (default and recommended) cpue_access <- est_cpue(   design = svy_interviews,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"ratio_of_means\"  # ✓ Correct for access interviews )  cpue_access # Assuming you have incomplete-trip interview data interviews_incomplete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 4),  # Catch so far   hours_fished = runif(100, min = 0.2, max = 6),  # Time so far   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # IMPORTANT: Truncate short trips before analysis interviews_truncated <- interviews_incomplete %>%   filter(hours_fished >= 0.5)  # Remove trips < 30 minutes  # Create survey design svy_roving <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_truncated )  # Use MEAN-OF-RATIOS for roving interviews cpue_roving <- est_cpue(   design = svy_roving,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"mean_of_ratios\"  # ✓ Correct for roving interviews )  cpue_roving"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"access-point-survey-example","dir":"Articles","previous_headings":"","what":"Access Point Survey Example","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"","code":"# Assuming you have complete-trip interview data interviews_complete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 8),   hours_fished = rgamma(100, shape = 4, rate = 1),   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # Create survey design svy_interviews <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_complete )  # Use RATIO-OF-MEANS (default and recommended) cpue_access <- est_cpue(   design = svy_interviews,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"ratio_of_means\"  # ✓ Correct for access interviews )  cpue_access"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"roving-survey-example","dir":"Articles","previous_headings":"","what":"Roving Survey Example","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"","code":"# Assuming you have incomplete-trip interview data interviews_incomplete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 4),  # Catch so far   hours_fished = runif(100, min = 0.2, max = 6),  # Time so far   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # IMPORTANT: Truncate short trips before analysis interviews_truncated <- interviews_incomplete %>%   filter(hours_fished >= 0.5)  # Remove trips < 30 minutes  # Create survey design svy_roving <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_truncated )  # Use MEAN-OF-RATIOS for roving interviews cpue_roving <- est_cpue(   design = svy_roving,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"mean_of_ratios\"  # ✓ Correct for roving interviews )  cpue_roving"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"variance-estimation","dir":"Articles","previous_headings":"","what":"Variance Estimation","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"ratio--means survey weights, survey package automatically uses delta method: Note: variance formulas assume sampling infinite (large) population. sample size substantial relative total number anglers (n/N > 5%), may want apply finite population correction (FPC): multiply variance (1 - n/N). However, creel surveys population potential anglers large, correction negligible. [(_1) (C - _1 E)] (C) = catch, (E) = effort. mean--ratios, variance straightforward: [(_2) = ()]","code":"# survey::svyratio() provides proper variance cpue_result <- est_cpue(design = svy_interviews, mode = \"ratio_of_means\")  # Standard error is included cpue_result$se  # 95% confidence interval cpue_result$ci_low cpue_result$ci_high # survey::svymean() on the ratio variable cpue_roving <- est_cpue(design = svy_roving, mode = \"mean_of_ratios\")  # Standard error and CIs included cpue_roving$se cpue_roving$ci_low cpue_roving$ci_high"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"access-point-ratio-of-means","dir":"Articles","previous_headings":"","what":"Access Point (Ratio-of-Means)","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"ratio--means survey weights, survey package automatically uses delta method: Note: variance formulas assume sampling infinite (large) population. sample size substantial relative total number anglers (n/N > 5%), may want apply finite population correction (FPC): multiply variance (1 - n/N). However, creel surveys population potential anglers large, correction negligible. [(_1) (C - _1 E)] (C) = catch, (E) = effort.","code":"# survey::svyratio() provides proper variance cpue_result <- est_cpue(design = svy_interviews, mode = \"ratio_of_means\")  # Standard error is included cpue_result$se  # 95% confidence interval cpue_result$ci_low cpue_result$ci_high"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"roving-mean-of-ratios-with-truncation","dir":"Articles","previous_headings":"","what":"Roving (Mean-of-Ratios with Truncation)","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"mean--ratios, variance straightforward: [(_2) = ()]","code":"# survey::svymean() on the ratio variable cpue_roving <- est_cpue(design = svy_roving, mode = \"mean_of_ratios\")  # Standard error and CIs included cpue_roving$se cpue_roving$ci_low cpue_roving$ci_high"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"special-considerations","dir":"Articles","previous_headings":"","what":"Special Considerations","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"⚠️ CRITICAL WARNING: Roving surveys can produce severe negative bias (underestimation 20-50%+) bag limits low (≤5 fish) anglers comply leaving immediately upon reaching limit. Problem: anglers leave immediately catching limit, roving clerk encounter unsuccessful anglers, leading severe underestimation. Example simulation (bag limit = 2 fish): Roving Bias Different Bag Limits Recommendation: bag limits low (≤5 fish) compliance high, use access point interviews instead roving. catch rates change systematically trips (e.g., learning curve, time--day effects), roving interviews may biased. Check : Comparing incomplete-trip catch rates complete-trip catch rates Looking patterns catch rate vs. time--day nonstationary: Consider access point interviews model time-varying catch rate.","code":"simulate_with_bag_limit <- function(n_reps = 500, bag_limit = 2) {   map_dfr(1:n_reps, function(rep) {     # Simulate fishing day     day <- simulate_fishing_day(n_anglers = 100)     true_rate <- day$true_population_rate[1]      # Apply bag limit: anglers stop when limit reached     day_limited <- day %>%       mutate(         # Time to reach bag limit (exponential waiting time)         time_to_limit = ifelse(catch_rate_true > 0,                                bag_limit / catch_rate_true,                                Inf),         # Actual trip length (stop at limit or planned end, whichever comes first)         actual_trip_length = pmin(trip_length, time_to_limit),         # Actual catch (capped at bag limit)         actual_catch = pmin(completed_catch, bag_limit),         # Did angler reach bag limit before planned trip end?         reached_limit = (time_to_limit < trip_length)       )      # Roving interviews can only encounter anglers still on-site     # Those who reached bag limit before their planned trip end have already left     # Only those who haven't reached the limit OR reached it at/after planned end are available     still_fishing <- day_limited %>%       filter(!reached_limit)      if (nrow(still_fishing) > 10) {       # Sample from those still fishing       sample_data <- sample_roving_interviews(still_fishing, n_interviews = 30) %>%         rename(catch = catch_at_interview, effort = time_at_interview) %>%         filter(effort >= 0.5)        if (nrow(sample_data) > 0) {         r2 <- mean(sample_data$catch / sample_data$effort)         return(tibble(rep = rep, true_rate = true_rate, estimated_rate = r2,                      bag_limit = bag_limit))       }     }      tibble(rep = rep, true_rate = true_rate, estimated_rate = NA, bag_limit = bag_limit)   }) }  bag_limit_results <- bind_rows(   simulate_with_bag_limit(bag_limit = 2),   simulate_with_bag_limit(bag_limit = 5),   simulate_with_bag_limit(bag_limit = 10) )  bag_limit_summary <- bag_limit_results %>%   filter(!is.na(estimated_rate)) %>%   group_by(bag_limit) %>%   summarise(     true_rate = mean(true_rate),     mean_estimate = mean(estimated_rate),     bias = mean(estimated_rate - true_rate),     pct_bias = 100 * mean((estimated_rate - true_rate) / true_rate)   )  bag_limit_summary %>%   knitr::kable(digits = 3, caption = \"Roving Bias Under Different Bag Limits\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"bag-limits","dir":"Articles","previous_headings":"","what":"Bag Limits","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"⚠️ CRITICAL WARNING: Roving surveys can produce severe negative bias (underestimation 20-50%+) bag limits low (≤5 fish) anglers comply leaving immediately upon reaching limit. Problem: anglers leave immediately catching limit, roving clerk encounter unsuccessful anglers, leading severe underestimation. Example simulation (bag limit = 2 fish): Roving Bias Different Bag Limits Recommendation: bag limits low (≤5 fish) compliance high, use access point interviews instead roving.","code":"simulate_with_bag_limit <- function(n_reps = 500, bag_limit = 2) {   map_dfr(1:n_reps, function(rep) {     # Simulate fishing day     day <- simulate_fishing_day(n_anglers = 100)     true_rate <- day$true_population_rate[1]      # Apply bag limit: anglers stop when limit reached     day_limited <- day %>%       mutate(         # Time to reach bag limit (exponential waiting time)         time_to_limit = ifelse(catch_rate_true > 0,                                bag_limit / catch_rate_true,                                Inf),         # Actual trip length (stop at limit or planned end, whichever comes first)         actual_trip_length = pmin(trip_length, time_to_limit),         # Actual catch (capped at bag limit)         actual_catch = pmin(completed_catch, bag_limit),         # Did angler reach bag limit before planned trip end?         reached_limit = (time_to_limit < trip_length)       )      # Roving interviews can only encounter anglers still on-site     # Those who reached bag limit before their planned trip end have already left     # Only those who haven't reached the limit OR reached it at/after planned end are available     still_fishing <- day_limited %>%       filter(!reached_limit)      if (nrow(still_fishing) > 10) {       # Sample from those still fishing       sample_data <- sample_roving_interviews(still_fishing, n_interviews = 30) %>%         rename(catch = catch_at_interview, effort = time_at_interview) %>%         filter(effort >= 0.5)        if (nrow(sample_data) > 0) {         r2 <- mean(sample_data$catch / sample_data$effort)         return(tibble(rep = rep, true_rate = true_rate, estimated_rate = r2,                      bag_limit = bag_limit))       }     }      tibble(rep = rep, true_rate = true_rate, estimated_rate = NA, bag_limit = bag_limit)   }) }  bag_limit_results <- bind_rows(   simulate_with_bag_limit(bag_limit = 2),   simulate_with_bag_limit(bag_limit = 5),   simulate_with_bag_limit(bag_limit = 10) )  bag_limit_summary <- bag_limit_results %>%   filter(!is.na(estimated_rate)) %>%   group_by(bag_limit) %>%   summarise(     true_rate = mean(true_rate),     mean_estimate = mean(estimated_rate),     bias = mean(estimated_rate - true_rate),     pct_bias = 100 * mean((estimated_rate - true_rate) / true_rate)   )  bag_limit_summary %>%   knitr::kable(digits = 3, caption = \"Roving Bias Under Different Bag Limits\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"nonstationary-catch-rates","dir":"Articles","previous_headings":"","what":"Nonstationary Catch Rates","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"catch rates change systematically trips (e.g., learning curve, time--day effects), roving interviews may biased. Check : Comparing incomplete-trip catch rates complete-trip catch rates Looking patterns catch rate vs. time--day nonstationary: Consider access point interviews model time-varying catch rate.","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"summary-practical-guidelines","dir":"Articles","previous_headings":"","what":"Summary: Practical Guidelines","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"surveys: Check missing data catch effort Verify effort > 0 interviews Check outliers (data entry errors) ROVING surveys specifically: Truncate short trips (< 20-30 minutes) Check bag limit compliance (may cause bias) Verify catch rate stationarity (possible) Use proper survey weights svydesign() Include stratification variables Use svyratio() ratio--means Use svymean() catch/effort ratio mean--ratios Report standard errors confidence intervals","code":""},{"path":[]},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"pre-processing-checklist","dir":"Articles","previous_headings":"","what":"Pre-processing Checklist","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"surveys: Check missing data catch effort Verify effort > 0 interviews Check outliers (data entry errors) ROVING surveys specifically: Truncate short trips (< 20-30 minutes) Check bag limit compliance (may cause bias) Verify catch rate stationarity (possible)","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"variance-estimation-checklist","dir":"Articles","previous_headings":"","what":"Variance Estimation Checklist","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Use proper survey weights svydesign() Include stratification variables Use svyratio() ratio--means Use svymean() catch/effort ratio mean--ratios Report standard errors confidence intervals","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Pollock, K.H., Hoenig, J.M., Jones, C.M., Robson, D.S., & Greene, C.J. (1997). Catch rate estimation roving access point surveys. North American Journal Fisheries Management, 17(1), 11-19. Rasmussen, P.W., Staggs, M.D., Beard, T.D., & Newman, S.P. (1998). Bias confidence interval coverage creel survey estimators evaluated simulation. Transactions American Fisheries Society, 127(3), 469-480. Jones, C.M., Robson, D.S., Lakkis, H.D., & Kressel, J. (1995). Properties catch rates used analysis angler surveys. Transactions American Fisheries Society, 124(6), 911-928. Lumley, T. (2004). Analysis complex survey samples. Journal Statistical Software, 9(1), 1-19.","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"choice ratio--means mean--ratios depends fundamentally survey design: Access point interviews → Use ratio--means Roving interviews → Use mean--ratios truncation tidycreel package implements estimators proper variance estimation survey package. following decision rules vignette, can ensure catch rate estimates unbiased confidence intervals correct coverage.","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"introduction-1","dir":"Articles","previous_headings":"","what":"Introduction","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"One common questions creel survey analysis : “use ratio--means mean--ratios estimate catch rate?” vignette answers question : Decision rules based survey design type Simulation demonstrations showing estimator performance Practical guidance variance estimation Clear examples using tidycreel","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"quick-answer-decision-tree-1","dir":"Articles","previous_headings":"","what":"Quick Answer: Decision Tree","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"","code":"┌─────────────────────────────────────────────┐ │   What type of interviews do you have?      │ └─────────────────┬───────────────────────────┘                   │         ┌─────────┴─────────┐         │                   │     ┌───▼──────┐          ┌───▼────────┐     │ ACCESS   │          │ ROVING     │     │(Complete │          │(Incomplete │     │ trips)   │          │  trips)    │     └───┬──────┘          └───┬────────┘         │                     │         │                     │     ┌───▼─────────────────┐   │     │ Use RATIO-OF-MEANS  │   │     │  R₁ = Σcatch/Σeffort│   │     │                     │   │     │ Why? Each angler    │   │     │ has equal sampling  │   │     │ probability.        │   │     │                     │   │     │ ✓ Unbiased          │   │     │ ✓ Finite variance   │   │     └─────────────────────┘   │                               │                   ┌───────────▼────────────────┐                   │ Use MEAN-OF-RATIOS         │                   │  R₂ = (1/n)Σ(catch/effort) │                   │                            │                   │ IMPORTANT: Truncate short  │                   │ trips (< 20-30 minutes)    │                   │                            │                   │ Why? Sampling probability  │                   │ ∝ trip length. R₁ would    │                   │ give biased estimate.      │                   │                            │                   │ ⚠ Avoid if bag limits      │                   │   are low & easily obtained│                   └────────────────────────────┘"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"theoretical-background-1","dir":"Articles","previous_headings":"","what":"Theoretical Background","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Sampling Design: Interviews conducted anglers complete trips anglers equal probability interviewed P(interviewed) = constant, regardless trip length Appropriate Estimator: Ratio--Means (R₁) [_1 = ] (C_j^) = total catch completed trip (L_j^) = total trip length completion. Expected Value: [E(_1) ] ✓ want total catch estimation! Sampling Design: Interviews conducted fishing trips Sampling probability ∝ trip length Longer trips likely encountered Appropriate Estimator: Mean--Ratios (R₂) Truncation [2 = {j=1}^{n} ] (C_j) = catch time interview (L_j) = elapsed time interview. truncation: include interviews (L_j > L_{min}) (typically 20-30 minutes). Expected Value: [E(_2) ] ✓ Correct roving interviews! use R₁ roving? ratio--means roving interviews : [E(_1^{roving}) ] weighted average weights = (trip length)², estimate population catch rate! matters: Real creel surveys often produce mix completed (access-point) incomplete (roving/intercept) interviews. Estimator choice must follow inclusion probability, just trip status, avoid bias. inclusion probability differs design (equal-probability access points vs. length-biased roving), pooling interviews applying single estimator can introduce bias. Treat designs according sampling properties. Treat complete incomplete interviews two strata, combine effort weighting: Complete trips (access point): use Ratio--Means (R₁ = ΣC / ΣE). Incomplete trips (roving): use Mean--Ratios (R₂ = (1/n) Σ(C/E)) truncation short trips (e.g., < 20–30 min). Effort-weighted combination: R̂combined=R1Ecomplete+R2EincompleteEcomplete+Eincomplete \\hat{R}_{\\text{combined}} = \\frac{R_1 E_{\\text{complete}} + R_2 E_{\\text{incomplete}}}{E_{\\text{complete}} + E_{\\text{incomplete}}} can estimate selection/inclusion probabilities (e.g., model trip completeness roving intercept likelihood), use weighted ratio: R̂weighted=∑iwiCi∑iwiEi,wi=1/P(selecti). \\hat{R}_{\\text{weighted}} = \\frac{\\sum_i w_i C_i}{\\sum_i w_i E_i}, \\quad w_i = 1 / P(\\text{select}_i). useful hybrid designs sampling varies predictably across modes, times, sites. Compute: () R₁ complete , (b) R₂ incomplete (truncation), (c) combined estimator. differences small (e.g., < 5–10%), pooling assumptions may reasonable; document . apply R₁ unfiltered roving data — biased high due length-biased sampling. apply R₂ complete trips — bias direction depends effort variability. Always truncate short incomplete trips stabilize R₂ reduce small-denominator issues. bag limits frequently hit, cautious R₂ (ceiling effects can distort ratios). Estimate SEs stratum appropriate formula (delta-method R₁; sample variance ratios R₂), combine via delta-method using effort-weight combination .","code":"complete <- data %>% dplyr::filter(trip_complete == TRUE) incomplete <- data %>% dplyr::filter(trip_complete == FALSE, trip_length >= 0.5)  # 0.5 h = 30 min  r1 <- sum(complete$catch) / sum(complete$effort) r2 <- mean(incomplete$catch / incomplete$effort)  E1 <- sum(complete$effort) E2 <- sum(incomplete$effort)  R_combined <- (r1 * E1 + r2 * E2) / (E1 + E2)"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"access-point-complete-trip-interviews-1","dir":"Articles","previous_headings":"","what":"Access Point (Complete Trip) Interviews","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Sampling Design: Interviews conducted anglers complete trips anglers equal probability interviewed P(interviewed) = constant, regardless trip length Appropriate Estimator: Ratio--Means (R₁) [_1 = ] (C_j^) = total catch completed trip (L_j^) = total trip length completion. Expected Value: [E(_1) ] ✓ want total catch estimation!","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"roving-incomplete-trip-interviews-1","dir":"Articles","previous_headings":"","what":"Roving (Incomplete Trip) Interviews","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Sampling Design: Interviews conducted fishing trips Sampling probability ∝ trip length Longer trips likely encountered Appropriate Estimator: Mean--Ratios (R₂) Truncation [2 = {j=1}^{n} ] (C_j) = catch time interview (L_j) = elapsed time interview. truncation: include interviews (L_j > L_{min}) (typically 20-30 minutes). Expected Value: [E(_2) ] ✓ Correct roving interviews! use R₁ roving? ratio--means roving interviews : [E(_1^{roving}) ] weighted average weights = (trip length)², estimate population catch rate!","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"handling-mixed-complete-and-incomplete-trips-8","dir":"Articles","previous_headings":"","what":"Handling Mixed Complete and Incomplete Trips","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"matters: Real creel surveys often produce mix completed (access-point) incomplete (roving/intercept) interviews. Estimator choice must follow inclusion probability, just trip status, avoid bias. inclusion probability differs design (equal-probability access points vs. length-biased roving), pooling interviews applying single estimator can introduce bias. Treat designs according sampling properties. Treat complete incomplete interviews two strata, combine effort weighting: Complete trips (access point): use Ratio--Means (R₁ = ΣC / ΣE). Incomplete trips (roving): use Mean--Ratios (R₂ = (1/n) Σ(C/E)) truncation short trips (e.g., < 20–30 min). Effort-weighted combination: R̂combined=R1Ecomplete+R2EincompleteEcomplete+Eincomplete \\hat{R}_{\\text{combined}} = \\frac{R_1 E_{\\text{complete}} + R_2 E_{\\text{incomplete}}}{E_{\\text{complete}} + E_{\\text{incomplete}}} can estimate selection/inclusion probabilities (e.g., model trip completeness roving intercept likelihood), use weighted ratio: R̂weighted=∑iwiCi∑iwiEi,wi=1/P(selecti). \\hat{R}_{\\text{weighted}} = \\frac{\\sum_i w_i C_i}{\\sum_i w_i E_i}, \\quad w_i = 1 / P(\\text{select}_i). useful hybrid designs sampling varies predictably across modes, times, sites. Compute: () R₁ complete , (b) R₂ incomplete (truncation), (c) combined estimator. differences small (e.g., < 5–10%), pooling assumptions may reasonable; document . apply R₁ unfiltered roving data — biased high due length-biased sampling. apply R₂ complete trips — bias direction depends effort variability. Always truncate short incomplete trips stabilize R₂ reduce small-denominator issues. bag limits frequently hit, cautious R₂ (ceiling effects can distort ratios). Estimate SEs stratum appropriate formula (delta-method R₁; sample variance ratios R₂), combine via delta-method using effort-weight combination .","code":"complete <- data %>% dplyr::filter(trip_complete == TRUE) incomplete <- data %>% dplyr::filter(trip_complete == FALSE, trip_length >= 0.5)  # 0.5 h = 30 min  r1 <- sum(complete$catch) / sum(complete$effort) r2 <- mean(incomplete$catch / incomplete$effort)  E1 <- sum(complete$effort) E2 <- sum(incomplete$effort)  R_combined <- (r1 * E1 + r2 * E2) / (E1 + E2)"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"simulation-study-1","dir":"Articles","previous_headings":"","what":"Simulation Study","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"theoretical results show estimator choice matters. large bias practice? truncation really help? Let’s demonstrate principles simulation, following approach Rasmussen et al. (1998) Pollock et al. (1997). ’ll simulate realistic fishing scenario compare estimator performance. Simulate traditional access point creel interview anglers finish. Now simulate roving interviews anglers intercepted trips. Run 1000 replications assess bias precision. Access Point Design: Estimator Performance Key Finding: access interviews, estimators approximately unbiased, ratio--means (R₁) typically slightly lower variance.  Access Point Design: Distribution Estimates. estimators center true value (dashed line), demonstrating unbiasedness. ratio--means (R₁) shows slightly tighter clustering, indicating lower variance. Roving Design: Estimator Performance Key Findings: R₁ (ratio--means) BIASED roving interviews - estimate population catch rate R₂ (mean--ratios) without truncation approximately unbiased high variance (unstable) R₂ truncation approximately unbiased lower variance ✓ RECOMMENDED  Roving Design: Effect Truncation. R₁ (ratio--means) biased roving surveys regardless truncation. R₂ (mean--ratios) unbiased high variance without truncation; truncation reduces variance maintaining unbiasedness.","code":"#' Simulate a day of fishing with known parameters #' #' @param n_anglers Number of anglers fishing during the day #' @param mean_trip_hours Mean trip length (hours) #' @param mean_catch_rate Mean catch per hour (Poisson rate parameter) #' @param day_length_hours Length of fishing day #' @return List with population parameters and individual angler data simulate_fishing_day <- function(n_anglers = 100,                                  mean_trip_hours = 4,                                  mean_catch_rate = 2,                                  day_length_hours = 12) {    # Each angler's true catch rate (gamma-distributed for heterogeneity)   # Shape = 1, rate = 1/mean gives exponential with specified mean   # This creates variation in angler skill/success   alpha <- 1   beta <- 1 / mean_catch_rate   catch_rates <- rgamma(n_anglers, shape = alpha, rate = beta)    # Trip lengths (gamma-distributed)   shape_trip <- 4  # Controls variability   rate_trip <- shape_trip / mean_trip_hours   trip_lengths <- rgamma(n_anglers, shape = shape_trip, rate = rate_trip)   trip_lengths <- pmin(trip_lengths, day_length_hours)  # Can't exceed day length    # Generate catches for each angler (Poisson process)   # Expected catch = catch_rate * trip_length   completed_catch <- rpois(n_anglers, lambda = catch_rates * trip_lengths)    # True population parameters   total_effort <- sum(trip_lengths)   total_catch <- sum(completed_catch)   true_catch_rate <- total_catch / total_effort    # Return angler-level data   tibble(     angler_id = 1:n_anglers,     catch_rate_true = catch_rates,     trip_length = trip_lengths,     completed_catch = completed_catch,     true_population_rate = true_catch_rate,     total_effort = total_effort,     total_catch = total_catch   ) }  # Example fishing_day <- simulate_fishing_day(n_anglers = 100) head(fishing_day) # A tibble: 6 × 7   angler_id catch_rate_true trip_length completed_catch true_population_rate       <int>           <dbl>       <dbl>           <int>                <dbl> 1         1           2.00         4.78               7                 2.15 2         2           2.26         1.56               5                 2.15 3         3           0.851        4.74               4                 2.15 4         4           1.03         6.06               5                 2.15 5         5           6.96         4.52              35                 2.15 6         6           0.627        5.59               3                 2.15 # ℹ 2 more variables: total_effort <dbl>, total_catch <int> # Summary of true population parameters cat(\"True Population Parameters:\\n\") True Population Parameters: cat(\"  Total anglers:\", nrow(fishing_day), \"\\n\") Total anglers: 100 cat(\"  Total effort:\", round(fishing_day$total_effort[1], 1), \"hours\\n\") Total effort: 391.8 hours cat(\"  Total catch:\", fishing_day$total_catch[1], \"fish\\n\") Total catch: 844 fish cat(\"  True catch rate:\", round(fishing_day$true_population_rate[1], 3), \"fish/hour\\n\") True catch rate: 2.154 fish/hour #' Simulate access point interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Number of interviews to conduct #' @return Tibble with interview data sample_access_interviews <- function(fishing_day, n_interviews = 30) {   # Simple random sample (equal probability)   sampled <- fishing_day %>%     sample_n(size = min(n_interviews, nrow(fishing_day)), replace = FALSE) %>%     select(angler_id, completed_catch, trip_length, true_population_rate)    sampled }  # Single realization access_sample <- sample_access_interviews(fishing_day, n_interviews = 30) head(access_sample) # A tibble: 6 × 4   angler_id completed_catch trip_length true_population_rate       <int>           <int>       <dbl>                <dbl> 1         1               7        4.78                 2.15 2        69               4        5.05                 2.15 3        79              14        6.27                 2.15 4        19               5        6.75                 2.15 5        12               1        4.72                 2.15 6        64               0        5.88                 2.15 # Calculate both estimators calculate_estimates <- function(interviews, truncate_minutes = NULL) {    # Apply truncation if specified (for roving surveys)   if (!is.null(truncate_minutes)) {     interviews <- interviews %>%       filter(trip_length >= truncate_minutes / 60)   }    n <- nrow(interviews)    # Ratio-of-means   r1 <- sum(interviews$completed_catch) / sum(interviews$trip_length)    # Mean-of-ratios   r2 <- mean(interviews$completed_catch / interviews$trip_length)    # Variance estimates (simplified)   # For R1: use delta method (Taylor series approximation)   # Var(R₁) ≈ (1/n·E̅²) · Var(C - R₁·E)   # where residual = catch - estimated_rate × effort   r <- interviews$completed_catch   e <- interviews$trip_length   r_bar <- mean(r)   e_bar <- mean(e)   var_r1 <- (1 / (n * e_bar^2)) * var(r - r1 * e)   se_r1 <- sqrt(var_r1)    # For R2: simple variance of the ratios   ratios <- interviews$completed_catch / interviews$trip_length   var_r2 <- var(ratios) / n   se_r2 <- sqrt(var_r2)    tibble(     n = n,     ratio_of_means = r1,     mean_of_ratios = r2,     se_r1 = se_r1,     se_r2 = se_r2,     true_rate = interviews$true_population_rate[1]   ) }  access_results <- calculate_estimates(access_sample) access_results # A tibble: 1 × 6       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> 1    30           2.04           2.41 0.401 0.463      2.15 #' Simulate roving interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Target number of interviews #' @return Tibble with incomplete trip interview data sample_roving_interviews <- function(fishing_day, n_interviews = 30) {    # Length-biased sampling: probability of encounter ∝ trip duration   # P(interview angler i) = L_i / Σ L_j (normalized by total effort)   # Longer trips have higher chance of being encountered during roving   prob_intercept <- fishing_day$trip_length / sum(fishing_day$trip_length)    # Sample with probability proportional to size   sampled_indices <- sample(     1:nrow(fishing_day),     size = min(n_interviews, nrow(fishing_day)),     replace = FALSE,     prob = prob_intercept   )    sampled <- fishing_day[sampled_indices, ]    # For each intercepted angler, determine interview time   # Uniform on [0, trip_length] (on average, intercepted at midpoint)   sampled <- sampled %>%     mutate(       # Time fished when interviewed (uniform on [0, trip_length])       # On average, anglers are intercepted at midpoint of their trip       time_at_interview = runif(n(), min = 0, max = trip_length),        # Catch at interview time (incomplete trip)       # Poisson process: E[catch | time_t] = λ × t       # where λ = angler's true catch rate, t = time fished so far       catch_at_interview = rpois(n(), lambda = catch_rate_true * time_at_interview)     ) %>%     select(angler_id, catch_at_interview, time_at_interview,            completed_catch, trip_length, true_population_rate)    sampled }  roving_sample <- sample_roving_interviews(fishing_day, n_interviews = 30) head(roving_sample) # A tibble: 6 × 6   angler_id catch_at_interview time_at_interview completed_catch trip_length       <int>              <int>             <dbl>           <int>       <dbl> 1        27                  1             2.57                2        5.27 2        37                  4             1.46               13        2.99 3        81                  0             0.326               3        3.86 4        32                  1             2.30                8        5.76 5        97                  6             3.54               10        4.81 6        28                  4             2.58                5        2.72 # ℹ 1 more variable: true_population_rate <dbl> # For roving, use incomplete data # Note: calculate_estimates() expects columns named 'completed_catch' and 'trip_length' roving_data <- roving_sample %>%   select(angler_id,          completed_catch = catch_at_interview,          trip_length = time_at_interview,          true_population_rate)  # No truncation roving_no_trunc <- calculate_estimates(roving_data, truncate_minutes = NULL)  # With truncation (30 minutes) roving_with_trunc <- calculate_estimates(roving_data, truncate_minutes = 30)  bind_rows(   roving_no_trunc %>% mutate(truncation = \"None\"),   roving_with_trunc %>% mutate(truncation = \"30 min\") ) # A tibble: 2 × 7       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate truncation   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> <chr> 1    30           1.98           1.77 0.329 0.289      2.15 None 2    27           1.97           1.67 0.334 0.281      2.15 30 min run_simulation <- function(n_reps = 1000,                            n_anglers = 100,                            n_interviews = 30,                            interview_type = c(\"access\", \"roving\")) {    interview_type <- match.arg(interview_type)    results <- map_dfr(1:n_reps, function(rep) {     # Generate population     day <- simulate_fishing_day(n_anglers = n_anglers)     true_rate <- day$true_population_rate[1]      # Sample based on design     if (interview_type == \"access\") {       sample_data <- sample_access_interviews(day, n_interviews)       sample_data <- sample_data %>%         rename(catch = completed_catch, effort = trip_length)     } else {       sample_data <- sample_roving_interviews(day, n_interviews) %>%         rename(catch = catch_at_interview, effort = time_at_interview)     }      # Calculate estimators     # No truncation     r1_no <- sum(sample_data$catch) / sum(sample_data$effort)     r2_no <- mean(sample_data$catch / sample_data$effort)      # With truncation (30 min = 0.5 hr)     trunc_data <- sample_data %>% filter(effort >= 0.5)     if (nrow(trunc_data) > 0) {       r1_trunc <- sum(trunc_data$catch) / sum(trunc_data$effort)       r2_trunc <- mean(trunc_data$catch / trunc_data$effort)     } else {       r1_trunc <- NA       r2_trunc <- NA     }      tibble(       rep = rep,       true_rate = true_rate,       r1_no_trunc = r1_no,       r2_no_trunc = r2_no,       r1_with_trunc = r1_trunc,       r2_with_trunc = r2_trunc,       n_interviews = n_interviews,       n_after_trunc = nrow(trunc_data)     )   })    results %>%     mutate(design = interview_type) }  # Run simulations access_mc <- run_simulation(n_reps = 1000, interview_type = \"access\") roving_mc <- run_simulation(n_reps = 1000, interview_type = \"roving\") # Summary statistics access_summary <- access_mc %>%   summarise(     true_rate = mean(true_rate),      # Ratio of means (R1)     r1_mean = mean(r1_no_trunc),     r1_bias = mean(r1_no_trunc - true_rate),     r1_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate),     r1_rmse = sqrt(mean((r1_no_trunc - true_rate)^2)),     r1_se = sd(r1_no_trunc),      # Mean of ratios (R2)     r2_mean = mean(r2_no_trunc),     r2_bias = mean(r2_no_trunc - true_rate),     r2_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate),     r2_rmse = sqrt(mean((r2_no_trunc - true_rate)^2)),     r2_se = sd(r2_no_trunc)   )  access_summary %>%   pivot_longer(cols = -true_rate, names_to = c(\"estimator\", \"metric\"), names_sep = \"_\", values_to = \"value\", names_repair = \"minimal\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   select(estimator, mean, bias, pct, se, rmse) %>%   rename(pct_bias = pct) %>%   knitr::kable(digits = 4, caption = \"Access Point Design: Estimator Performance\") access_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc) %>%   pivot_longer(cols = c(r1_no_trunc, r2_no_trunc),                names_to = \"estimator\",                values_to = \"estimate\") %>%   mutate(estimator = recode(estimator,                             r1_no_trunc = \"Ratio of Means (R₁)\",                             r2_no_trunc = \"Mean of Ratios (R₂)\")) %>%   ggplot(aes(x = estimate, fill = estimator)) +   geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +   geom_vline(aes(xintercept = mean(true_rate)), linetype = \"dashed\", size = 1) +   facet_wrap(~estimator, ncol = 1) +   labs(title = \"Access Point Design: Sampling Distribution\",        subtitle = \"Dashed line = true population catch rate\",        x = \"Estimated Catch Rate (fish/hour)\",        y = \"Frequency\") +   theme_minimal() +   theme(legend.position = \"none\") # Summary statistics roving_summary <- roving_mc %>%   summarise(     true_rate = mean(true_rate),      # R1 no truncation     r1_no_mean = mean(r1_no_trunc, na.rm = TRUE),     r1_no_bias = mean(r1_no_trunc - true_rate, na.rm = TRUE),     r1_no_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_no_rmse = sqrt(mean((r1_no_trunc - true_rate)^2, na.rm = TRUE)),      # R2 no truncation     r2_no_mean = mean(r2_no_trunc, na.rm = TRUE),     r2_no_bias = mean(r2_no_trunc - true_rate, na.rm = TRUE),     r2_no_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_no_rmse = sqrt(mean((r2_no_trunc - true_rate)^2, na.rm = TRUE)),      # R1 with truncation     r1_trunc_mean = mean(r1_with_trunc, na.rm = TRUE),     r1_trunc_bias = mean(r1_with_trunc - true_rate, na.rm = TRUE),     r1_trunc_pct_bias = 100 * mean((r1_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_trunc_rmse = sqrt(mean((r1_with_trunc - true_rate)^2, na.rm = TRUE)),      # R2 with truncation     r2_trunc_mean = mean(r2_with_trunc, na.rm = TRUE),     r2_trunc_bias = mean(r2_with_trunc - true_rate, na.rm = TRUE),     r2_trunc_pct_bias = 100 * mean((r2_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_trunc_rmse = sqrt(mean((r2_with_trunc - true_rate)^2, na.rm = TRUE))   )  roving_summary %>%   pivot_longer(cols = -true_rate,                names_to = c(\"estimator\", \"truncation\", \"metric\"),                names_pattern = \"([^_]+)_([^_]+)_(.*)\",                values_to = \"value\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   mutate(estimator = recode(estimator, r1 = \"Ratio of Means\", r2 = \"Mean of Ratios\"),          truncation = recode(truncation, no = \"No truncation\", trunc = \"30-min truncation\")) %>%   select(estimator, truncation, mean, bias, pct_bias, rmse) %>%   knitr::kable(digits = 4, caption = \"Roving Design: Estimator Performance\") roving_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc, r1_with_trunc, r2_with_trunc) %>%   pivot_longer(cols = -c(rep, true_rate),                names_to = \"estimator\",                values_to = \"estimate\") %>%   filter(!is.na(estimate)) %>%   mutate(     estimator_type = ifelse(grepl(\"r1\", estimator), \"Ratio of Means (R₁)\", \"Mean of Ratios (R₂)\"),     truncation = ifelse(grepl(\"no_trunc\", estimator), \"No Truncation\", \"30-Min Truncation\")   ) %>%   ggplot(aes(x = estimate, fill = truncation)) +   geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +   geom_vline(aes(xintercept = mean(true_rate)), linetype = \"dashed\", size = 1) +   facet_grid(estimator_type ~ truncation, scales = \"free_y\") +   labs(title = \"Roving Design: Impact of Estimator Choice and Truncation\",        subtitle = \"Dashed line = true population catch rate\",        x = \"Estimated Catch Rate (fish/hour)\",        y = \"Frequency\",        fill = \"Truncation\") +   theme_minimal() +   theme(legend.position = \"bottom\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"simulation-setup-1","dir":"Articles","previous_headings":"","what":"Simulation Setup","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"’ll simulate realistic fishing scenario compare estimator performance.","code":"#' Simulate a day of fishing with known parameters #' #' @param n_anglers Number of anglers fishing during the day #' @param mean_trip_hours Mean trip length (hours) #' @param mean_catch_rate Mean catch per hour (Poisson rate parameter) #' @param day_length_hours Length of fishing day #' @return List with population parameters and individual angler data simulate_fishing_day <- function(n_anglers = 100,                                  mean_trip_hours = 4,                                  mean_catch_rate = 2,                                  day_length_hours = 12) {    # Each angler's true catch rate (gamma-distributed for heterogeneity)   # Shape = 1, rate = 1/mean gives exponential with specified mean   # This creates variation in angler skill/success   alpha <- 1   beta <- 1 / mean_catch_rate   catch_rates <- rgamma(n_anglers, shape = alpha, rate = beta)    # Trip lengths (gamma-distributed)   shape_trip <- 4  # Controls variability   rate_trip <- shape_trip / mean_trip_hours   trip_lengths <- rgamma(n_anglers, shape = shape_trip, rate = rate_trip)   trip_lengths <- pmin(trip_lengths, day_length_hours)  # Can't exceed day length    # Generate catches for each angler (Poisson process)   # Expected catch = catch_rate * trip_length   completed_catch <- rpois(n_anglers, lambda = catch_rates * trip_lengths)    # True population parameters   total_effort <- sum(trip_lengths)   total_catch <- sum(completed_catch)   true_catch_rate <- total_catch / total_effort    # Return angler-level data   tibble(     angler_id = 1:n_anglers,     catch_rate_true = catch_rates,     trip_length = trip_lengths,     completed_catch = completed_catch,     true_population_rate = true_catch_rate,     total_effort = total_effort,     total_catch = total_catch   ) }  # Example fishing_day <- simulate_fishing_day(n_anglers = 100) head(fishing_day) # A tibble: 6 × 7   angler_id catch_rate_true trip_length completed_catch true_population_rate       <int>           <dbl>       <dbl>           <int>                <dbl> 1         1           2.00         4.78               7                 2.15 2         2           2.26         1.56               5                 2.15 3         3           0.851        4.74               4                 2.15 4         4           1.03         6.06               5                 2.15 5         5           6.96         4.52              35                 2.15 6         6           0.627        5.59               3                 2.15 # ℹ 2 more variables: total_effort <dbl>, total_catch <int> # Summary of true population parameters cat(\"True Population Parameters:\\n\") True Population Parameters: cat(\"  Total anglers:\", nrow(fishing_day), \"\\n\") Total anglers: 100 cat(\"  Total effort:\", round(fishing_day$total_effort[1], 1), \"hours\\n\") Total effort: 391.8 hours cat(\"  Total catch:\", fishing_day$total_catch[1], \"fish\\n\") Total catch: 844 fish cat(\"  True catch rate:\", round(fishing_day$true_population_rate[1], 3), \"fish/hour\\n\") True catch rate: 2.154 fish/hour"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"scenario-1-access-point-interviews-complete-trips-1","dir":"Articles","previous_headings":"","what":"Scenario 1: Access Point Interviews (Complete Trips)","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Simulate traditional access point creel interview anglers finish.","code":"#' Simulate access point interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Number of interviews to conduct #' @return Tibble with interview data sample_access_interviews <- function(fishing_day, n_interviews = 30) {   # Simple random sample (equal probability)   sampled <- fishing_day %>%     sample_n(size = min(n_interviews, nrow(fishing_day)), replace = FALSE) %>%     select(angler_id, completed_catch, trip_length, true_population_rate)    sampled }  # Single realization access_sample <- sample_access_interviews(fishing_day, n_interviews = 30) head(access_sample) # A tibble: 6 × 4   angler_id completed_catch trip_length true_population_rate       <int>           <int>       <dbl>                <dbl> 1         1               7        4.78                 2.15 2        69               4        5.05                 2.15 3        79              14        6.27                 2.15 4        19               5        6.75                 2.15 5        12               1        4.72                 2.15 6        64               0        5.88                 2.15 # Calculate both estimators calculate_estimates <- function(interviews, truncate_minutes = NULL) {    # Apply truncation if specified (for roving surveys)   if (!is.null(truncate_minutes)) {     interviews <- interviews %>%       filter(trip_length >= truncate_minutes / 60)   }    n <- nrow(interviews)    # Ratio-of-means   r1 <- sum(interviews$completed_catch) / sum(interviews$trip_length)    # Mean-of-ratios   r2 <- mean(interviews$completed_catch / interviews$trip_length)    # Variance estimates (simplified)   # For R1: use delta method (Taylor series approximation)   # Var(R₁) ≈ (1/n·E̅²) · Var(C - R₁·E)   # where residual = catch - estimated_rate × effort   r <- interviews$completed_catch   e <- interviews$trip_length   r_bar <- mean(r)   e_bar <- mean(e)   var_r1 <- (1 / (n * e_bar^2)) * var(r - r1 * e)   se_r1 <- sqrt(var_r1)    # For R2: simple variance of the ratios   ratios <- interviews$completed_catch / interviews$trip_length   var_r2 <- var(ratios) / n   se_r2 <- sqrt(var_r2)    tibble(     n = n,     ratio_of_means = r1,     mean_of_ratios = r2,     se_r1 = se_r1,     se_r2 = se_r2,     true_rate = interviews$true_population_rate[1]   ) }  access_results <- calculate_estimates(access_sample) access_results # A tibble: 1 × 6       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> 1    30           2.04           2.41 0.401 0.463      2.15"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"scenario-2-roving-interviews-incomplete-trips-1","dir":"Articles","previous_headings":"","what":"Scenario 2: Roving Interviews (Incomplete Trips)","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Now simulate roving interviews anglers intercepted trips.","code":"#' Simulate roving interviews #' #' @param fishing_day Tibble from simulate_fishing_day() #' @param n_interviews Target number of interviews #' @return Tibble with incomplete trip interview data sample_roving_interviews <- function(fishing_day, n_interviews = 30) {    # Length-biased sampling: probability of encounter ∝ trip duration   # P(interview angler i) = L_i / Σ L_j (normalized by total effort)   # Longer trips have higher chance of being encountered during roving   prob_intercept <- fishing_day$trip_length / sum(fishing_day$trip_length)    # Sample with probability proportional to size   sampled_indices <- sample(     1:nrow(fishing_day),     size = min(n_interviews, nrow(fishing_day)),     replace = FALSE,     prob = prob_intercept   )    sampled <- fishing_day[sampled_indices, ]    # For each intercepted angler, determine interview time   # Uniform on [0, trip_length] (on average, intercepted at midpoint)   sampled <- sampled %>%     mutate(       # Time fished when interviewed (uniform on [0, trip_length])       # On average, anglers are intercepted at midpoint of their trip       time_at_interview = runif(n(), min = 0, max = trip_length),        # Catch at interview time (incomplete trip)       # Poisson process: E[catch | time_t] = λ × t       # where λ = angler's true catch rate, t = time fished so far       catch_at_interview = rpois(n(), lambda = catch_rate_true * time_at_interview)     ) %>%     select(angler_id, catch_at_interview, time_at_interview,            completed_catch, trip_length, true_population_rate)    sampled }  roving_sample <- sample_roving_interviews(fishing_day, n_interviews = 30) head(roving_sample) # A tibble: 6 × 6   angler_id catch_at_interview time_at_interview completed_catch trip_length       <int>              <int>             <dbl>           <int>       <dbl> 1        27                  1             2.57                2        5.27 2        37                  4             1.46               13        2.99 3        81                  0             0.326               3        3.86 4        32                  1             2.30                8        5.76 5        97                  6             3.54               10        4.81 6        28                  4             2.58                5        2.72 # ℹ 1 more variable: true_population_rate <dbl> # For roving, use incomplete data # Note: calculate_estimates() expects columns named 'completed_catch' and 'trip_length' roving_data <- roving_sample %>%   select(angler_id,          completed_catch = catch_at_interview,          trip_length = time_at_interview,          true_population_rate)  # No truncation roving_no_trunc <- calculate_estimates(roving_data, truncate_minutes = NULL)  # With truncation (30 minutes) roving_with_trunc <- calculate_estimates(roving_data, truncate_minutes = 30)  bind_rows(   roving_no_trunc %>% mutate(truncation = \"None\"),   roving_with_trunc %>% mutate(truncation = \"30 min\") ) # A tibble: 2 × 7       n ratio_of_means mean_of_ratios se_r1 se_r2 true_rate truncation   <int>          <dbl>          <dbl> <dbl> <dbl>     <dbl> <chr> 1    30           1.98           1.77 0.329 0.289      2.15 None 2    27           1.97           1.67 0.334 0.281      2.15 30 min"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"monte-carlo-simulation-1","dir":"Articles","previous_headings":"","what":"Monte Carlo Simulation","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Run 1000 replications assess bias precision.","code":"run_simulation <- function(n_reps = 1000,                            n_anglers = 100,                            n_interviews = 30,                            interview_type = c(\"access\", \"roving\")) {    interview_type <- match.arg(interview_type)    results <- map_dfr(1:n_reps, function(rep) {     # Generate population     day <- simulate_fishing_day(n_anglers = n_anglers)     true_rate <- day$true_population_rate[1]      # Sample based on design     if (interview_type == \"access\") {       sample_data <- sample_access_interviews(day, n_interviews)       sample_data <- sample_data %>%         rename(catch = completed_catch, effort = trip_length)     } else {       sample_data <- sample_roving_interviews(day, n_interviews) %>%         rename(catch = catch_at_interview, effort = time_at_interview)     }      # Calculate estimators     # No truncation     r1_no <- sum(sample_data$catch) / sum(sample_data$effort)     r2_no <- mean(sample_data$catch / sample_data$effort)      # With truncation (30 min = 0.5 hr)     trunc_data <- sample_data %>% filter(effort >= 0.5)     if (nrow(trunc_data) > 0) {       r1_trunc <- sum(trunc_data$catch) / sum(trunc_data$effort)       r2_trunc <- mean(trunc_data$catch / trunc_data$effort)     } else {       r1_trunc <- NA       r2_trunc <- NA     }      tibble(       rep = rep,       true_rate = true_rate,       r1_no_trunc = r1_no,       r2_no_trunc = r2_no,       r1_with_trunc = r1_trunc,       r2_with_trunc = r2_trunc,       n_interviews = n_interviews,       n_after_trunc = nrow(trunc_data)     )   })    results %>%     mutate(design = interview_type) }  # Run simulations access_mc <- run_simulation(n_reps = 1000, interview_type = \"access\") roving_mc <- run_simulation(n_reps = 1000, interview_type = \"roving\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"results-access-point-design-1","dir":"Articles","previous_headings":"","what":"Results: Access Point Design","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Access Point Design: Estimator Performance Key Finding: access interviews, estimators approximately unbiased, ratio--means (R₁) typically slightly lower variance.  Access Point Design: Distribution Estimates. estimators center true value (dashed line), demonstrating unbiasedness. ratio--means (R₁) shows slightly tighter clustering, indicating lower variance.","code":"# Summary statistics access_summary <- access_mc %>%   summarise(     true_rate = mean(true_rate),      # Ratio of means (R1)     r1_mean = mean(r1_no_trunc),     r1_bias = mean(r1_no_trunc - true_rate),     r1_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate),     r1_rmse = sqrt(mean((r1_no_trunc - true_rate)^2)),     r1_se = sd(r1_no_trunc),      # Mean of ratios (R2)     r2_mean = mean(r2_no_trunc),     r2_bias = mean(r2_no_trunc - true_rate),     r2_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate),     r2_rmse = sqrt(mean((r2_no_trunc - true_rate)^2)),     r2_se = sd(r2_no_trunc)   )  access_summary %>%   pivot_longer(cols = -true_rate, names_to = c(\"estimator\", \"metric\"), names_sep = \"_\", values_to = \"value\", names_repair = \"minimal\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   select(estimator, mean, bias, pct, se, rmse) %>%   rename(pct_bias = pct) %>%   knitr::kable(digits = 4, caption = \"Access Point Design: Estimator Performance\") access_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc) %>%   pivot_longer(cols = c(r1_no_trunc, r2_no_trunc),                names_to = \"estimator\",                values_to = \"estimate\") %>%   mutate(estimator = recode(estimator,                             r1_no_trunc = \"Ratio of Means (R₁)\",                             r2_no_trunc = \"Mean of Ratios (R₂)\")) %>%   ggplot(aes(x = estimate, fill = estimator)) +   geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +   geom_vline(aes(xintercept = mean(true_rate)), linetype = \"dashed\", size = 1) +   facet_wrap(~estimator, ncol = 1) +   labs(title = \"Access Point Design: Sampling Distribution\",        subtitle = \"Dashed line = true population catch rate\",        x = \"Estimated Catch Rate (fish/hour)\",        y = \"Frequency\") +   theme_minimal() +   theme(legend.position = \"none\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"results-roving-design-1","dir":"Articles","previous_headings":"","what":"Results: Roving Design","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Roving Design: Estimator Performance Key Findings: R₁ (ratio--means) BIASED roving interviews - estimate population catch rate R₂ (mean--ratios) without truncation approximately unbiased high variance (unstable) R₂ truncation approximately unbiased lower variance ✓ RECOMMENDED  Roving Design: Effect Truncation. R₁ (ratio--means) biased roving surveys regardless truncation. R₂ (mean--ratios) unbiased high variance without truncation; truncation reduces variance maintaining unbiasedness.","code":"# Summary statistics roving_summary <- roving_mc %>%   summarise(     true_rate = mean(true_rate),      # R1 no truncation     r1_no_mean = mean(r1_no_trunc, na.rm = TRUE),     r1_no_bias = mean(r1_no_trunc - true_rate, na.rm = TRUE),     r1_no_pct_bias = 100 * mean((r1_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_no_rmse = sqrt(mean((r1_no_trunc - true_rate)^2, na.rm = TRUE)),      # R2 no truncation     r2_no_mean = mean(r2_no_trunc, na.rm = TRUE),     r2_no_bias = mean(r2_no_trunc - true_rate, na.rm = TRUE),     r2_no_pct_bias = 100 * mean((r2_no_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_no_rmse = sqrt(mean((r2_no_trunc - true_rate)^2, na.rm = TRUE)),      # R1 with truncation     r1_trunc_mean = mean(r1_with_trunc, na.rm = TRUE),     r1_trunc_bias = mean(r1_with_trunc - true_rate, na.rm = TRUE),     r1_trunc_pct_bias = 100 * mean((r1_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r1_trunc_rmse = sqrt(mean((r1_with_trunc - true_rate)^2, na.rm = TRUE)),      # R2 with truncation     r2_trunc_mean = mean(r2_with_trunc, na.rm = TRUE),     r2_trunc_bias = mean(r2_with_trunc - true_rate, na.rm = TRUE),     r2_trunc_pct_bias = 100 * mean((r2_with_trunc - true_rate) / true_rate, na.rm = TRUE),     r2_trunc_rmse = sqrt(mean((r2_with_trunc - true_rate)^2, na.rm = TRUE))   )  roving_summary %>%   pivot_longer(cols = -true_rate,                names_to = c(\"estimator\", \"truncation\", \"metric\"),                names_pattern = \"([^_]+)_([^_]+)_(.*)\",                values_to = \"value\") %>%   pivot_wider(names_from = metric, values_from = value) %>%   mutate(estimator = recode(estimator, r1 = \"Ratio of Means\", r2 = \"Mean of Ratios\"),          truncation = recode(truncation, no = \"No truncation\", trunc = \"30-min truncation\")) %>%   select(estimator, truncation, mean, bias, pct_bias, rmse) %>%   knitr::kable(digits = 4, caption = \"Roving Design: Estimator Performance\") roving_mc %>%   select(rep, true_rate, r1_no_trunc, r2_no_trunc, r1_with_trunc, r2_with_trunc) %>%   pivot_longer(cols = -c(rep, true_rate),                names_to = \"estimator\",                values_to = \"estimate\") %>%   filter(!is.na(estimate)) %>%   mutate(     estimator_type = ifelse(grepl(\"r1\", estimator), \"Ratio of Means (R₁)\", \"Mean of Ratios (R₂)\"),     truncation = ifelse(grepl(\"no_trunc\", estimator), \"No Truncation\", \"30-Min Truncation\")   ) %>%   ggplot(aes(x = estimate, fill = truncation)) +   geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +   geom_vline(aes(xintercept = mean(true_rate)), linetype = \"dashed\", size = 1) +   facet_grid(estimator_type ~ truncation, scales = \"free_y\") +   labs(title = \"Roving Design: Impact of Estimator Choice and Truncation\",        subtitle = \"Dashed line = true population catch rate\",        x = \"Estimated Catch Rate (fish/hour)\",        y = \"Frequency\",        fill = \"Truncation\") +   theme_minimal() +   theme(legend.position = \"bottom\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"practical-implementation-with-tidycreel-1","dir":"Articles","previous_headings":"","what":"Practical Implementation with tidycreel","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"","code":"# Assuming you have complete-trip interview data interviews_complete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 8),   hours_fished = rgamma(100, shape = 4, rate = 1),   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # Create survey design svy_interviews <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_complete )  # Use RATIO-OF-MEANS (default and recommended) cpue_access <- est_cpue(   design = svy_interviews,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"ratio_of_means\"  # ✓ Correct for access interviews )  cpue_access # Assuming you have incomplete-trip interview data interviews_incomplete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 4),  # Catch so far   hours_fished = runif(100, min = 0.2, max = 6),  # Time so far   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # IMPORTANT: Truncate short trips before analysis interviews_truncated <- interviews_incomplete %>%   filter(hours_fished >= 0.5)  # Remove trips < 30 minutes  # Create survey design svy_roving <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_truncated )  # Use MEAN-OF-RATIOS for roving interviews cpue_roving <- est_cpue(   design = svy_roving,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"mean_of_ratios\"  # ✓ Correct for roving interviews )  cpue_roving"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"access-point-survey-example-1","dir":"Articles","previous_headings":"","what":"Access Point Survey Example","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"","code":"# Assuming you have complete-trip interview data interviews_complete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 8),   hours_fished = rgamma(100, shape = 4, rate = 1),   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # Create survey design svy_interviews <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_complete )  # Use RATIO-OF-MEANS (default and recommended) cpue_access <- est_cpue(   design = svy_interviews,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"ratio_of_means\"  # ✓ Correct for access interviews )  cpue_access"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"roving-survey-example-1","dir":"Articles","previous_headings":"","what":"Roving Survey Example","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"","code":"# Assuming you have incomplete-trip interview data interviews_incomplete <- tibble(   angler_id = 1:100,   date = rep(as.Date(\"2024-01-01\") + 0:9, each = 10),   catch_total = rpois(100, lambda = 4),  # Catch so far   hours_fished = runif(100, min = 0.2, max = 6),  # Time so far   day_type = rep(c(\"weekday\", \"weekend\"), length.out = 100) )  # IMPORTANT: Truncate short trips before analysis interviews_truncated <- interviews_incomplete %>%   filter(hours_fished >= 0.5)  # Remove trips < 30 minutes  # Create survey design svy_roving <- survey::svydesign(   ids = ~1,   strata = ~day_type,   data = interviews_truncated )  # Use MEAN-OF-RATIOS for roving interviews cpue_roving <- est_cpue(   design = svy_roving,   by = NULL,   response = \"catch_total\",   effort_col = \"hours_fished\",   mode = \"mean_of_ratios\"  # ✓ Correct for roving interviews )  cpue_roving"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"variance-estimation-1","dir":"Articles","previous_headings":"","what":"Variance Estimation","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"ratio--means survey weights, survey package automatically uses delta method: Note: variance formulas assume sampling infinite (large) population. sample size substantial relative total number anglers (n/N > 5%), may want apply finite population correction (FPC): multiply variance (1 - n/N). However, creel surveys population potential anglers large, correction negligible. [(_1) (C - _1 E)] (C) = catch, (E) = effort. mean--ratios, variance straightforward: [(_2) = ()]","code":"# survey::svyratio() provides proper variance cpue_result <- est_cpue(design = svy_interviews, mode = \"ratio_of_means\")  # Standard error is included cpue_result$se  # 95% confidence interval cpue_result$ci_low cpue_result$ci_high # survey::svymean() on the ratio variable cpue_roving <- est_cpue(design = svy_roving, mode = \"mean_of_ratios\")  # Standard error and CIs included cpue_roving$se cpue_roving$ci_low cpue_roving$ci_high"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"access-point-ratio-of-means-1","dir":"Articles","previous_headings":"","what":"Access Point (Ratio-of-Means)","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"ratio--means survey weights, survey package automatically uses delta method: Note: variance formulas assume sampling infinite (large) population. sample size substantial relative total number anglers (n/N > 5%), may want apply finite population correction (FPC): multiply variance (1 - n/N). However, creel surveys population potential anglers large, correction negligible. [(_1) (C - _1 E)] (C) = catch, (E) = effort.","code":"# survey::svyratio() provides proper variance cpue_result <- est_cpue(design = svy_interviews, mode = \"ratio_of_means\")  # Standard error is included cpue_result$se  # 95% confidence interval cpue_result$ci_low cpue_result$ci_high"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"roving-mean-of-ratios-with-truncation-1","dir":"Articles","previous_headings":"","what":"Roving (Mean-of-Ratios with Truncation)","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"mean--ratios, variance straightforward: [(_2) = ()]","code":"# survey::svymean() on the ratio variable cpue_roving <- est_cpue(design = svy_roving, mode = \"mean_of_ratios\")  # Standard error and CIs included cpue_roving$se cpue_roving$ci_low cpue_roving$ci_high"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"special-considerations-1","dir":"Articles","previous_headings":"","what":"Special Considerations","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"⚠️ CRITICAL WARNING: Roving surveys can produce severe negative bias (underestimation 20-50%+) bag limits low (≤5 fish) anglers comply leaving immediately upon reaching limit. Problem: anglers leave immediately catching limit, roving clerk encounter unsuccessful anglers, leading severe underestimation. Example simulation (bag limit = 2 fish): Roving Bias Different Bag Limits Recommendation: bag limits low (≤5 fish) compliance high, use access point interviews instead roving. catch rates change systematically trips (e.g., learning curve, time--day effects), roving interviews may biased. Check : Comparing incomplete-trip catch rates complete-trip catch rates Looking patterns catch rate vs. time--day nonstationary: Consider access point interviews model time-varying catch rate.","code":"simulate_with_bag_limit <- function(n_reps = 500, bag_limit = 2) {   map_dfr(1:n_reps, function(rep) {     # Simulate fishing day     day <- simulate_fishing_day(n_anglers = 100)     true_rate <- day$true_population_rate[1]      # Apply bag limit: anglers stop when limit reached     day_limited <- day %>%       mutate(         # Time to reach bag limit (exponential waiting time)         time_to_limit = ifelse(catch_rate_true > 0,                                bag_limit / catch_rate_true,                                Inf),         # Actual trip length (stop at limit or planned end, whichever comes first)         actual_trip_length = pmin(trip_length, time_to_limit),         # Actual catch (capped at bag limit)         actual_catch = pmin(completed_catch, bag_limit),         # Did angler reach bag limit before planned trip end?         reached_limit = (time_to_limit < trip_length)       )      # Roving interviews can only encounter anglers still on-site     # Those who reached bag limit before their planned trip end have already left     # Only those who haven't reached the limit OR reached it at/after planned end are available     still_fishing <- day_limited %>%       filter(!reached_limit)      if (nrow(still_fishing) > 10) {       # Sample from those still fishing       sample_data <- sample_roving_interviews(still_fishing, n_interviews = 30) %>%         rename(catch = catch_at_interview, effort = time_at_interview) %>%         filter(effort >= 0.5)        if (nrow(sample_data) > 0) {         r2 <- mean(sample_data$catch / sample_data$effort)         return(tibble(rep = rep, true_rate = true_rate, estimated_rate = r2,                      bag_limit = bag_limit))       }     }      tibble(rep = rep, true_rate = true_rate, estimated_rate = NA, bag_limit = bag_limit)   }) }  bag_limit_results <- bind_rows(   simulate_with_bag_limit(bag_limit = 2),   simulate_with_bag_limit(bag_limit = 5),   simulate_with_bag_limit(bag_limit = 10) )  bag_limit_summary <- bag_limit_results %>%   filter(!is.na(estimated_rate)) %>%   group_by(bag_limit) %>%   summarise(     true_rate = mean(true_rate),     mean_estimate = mean(estimated_rate),     bias = mean(estimated_rate - true_rate),     pct_bias = 100 * mean((estimated_rate - true_rate) / true_rate)   )  bag_limit_summary %>%   knitr::kable(digits = 3, caption = \"Roving Bias Under Different Bag Limits\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"bag-limits-1","dir":"Articles","previous_headings":"","what":"Bag Limits","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"⚠️ CRITICAL WARNING: Roving surveys can produce severe negative bias (underestimation 20-50%+) bag limits low (≤5 fish) anglers comply leaving immediately upon reaching limit. Problem: anglers leave immediately catching limit, roving clerk encounter unsuccessful anglers, leading severe underestimation. Example simulation (bag limit = 2 fish): Roving Bias Different Bag Limits Recommendation: bag limits low (≤5 fish) compliance high, use access point interviews instead roving.","code":"simulate_with_bag_limit <- function(n_reps = 500, bag_limit = 2) {   map_dfr(1:n_reps, function(rep) {     # Simulate fishing day     day <- simulate_fishing_day(n_anglers = 100)     true_rate <- day$true_population_rate[1]      # Apply bag limit: anglers stop when limit reached     day_limited <- day %>%       mutate(         # Time to reach bag limit (exponential waiting time)         time_to_limit = ifelse(catch_rate_true > 0,                                bag_limit / catch_rate_true,                                Inf),         # Actual trip length (stop at limit or planned end, whichever comes first)         actual_trip_length = pmin(trip_length, time_to_limit),         # Actual catch (capped at bag limit)         actual_catch = pmin(completed_catch, bag_limit),         # Did angler reach bag limit before planned trip end?         reached_limit = (time_to_limit < trip_length)       )      # Roving interviews can only encounter anglers still on-site     # Those who reached bag limit before their planned trip end have already left     # Only those who haven't reached the limit OR reached it at/after planned end are available     still_fishing <- day_limited %>%       filter(!reached_limit)      if (nrow(still_fishing) > 10) {       # Sample from those still fishing       sample_data <- sample_roving_interviews(still_fishing, n_interviews = 30) %>%         rename(catch = catch_at_interview, effort = time_at_interview) %>%         filter(effort >= 0.5)        if (nrow(sample_data) > 0) {         r2 <- mean(sample_data$catch / sample_data$effort)         return(tibble(rep = rep, true_rate = true_rate, estimated_rate = r2,                      bag_limit = bag_limit))       }     }      tibble(rep = rep, true_rate = true_rate, estimated_rate = NA, bag_limit = bag_limit)   }) }  bag_limit_results <- bind_rows(   simulate_with_bag_limit(bag_limit = 2),   simulate_with_bag_limit(bag_limit = 5),   simulate_with_bag_limit(bag_limit = 10) )  bag_limit_summary <- bag_limit_results %>%   filter(!is.na(estimated_rate)) %>%   group_by(bag_limit) %>%   summarise(     true_rate = mean(true_rate),     mean_estimate = mean(estimated_rate),     bias = mean(estimated_rate - true_rate),     pct_bias = 100 * mean((estimated_rate - true_rate) / true_rate)   )  bag_limit_summary %>%   knitr::kable(digits = 3, caption = \"Roving Bias Under Different Bag Limits\")"},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"nonstationary-catch-rates-1","dir":"Articles","previous_headings":"","what":"Nonstationary Catch Rates","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"catch rates change systematically trips (e.g., learning curve, time--day effects), roving interviews may biased. Check : Comparing incomplete-trip catch rates complete-trip catch rates Looking patterns catch rate vs. time--day nonstationary: Consider access point interviews model time-varying catch rate.","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"summary-practical-guidelines-1","dir":"Articles","previous_headings":"","what":"Summary: Practical Guidelines","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"surveys: Check missing data catch effort Verify effort > 0 interviews Check outliers (data entry errors) ROVING surveys specifically: Truncate short trips (< 20-30 minutes) Check bag limit compliance (may cause bias) Verify catch rate stationarity (possible) Use proper survey weights svydesign() Include stratification variables Use svyratio() ratio--means Use svymean() catch/effort ratio mean--ratios Report standard errors confidence intervals","code":""},{"path":[]},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"pre-processing-checklist-1","dir":"Articles","previous_headings":"","what":"Pre-processing Checklist","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"surveys: Check missing data catch effort Verify effort > 0 interviews Check outliers (data entry errors) ROVING surveys specifically: Truncate short trips (< 20-30 minutes) Check bag limit compliance (may cause bias) Verify catch rate stationarity (possible)","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"variance-estimation-checklist-1","dir":"Articles","previous_headings":"","what":"Variance Estimation Checklist","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Use proper survey weights svydesign() Include stratification variables Use svyratio() ratio--means Use svymean() catch/effort ratio mean--ratios Report standard errors confidence intervals","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"references-1","dir":"Articles","previous_headings":"","what":"References","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"Pollock, K.H., Hoenig, J.M., Jones, C.M., Robson, D.S., & Greene, C.J. (1997). Catch rate estimation roving access point surveys. North American Journal Fisheries Management, 17(1), 11-19. Rasmussen, P.W., Staggs, M.D., Beard, T.D., & Newman, S.P. (1998). Bias confidence interval coverage creel survey estimators evaluated simulation. Transactions American Fisheries Society, 127(3), 469-480. Jones, C.M., Robson, D.S., Lakkis, H.D., & Kressel, J. (1995). Properties catch rates used analysis angler surveys. Transactions American Fisheries Society, 124(6), 911-928. Lumley, T. (2004). Analysis complex survey samples. Journal Statistical Software, 9(1), 1-19.","code":""},{"path":"/articles/ratio-estimators-guide_full_with_hybrid.html","id":"conclusion-1","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Ratio Estimators: When to Use Ratio-of-Means vs Mean-of-Ratios","text":"choice ratio--means mean--ratios depends fundamentally survey design: Access point interviews → Use ratio--means Roving interviews → Use mean--ratios truncation tidycreel package implements estimators proper variance estimation survey package. following decision rules vignette, can ensure catch rate estimates unbiased confidence intervals correct coverage.","code":""},{"path":"/articles/replicate_designs_creel.html","id":"when-to-use-replicate-designs","dir":"Articles","previous_headings":"","what":"When to use replicate designs","title":"Replicate Designs for Creel Inference","text":"Taylor linearization (analytic SE) often sufficient creel totals ratios. Replicate designs (bootstrap, jackknife, BRR) useful : Variance structure complex (e.g., HT contributions variable inclusion probabilities), combine multiple non-linear steps (e.g., effort × CPUE), need small-sample robustness checks. tidycreel, recommend building replicate designs day-PSU svydesign created as_day_svydesign().","code":""},{"path":"/articles/replicate_designs_creel.html","id":"build-a-replicate-design-from-day-psus","dir":"Articles","previous_headings":"","what":"Build a replicate design from day PSUs","title":"Replicate Designs for Creel Inference","text":"Notes: - .svrepdesign() derives replicate weights day design (preferred custom resampling). - Use type = \"JK1\" jackknife type = \"BRR\" design fits BRR assumptions.","code":"library(tidycreel) library(survey) library(dplyr)  # Toy calendar of sampled days a <- tibble::tibble(   date = as.Date(c(\"2025-08-20\",\"2025-08-21\",\"2025-08-22\")),   day_type = c(\"weekday\",\"weekday\",\"weekend\"),   month = c(\"Aug\",\"Aug\",\"Aug\"),   target_sample = c(4,4,4),   actual_sample = c(2,2,1) ) svy_day <- as_day_svydesign(a, day_id = \"date\", strata_vars = c(\"day_type\",\"month\"))  # Convert to replicate-weight design (bootstrap with 50 reps) svy_rep <- survey::as.svrepdesign(svy_day, type = \"bootstrap\", replicates = 50, mse = TRUE) svy_rep"},{"path":"/articles/replicate_designs_creel.html","id":"use-replicate-design-in-estimators","dir":"Articles","previous_headings":"","what":"Use replicate design in estimators","title":"Replicate Designs for Creel Inference","text":"svy_rep carries replicate weights, estimator computes totals SE using replicate variance automatically.","code":"# Instantaneous counts example (very small synthetic data) counts <- tibble::tibble(   date = rep(a$date, each = 2),   location = rep(c(\"A\",\"B\"), times = 3),   count = c(10, 12, 8, 11, 9, 14),   interval_minutes = 60,   total_day_minutes = 600 )  est_effort(   design = svy_rep,   counts = counts,   method = \"instantaneous\",   by = \"location\" )"},{"path":"/articles/replicate_designs_creel.html","id":"tips-and-caveats","dir":"Articles","previous_headings":"","what":"Tips and caveats","title":"Replicate Designs for Creel Inference","text":"Keep replicate counts modest examples vignettes (e.g., 50–200) avoid slow builds; increase production analysis. Ensure PSUs truly represent days; need sub-day PSUs (rare), document assumptions. Horvitz–Thompson contributions (e.g., bus-route), compute day×group totals first, let day replicate design handle SE.","code":""},{"path":"/articles/replicate_designs_creel.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Replicate Designs for Creel Inference","text":"survey package: .svrepdesign, svrepdesign, variance vignette. creel methodology references creel_chapter.md context.","code":"sessionInfo()"},{"path":"/articles/survey_creel_terms.html","id":"why-this-guide","dir":"Articles","previous_headings":"","what":"Why this guide","title":"Survey Package to Creel: A Translator","text":"Many creel practitioners know field methods estimators less familiar survey package vocabulary. guide “translates” survey’s core concepts creel terms shows tidycreel applies survey-first workflow. See also creel_chapter.md background references.","code":""},{"path":"/articles/survey_creel_terms.html","id":"core-translation-concepts-and-terms","dir":"Articles","previous_headings":"","what":"Core translation: concepts and terms","title":"Survey Package to Creel: A Translator","text":"PSUs (Primary Sampling Units): sampled days; sometimes day×stratum needed. SSUs: count passes interviews within day; typically aggregated day totals. Strata: calendar groupings (e.g., weekday/weekend, month, season, area). target_sample vs actual_sample: planned vs realized number sampled PSUs stratum. Day weights (w): expansion sampled target days; often w = target_sample / actual_sample within stratum. Inclusion probability (π): probability unit observed. bus-route HT, per-observation π enters directly. Totals (svytotal): sum day totals across sampled days design-based variance. Means (svymean): average PSUs; less common creel totals. Ratios (svyratio): CPUE catch/effort design-based variance. Replicate designs (svrepdesign): bootstrap/jackknife/BRR Taylor SE complex.","code":""},{"path":"/articles/survey_creel_terms.html","id":"survey-first-workflow-in-tidycreel","dir":"Articles","previous_headings":"","what":"Survey-first workflow in tidycreel","title":"Survey Package to Creel: A Translator","text":"Build day-PSU survey design calendar. Aggregate raw counts day×group totals (vectorized, tidy). Use survey get totals SEs group (svytotal/svyby). Prefer replicate-weight designs complex cases.","code":""},{"path":"/articles/survey_creel_terms.html","id":"day-psu-design","dir":"Articles","previous_headings":"Survey-first workflow in tidycreel","what":"1) Day-PSU design","title":"Survey Package to Creel: A Translator","text":"means creel terms: sampled day represents target_sample / actual_sample similar days within stratum. survey carries weight variance estimation.","code":"library(tidycreel) library(dplyr)  # Minimal, toy calendar: two sampled days, both intended 4 samples/stratum calendar <- tibble::tibble(   date = as.Date(c(\"2025-08-20\", \"2025-08-21\")),   day_type = c(\"weekday\", \"weekday\"),   month = c(\"Aug\", \"Aug\"),   target_sample = c(4, 4),   actual_sample = c(2, 2) )  svy_day <- as_day_svydesign(calendar, day_id = \"date\", strata_vars = c(\"day_type\", \"month\")) svy_day"},{"path":"/articles/survey_creel_terms.html","id":"instantaneous-effort-from-counts","dir":"Articles","previous_headings":"Survey-first workflow in tidycreel","what":"2) Instantaneous effort from counts","title":"Survey Package to Creel: A Translator","text":"Interpretation: per day×location, effort_day = mean(count) × total_day_minutes / 60; totals SEs come day design.","code":"# Toy snapshot counts for two locations over two days (minutes per snapshot) counts_inst <- tibble::tibble(   date = rep(calendar$date, each = 2),   location = rep(c(\"A\", \"B\"), times = 2),   count = c(10, 12, 9, 15),   interval_minutes = 60,   total_day_minutes = 600  # e.g., 10-hour day window )  est_effort(   design = svy_day,   counts = counts_inst,   method = \"instantaneous\",   by = \"location\" )"},{"path":"/articles/survey_creel_terms.html","id":"progressive-roving-effort","dir":"Articles","previous_headings":"Survey-first workflow in tidycreel","what":"3) Progressive (roving) effort","title":"Survey Package to Creel: A Translator","text":"Interpretation: per day×location, sum(count × route_minutes)/60 across passes, design-based totals.","code":"# Toy progressive (roving) pass counts with per-pass route minutes counts_prog <- tibble::tibble(   date = rep(calendar$date, each = 3),   location = rep(c(\"A\", \"A\", \"B\"), times = 2),   pass_id = rep(1:3, times = 2),   count = c(4, 6, 8, 5, 7, 9),   route_minutes = c(45, 45, 45, 45, 45, 45) )  est_effort(   design = svy_day,   counts = counts_prog,   method = \"progressive\",   by = \"location\" )"},{"path":"/articles/survey_creel_terms.html","id":"aerial-effort-and-visibility","dir":"Articles","previous_headings":"Survey-first workflow in tidycreel","what":"4) Aerial effort and visibility","title":"Survey Package to Creel: A Translator","text":"Interpretation: adjust counts visibility, compute day totals, use day design totals/SEs.","code":"# Aerial snapshots with a simple visibility factor (0-1) counts_air <- tibble::tibble(   date = rep(calendar$date, each = 2),   location = rep(c(\"A\", \"B\"), times = 2),   count = c(10, 8, 12, 15),   interval_minutes = 60,   total_day_minutes = 600,   visibility = c(0.8, 0.9, 0.7, 1.0) )  est_effort.aerial(   counts = counts_air,   by = \"location\",   minutes_col = \"interval_minutes\",   total_minutes_col = \"total_day_minutes\",   visibility_col = \"visibility\",   svy = svy_day )"},{"path":"/articles/survey_creel_terms.html","id":"cpue-and-harvest-in-brief","dir":"Articles","previous_headings":"","what":"CPUE and Harvest (in brief)","title":"Survey Package to Creel: A Translator","text":"CPUE: ratio estimator (svyratio) catch effort. creel terms, means combining interview-derived catch associated effort, respecting day-PSU design. survey-first estimate_cpue() aligned tidy outputs planned. Harvest/Catch totals: use svytotal interview-level kept/total catch expanded day weights, combined estimator multiplies effort CPUE appropriate (delta/replicate methods).","code":""},{"path":"/articles/survey_creel_terms.html","id":"jargon-quick-map","dir":"Articles","previous_headings":"","what":"Jargon quick map","title":"Survey Package to Creel: A Translator","text":"PSU (Primary Sampling Unit): sampled day (primary “draw”). Strata: calendar groups (weekday/weekend, month, season, region). Weight: expansion factor sampled days target days stratum. Inclusion probability (π): chance observation appears (e.g., bus-route pass); enters HT contributions. HT (Horvitz–Thompson) contribution: observed contribution divided π. Taylor SE: analytic variance survey; Replicate SE: via bootstrap/jackknife/BRR svrepdesign.","code":""},{"path":"/articles/survey_creel_terms.html","id":"references-and-further-reading","dir":"Articles","previous_headings":"","what":"References and further reading","title":"Survey Package to Creel: A Translator","text":"tidycreel design/estimation vignettes function docs. survey package documentation svydesign, svytotal, svyratio, svyby, svrepdesign. creel_chapter.md creel_foundations.md repo statistical background.","code":"sessionInfo()"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Christopher Chizinski. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chizinski C (2025). tidycreel: Tidy Interface Creel Survey Design Analysis. R package version 0.0.0.9000, https://github.com/chrischizinski/tidycreel.","code":"@Manual{,   title = {tidycreel: Tidy Interface for Creel Survey Design and Analysis},   author = {Christopher Chizinski},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://github.com/chrischizinski/tidycreel}, }"},{"path":"/index.html","id":"tidycreel","dir":"","previous_headings":"","what":"Tidy Interface for Creel Survey Design and Analysis","title":"Tidy Interface for Creel Survey Design and Analysis","text":"goal tidycreel provide survey-first, tidy interface creel survey design analysis. Estimators built survey/svrepdesign framework vectorized, tidyverse data workflows, delivering defensible estimates effort, CPUE, catch, harvest.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tidy Interface for Creel Survey Design and Analysis","text":"tidycreel distributed via GitHub (submitted CRAN). Install latest version :","code":"# install.packages(\"pak\") pak::pak(\"chrischizinski/tidycreel\")  # Or using devtools/remotes # install.packages(\"devtools\") devtools::install_github(\"chrischizinski/tidycreel\")"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Tidy Interface for Creel Survey Design and Analysis","text":"Survey-first estimators using bundled toy data:","code":"library(tidycreel)  # Load example data interviews <- readr::read_csv(   system.file(\"extdata/toy_interviews.csv\", package = \"tidycreel\") ) counts <- readr::read_csv(   system.file(\"extdata/toy_counts.csv\", package = \"tidycreel\") ) calendar <- readr::read_csv(   system.file(\"extdata/toy_calendar.csv\", package = \"tidycreel\") )  # Create day-PSU design from calendar svy_day <- as_day_svydesign(   calendar,   day_id = \"date\",   strata_vars = c(\"day_type\", \"month\") )  # Estimate effort from instantaneous counts est_effort(svy_day, counts, method = \"instantaneous\", by = c(\"location\"))  # Estimate CPUE and catch from interview data svy_int <- survey::svydesign(ids = ~1, weights = ~1, data = interviews) est_cpue(svy_int, by = c(\"target_species\"), response = \"catch_total\") est_catch(svy_int, by = c(\"target_species\"), response = \"catch_kept\")"},{"path":"/index.html","id":"effort-overview-survey-first","dir":"","previous_headings":"","what":"Effort Overview (Survey-First)","title":"Tidy Interface for Creel Survey Design and Analysis","text":"Instantaneous Progressive (roving) estimators aggregate day × group totals use day-PSU design inference. See vignette: Aerial snapshot counts covariates, post-stratification, calibration covered : Tip: replicate variance, convert day design survey::.svrepdesign() pass estimators.","code":"vignette(\"effort_survey_first\", package = \"tidycreel\") vignette(\"aerial\", package = \"tidycreel\")"},{"path":"/index.html","id":"guides-and-vignettes","dir":"","previous_headings":"","what":"Guides and Vignettes","title":"Tidy Interface for Creel Survey Design and Analysis","text":"Survey terms creel context: translator Replicate designs (bootstrap/jackknife/BRR) creel inference","code":"vignette(\"survey_creel_terms\", package = \"tidycreel\") vignette(\"replicate_designs_creel\", package = \"tidycreel\")"},{"path":"/reference/acres_to_hectares.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert acres to hectares — acres_to_hectares","title":"Convert acres to hectares — acres_to_hectares","text":"Convert acres hectares","code":""},{"path":"/reference/acres_to_hectares.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert acres to hectares — acres_to_hectares","text":"","code":"acres_to_hectares(x)"},{"path":"/reference/acres_to_hectares.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert acres to hectares — acres_to_hectares","text":"x numeric vector (acres)","code":""},{"path":"/reference/acres_to_hectares.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert acres to hectares — acres_to_hectares","text":"numeric vector (hectares)","code":""},{"path":"/reference/as_day_svydesign.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a day-level survey design for aerial estimation — as_day_svydesign","title":"Construct a day-level survey design for aerial estimation — as_day_svydesign","text":"Builds survey::svydesign sampled days (PSUs) using calendar information. Weights per sampled day computed target vs actual sample counts within strata (target_sample / actual_sample).","code":""},{"path":"/reference/as_day_svydesign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a day-level survey design for aerial estimation — as_day_svydesign","text":"","code":"as_day_svydesign(   calendar,   day_id = \"date\",   strata_vars = c(\"day_type\", \"month\", \"season\", \"weekend\") )"},{"path":"/reference/as_day_svydesign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a day-level survey design for aerial estimation — as_day_svydesign","text":"calendar Tibble/data.frame day-level sampling plan, including day_id, target_sample, actual_sample, strata variables. day_id Column name identifying day PSU (default date). strata_vars Character vector calendar columns defining strata (e.g., c(\"day_type\",\"month\")). Missing columns ignored warning.","code":""},{"path":"/reference/as_day_svydesign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a day-level survey design for aerial estimation — as_day_svydesign","text":"survey::svydesign object one row per sampled day.","code":""},{"path":"/reference/as_day_svydesign.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a day-level survey design for aerial estimation — as_day_svydesign","text":"","code":"cal <- tibble::tibble(   date = as.Date(c(\"2025-08-20\",\"2025-08-21\")),   day_type = c(\"weekday\",\"weekday\"),   month = c(\"August\",\"August\"),   target_sample = c(4,4),   actual_sample = c(2,2) ) svy_day <- as_day_svydesign(cal, day_id = \"date\", strata_vars = c(\"day_type\",\"month\"))"},{"path":"/reference/as_survey_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract survey design object from a creel_design — as_survey_design","title":"Extract survey design object from a creel_design — as_survey_design","text":"helper bridges tidycreel design objects survey package. returns embedded survey::svydesign survey::svrepdesign object downstream analysis.","code":""},{"path":"/reference/as_survey_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract survey design object from a creel_design — as_survey_design","text":"","code":"as_survey_design(design)"},{"path":"/reference/as_survey_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract survey design object from a creel_design — as_survey_design","text":"design creel_design object (subclass)","code":""},{"path":"/reference/as_survey_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract survey design object from a creel_design — as_survey_design","text":"survey::svydesign survey::svrepdesign object","code":""},{"path":"/reference/as_survey_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract survey design object from a creel_design — as_survey_design","text":"function provides clear, pipe-friendly way access underlying survey design object created tidycreel constructors. Use analysis survey srvyr functions. access-point, roving, bus route designs, returns survey::svydesign. replicate weights designs, returns survey::svrepdesign. Raises error embedded survey design found.","code":""},{"path":"/reference/as_survey_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract survey design object from a creel_design — as_survey_design","text":"","code":"if (FALSE) { # \\dontrun{ access_design <- design_access(   interviews = utils::read.csv(system.file(\"extdata\", \"toy_interviews.csv\",     package = \"tidycreel\"   )),   calendar = utils::read.csv(system.file(\"extdata\", \"toy_calendar.csv\",     package = \"tidycreel\"   )) ) svy <- as_survey_design(access_design) summary(svy) } # }"},{"path":"/reference/as_svrep_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract replicate weights survey design from a repweights_design — as_svrep_design","title":"Extract replicate weights survey design from a repweights_design — as_svrep_design","text":"Returns embedded survey::svrepdesign object bootstrap/jackknife/BRR designs.","code":""},{"path":"/reference/as_svrep_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract replicate weights survey design from a repweights_design — as_svrep_design","text":"","code":"as_svrep_design(design)"},{"path":"/reference/as_svrep_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract replicate weights survey design from a repweights_design — as_svrep_design","text":"design repweights_design object","code":""},{"path":"/reference/as_svrep_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract replicate weights survey design from a repweights_design — as_svrep_design","text":"survey::svrepdesign object","code":""},{"path":"/reference/as_svrep_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract replicate weights survey design from a repweights_design — as_svrep_design","text":"Use helper advanced variance estimation resampling-based inference. Raises error embedded svrepdesign found.","code":""},{"path":"/reference/as_svrep_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract replicate weights survey design from a repweights_design — as_svrep_design","text":"","code":"if (FALSE) { # \\dontrun{ # Create a replicate weights design first # (design_repweights is an internal function) access_design <- design_access(interviews, calendar) # Then extract the survey design for advanced use # svyrep <- as_svrep_design(rep_design) } # }"},{"path":"/reference/auxiliary_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Auxiliary Data Schema — auxiliary_schema","title":"Auxiliary Data Schema — auxiliary_schema","text":"Defines expected structure auxiliary data (sunrise/sunset, holidays).","code":""},{"path":"/reference/auxiliary_schema.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Auxiliary Data Schema — auxiliary_schema","text":"tibble following columns: date Date, date auxiliary data sunrise POSIXct, sunrise time sunset POSIXct, sunset time holiday Character, holiday name ()","code":""},{"path":"/reference/calendar_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Sampling Calendar Schema — calendar_schema","title":"Sampling Calendar Schema — calendar_schema","text":"Defines expected structure sampling calendar data including temporal strata definitions.","code":""},{"path":"/reference/calendar_schema.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sampling Calendar Schema — calendar_schema","text":"tibble following columns: date Date, sampling date stratum_id Character, unique stratum identifier day_type Character, type day (weekday, weekend, holiday) season Character, season identifier month Character, month identifier weekend Logical, TRUE weekend holiday Logical, TRUE holiday shift_block Character, shift identifier (morning, afternoon, evening) target_sample Integer, target sample size stratum actual_sample Integer, actual sample size achieved","code":""},{"path":"/reference/capwords.html","id":null,"dir":"Reference","previous_headings":"","what":"Capitalize words — capwords","title":"Capitalize words — capwords","text":"Capitalize words","code":""},{"path":"/reference/capwords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Capitalize words — capwords","text":"","code":"capwords(x)"},{"path":"/reference/capwords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Capitalize words — capwords","text":"x character vector","code":""},{"path":"/reference/capwords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Capitalize words — capwords","text":"character vector","code":""},{"path":"/reference/change_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Change NA or specific values to a target — change_na","title":"Change NA or specific values to a target — change_na","text":"Change NA specific values target","code":""},{"path":"/reference/change_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change NA or specific values to a target — change_na","text":"","code":"change_na(x, from = NA, to = 0)"},{"path":"/reference/change_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change NA or specific values to a target — change_na","text":"x vector values treat missing (default NA) replacement value (default 0)","code":""},{"path":"/reference/change_na.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change NA or specific values to a target — change_na","text":"vector replacements","code":""},{"path":"/reference/convertToLogical.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to logical (compat) — convertToLogical","title":"Convert to logical (compat) — convertToLogical","text":"Convert logical (compat)","code":""},{"path":"/reference/convertToLogical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to logical (compat) — convertToLogical","text":"","code":"convertToLogical(x)"},{"path":"/reference/convertToLogical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to logical (compat) — convertToLogical","text":"x ","code":""},{"path":"/reference/convertToLogical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert to logical (compat) — convertToLogical","text":"logical","code":""},{"path":"/reference/count_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantaneous Count Schema — count_schema","title":"Instantaneous Count Schema — count_schema","text":"Defines expected structure instantaneous count data.","code":""},{"path":"/reference/count_schema.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Instantaneous Count Schema — count_schema","text":"tibble following columns: count_id Character, unique count identifier date Date, count date time POSIXct, count time location Character, sampling location mode Character, fishing mode anglers_count Integer, number anglers observed parties_count Integer, number fishing parties observed weather_code Character, weather condition code temperature Numeric, temperature Celsius wind_speed Numeric, wind speed visibility Character, visibility conditions count_duration Numeric, duration count minutes","code":""},{"path":"/reference/design-constructors.html","id":null,"dir":"Reference","previous_headings":"","what":"Survey Design Constructors for Access-Point Creel Surveys — design-constructors","title":"Survey Design Constructors for Access-Point Creel Surveys — design-constructors","text":"functions create survey design objects different types access-point creel surveys, including standard access designs, roving designs, designs replicate weights.","code":""},{"path":"/reference/design_access.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Access-Point Survey Design (lean container) — design_access","title":"Create Access-Point Survey Design (lean container) — design_access","text":"Constructs lean container access-point creel surveys. validates stores inputs plus descriptive metadata. Estimation uses survey-first estimators day-PSU designs built via as_day_svydesign(). ad-hoc weighting embedded svydesign created .","code":""},{"path":"/reference/design_access.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Access-Point Survey Design (lean container) — design_access","text":"","code":"design_access(   interviews,   calendar,   locations = NULL,   strata_vars = c(\"date\", \"shift_block\", \"location\"),   weight_method = c(\"equal\", \"standard\") )"},{"path":"/reference/design_access.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Access-Point Survey Design (lean container) — design_access","text":"interviews Tibble interview data validated validate_interviews(). calendar Tibble sampling calendar validated validate_calendar(). locations Optional character vector sampling locations; defaults unique locations interviews. strata_vars Character vector variables describing stratification (e.g., c(\"date\",\"shift_block\",\"location\")). Missing columns ignored.","code":""},{"path":"/reference/design_access.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Access-Point Survey Design (lean container) — design_access","text":"list class c(\"access_design\",\"creel_design\",\"list\") containing design_type, interviews, calendar, locations, strata_vars, metadata.","code":""},{"path":"/reference/design_busroute.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Bus Route Survey Design — design_busroute","title":"Create Bus Route Survey Design — design_busroute","text":"Constructs lean design container bus-route creel surveys. design holds validated inputs metadata; estimation performed survey-first estimators (e.g., est_effort.busroute_design()) rely day-PSU survey design as_day_svydesign(). ad-hoc weighting performed .","code":""},{"path":"/reference/design_busroute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Bus Route Survey Design — design_busroute","text":"","code":"design_busroute(   interviews,   counts,   calendar,   route_schedule,   strata_vars = c(\"date\", \"location\") )"},{"path":"/reference/design_busroute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Bus Route Survey Design — design_busroute","text":"interviews Tibble interview data validated validate_interviews(). counts Tibble count/observation data validated validate_counts(). HT-style effort estimation, counts include inclusion probabilities (e.g., inclusion_prob) sufficient fields derive upstream. calendar Tibble sampling calendar validated validate_calendar(). Used construct day-level svydesign as_day_svydesign(). route_schedule Tibble describing bus-route schedule (e.g., stop, time, planned coverage). Used diagnostics documentation; used compute weights . strata_vars Character vector descriptive stratification metadata (e.g., c(\"date\",\"location\")). Missing columns ignored.","code":""},{"path":"/reference/design_busroute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Bus Route Survey Design — design_busroute","text":"list class c(\"busroute_design\",\"creel_design\",\"list\") fields: design_type, interviews, counts, calendar, route_schedule, strata_vars, metadata.","code":""},{"path":"/reference/design_busroute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Bus Route Survey Design — design_busroute","text":"","code":"# design <- design_busroute(interviews, counts, calendar, route_schedule)"},{"path":"/reference/design_roving.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Roving Survey Design (lean container) — design_roving","title":"Create Roving Survey Design (lean container) — design_roving","text":"Constructs lean container roving creel surveys. validates stores inputs plus descriptive metadata. Estimation effort use survey-first estimators counts (instantaneous progressive) coupled day-PSU design as_day_svydesign(). ad-hoc weighting embedded svydesign created .","code":""},{"path":"/reference/design_roving.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Roving Survey Design (lean container) — design_roving","text":"","code":"design_roving(   interviews,   counts,   calendar,   locations = NULL,   strata_vars = c(\"date\", \"shift_block\", \"location\"),   effort_method = c(\"ratio\", \"calibrate\"),   coverage_correction = FALSE )"},{"path":"/reference/design_roving.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Roving Survey Design (lean container) — design_roving","text":"interviews Tibble validated validate_interviews(). counts Tibble validated validate_counts(). calendar Tibble validated validate_calendar(). locations Optional character vector; defaults union interview count locations. strata_vars Character vector describing stratification (e.g., c(\"date\",\"shift_block\",\"location\")). Missing columns ignored.","code":""},{"path":"/reference/design_roving.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Roving Survey Design (lean container) — design_roving","text":"list class c(\"roving_design\",\"creel_design\",\"list\") containing design_type, interviews, counts, calendar, locations, strata_vars, metadata.","code":""},{"path":"/reference/dot-tc_ensure_shift_block.html","id":null,"dir":"Reference","previous_headings":"","what":"Ensure Shift Block — .tc_ensure_shift_block","title":"Ensure Shift Block — .tc_ensure_shift_block","text":"Internal helper function create shift_block missing.","code":""},{"path":"/reference/dot-tc_ensure_shift_block.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ensure Shift Block — .tc_ensure_shift_block","text":"","code":".tc_ensure_shift_block(data)"},{"path":"/reference/dot-todo.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal TODO stub for compatibility — .todo","title":"Internal TODO stub for compatibility — .todo","text":"Internal TODO stub compatibility","code":""},{"path":"/reference/dot-todo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal TODO stub for compatibility — .todo","text":"","code":".todo(name)"},{"path":"/reference/est_catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Catch/Harvest Total Estimator (survey-first) — est_catch","title":"Catch/Harvest Total Estimator (survey-first) — est_catch","text":"Design-based estimation total catch harvest interview data using survey package. Returns tidy totals groups standard errors Wald confidence intervals.","code":""},{"path":"/reference/est_catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Catch/Harvest Total Estimator (survey-first) — est_catch","text":"","code":"est_catch(   design,   by = NULL,   response = c(\"catch_total\", \"catch_kept\", \"weight_total\"),   conf_level = 0.95 )"},{"path":"/reference/est_catch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Catch/Harvest Total Estimator (survey-first) — est_catch","text":"design svydesign/svrepdesign interviews, creel_design interviews (equal-weight design constructed needed, warning). Character vector grouping variables interview data. response One \"catch_total\", \"catch_kept\", \"weight_total\". Determines total estimated. conf_level Confidence level Wald CIs (default 0.95).","code":""},{"path":"/reference/est_catch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Catch/Harvest Total Estimator (survey-first) — est_catch","text":"Tibble grouping columns, estimate, se, ci_low, ci_high, n, method, diagnostics list-column.","code":""},{"path":[]},{"path":"/reference/est_cpue.html","id":null,"dir":"Reference","previous_headings":"","what":"CPUE Estimator (survey-first) — est_cpue","title":"CPUE Estimator (survey-first) — est_cpue","text":"Design-based estimation catch per unit effort (CPUE) using survey package. Supports ratio--means (recommended incomplete trips) mean--ratios (complete trips). Returns tidy tibble consistent schema across estimators.","code":""},{"path":"/reference/est_cpue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CPUE Estimator (survey-first) — est_cpue","text":"","code":"est_cpue(   design,   by = NULL,   response = c(\"catch_total\", \"catch_kept\", \"weight_total\"),   effort_col = \"hours_fished\",   mode = c(\"auto\", \"ratio_of_means\", \"mean_of_ratios\"),   min_trip_hours = 0.5,   conf_level = 0.95 )"},{"path":"/reference/est_cpue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CPUE Estimator (survey-first) — est_cpue","text":"design svydesign/svrepdesign built interview data, creel_design containing interviews. creel_design supplied, minimal equal-weight design constructed (warns). Character vector grouping variables present interview data (e.g., c(\"target_species\",\"location\")). Missing columns ignored warning. response One \"catch_total\", \"catch_kept\", \"weight_total\". Determines CPUE numerator. effort_col Interview effort column denominator (default \"hours_fished\"). mode Estimation mode: \"auto\" (default; automatically selects based trip_complete field), \"ratio_of_means\" (incomplete trips), \"mean_of_ratios\" (complete trips). min_trip_hours Minimum trip duration hours incomplete trips. Trips shorter truncated avoid unstable ratios. Default 0.5 (30 minutes). used mode=\"auto\" mode=\"ratio_of_means\" incomplete trips. conf_level Confidence level Wald CIs (default 0.95).","code":""},{"path":"/reference/est_cpue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CPUE Estimator (survey-first) — est_cpue","text":"Tibble grouping columns, estimate, se, ci_low, ci_high, n, method, diagnostics list-column.","code":""},{"path":"/reference/est_cpue.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CPUE Estimator (survey-first) — est_cpue","text":"Auto mode: Examines trip_complete field determine appropriate estimator. complete trips uses mean--ratios; incomplete uses ratio--means truncation; mixed data combines estimates using effort-weighting. Ratio--means: svyratio(~response, ~effort_col) optionally via svyby(…, =~group, FUN=svyratio). robust trips incomplete. Short trips truncated detected. Mean--ratios: computes trip-level response/effort_col uses svymean/svyby. Prefer complete trips minimal zero-inflation.","code":""},{"path":[]},{"path":"/reference/est_effort.aerial.html","id":null,"dir":"Reference","previous_headings":"","what":"Aerial Effort Estimator — est_effort.aerial","title":"Aerial Effort Estimator — est_effort.aerial","text":"Estimate angler-hours aerial snapshot counts using mean-count expansion within groups, optional visibility calibration adjustments, design-based variance via survey package day-level svydesign provided.","code":""},{"path":"/reference/est_effort.aerial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aerial Effort Estimator — est_effort.aerial","text":"","code":"est_effort.aerial(   counts,   by = c(\"date\", \"location\"),   minutes_col = c(\"flight_minutes\", \"interval_minutes\", \"count_duration\"),   total_minutes_col = c(\"total_minutes\", \"total_day_minutes\", \"block_total_minutes\"),   day_id = \"date\",   covariates = NULL,   visibility_col = NULL,   calibration_col = NULL,   svy = NULL,   post_strata_var = NULL,   post_strata = NULL,   calibrate_formula = NULL,   calibrate_population = NULL,   calfun = c(\"linear\", \"raking\", \"logit\"),   conf_level = 0.95 )"},{"path":"/reference/est_effort.aerial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aerial Effort Estimator — est_effort.aerial","text":"counts Data frame/tibble aerial counts least count minutes column (e.g., flight_minutes, interval_minutes, count_duration). Character vector grouping variables present counts (e.g., date, location). Missing columns ignored warning. minutes_col Candidate column names minutes represented count. first present used. total_minutes_col Optional column giving total minutes represented whole day×group (e.g., full day length block coverage). absent, estimator falls back sum per-count minutes within day×group (warns). day_id Day identifier (PSU), typically date, used join survey design. covariates Optional character vector additional grouping variables aerial conditions (e.g., cloud, glare, observer, altitude). visibility_col Optional name column visibility proportion (0–1). Counts divided value (guarded avoid division small numbers). calibration_col Optional name column multiplicative calibration factors apply visibility correction. svy Optional svydesign/svrepdesign encoding day sampling design (must include day_id svy$variables). provided, totals, SEs, CIs computed survey functions. conf_level Confidence level Wald CIs (default 0.95).","code":""},{"path":"/reference/est_effort.aerial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aerial Effort Estimator — est_effort.aerial","text":"Tibble grouping columns, estimate, se, ci_low, ci_high, n, method, diagnostics list-column.","code":""},{"path":"/reference/est_effort.aerial.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aerial Effort Estimator — est_effort.aerial","text":"Effort per day×group = mean(adjusted_count) × total_minutes_represented ÷ 60. Group totals computed survey::svytotal/svyby svy encodes day sampling design.","code":""},{"path":"/reference/est_effort.aerial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aerial Effort Estimator — est_effort.aerial","text":"","code":"df <- tibble::tibble(   date = as.Date(rep(\"2025-08-20\", 4)),   location = c(\"A\",\"A\",\"B\",\"B\"),   count = c(10, 12, 8, 15),   interval_minutes = c(60, 60, 60, 60) ) est_effort.aerial(df) #> Warning: ! Aerial: using sum of interval_minutes per day×group as total minutes. #> ℹ Provide `total_minutes_col` for proper expansion. #> # A tibble: 2 × 9 #>   date       location estimate    se ci_low ci_high     n method diagnostics #>   <date>     <chr>       <dbl> <dbl>  <dbl>   <dbl> <int> <chr>  <list>      #> 1 2025-08-20 A              22     2  18.1     25.9     2 aerial <NULL>      #> 2 2025-08-20 B              23     7   9.28    36.7     2 aerial <NULL>"},{"path":"/reference/est_effort.busroute_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Bus-Route Effort Estimation (survey-first HT) — est_effort.busroute_design","title":"Bus-Route Effort Estimation (survey-first HT) — est_effort.busroute_design","text":"Estimate fishing effort bus-route designs using Horvitz–Thompson-style day×group total compute design-based totals variance via survey package. Supports replicate-weight designs.","code":""},{"path":"/reference/est_effort.busroute_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bus-Route Effort Estimation (survey-first HT) — est_effort.busroute_design","text":"","code":"est_effort.busroute_design(   x,   counts = NULL,   by = c(\"date\", \"location\"),   day_id = \"date\",   inclusion_prob_col = \"inclusion_prob\",   route_minutes_col = \"route_minutes\",   contrib_hours_col = NULL,   covariates = NULL,   svy = NULL,   conf_level = 0.95,   ... )"},{"path":"/reference/est_effort.busroute_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bus-Route Effort Estimation (survey-first HT) — est_effort.busroute_design","text":"x busroute_design object. counts Optional tibble/data.frame observation data. x contains $counts, used default. Character vector grouping variables retain output (e.g., date, location). Missing columns ignored warning. day_id Day identifier (PSU), typically date. inclusion_prob_col Column name inclusion probability pi observed party/vehicle count segment (default inclusion_prob). route_minutes_col Per-visit route minutes column translate counts time (default route_minutes). Used contrib_hours_col given. contrib_hours_col Optional precomputed contribution hours observed unit (e.g., observed overlap hours). present, HT contribution contrib_hours / pi. Otherwise uses count / pi * route_minutes/60. covariates Optional character vector additional grouping variables. svy Optional svydesign/svrepdesign encoding day-level sampling. absent, day-PSU design constructed x$calendar via as_day_svydesign(). conf_level Confidence level CI (default 0.95). ... Reserved future arguments.","code":""},{"path":"/reference/est_effort.busroute_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bus-Route Effort Estimation (survey-first HT) — est_effort.busroute_design","text":"tibble group columns, estimate, se, ci_low, ci_high, n, method, diagnostics list-column.","code":""},{"path":"/reference/est_effort.busroute_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bus-Route Effort Estimation (survey-first HT) — est_effort.busroute_design","text":"Computes day × group totals using Horvitz–Thompson contributions uses day-PSU survey design compute totals/variance via survey package. Replicate-weight designs supported passing svrepdesign.","code":""},{"path":"/reference/est_effort.busroute_design.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bus-Route Effort Estimation (survey-first HT) — est_effort.busroute_design","text":"Malvestuto, S.P. (1996). Sampling creel survey data. : Murphy, B.R. & Willis, D.W. (eds) Fisheries Techniques, 2nd Edition. American Fisheries Society.","code":""},{"path":"/reference/est_effort.busroute_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bus-Route Effort Estimation (survey-first HT) — est_effort.busroute_design","text":"","code":"if (FALSE) { # \\dontrun{ # Example: Create bus-route design and estimate effort # design <- design_busroute(counts, schedule, calendar) # est_effort(design, by = c(\"date\", \"location\")) } # }"},{"path":"/reference/est_effort.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Fishing Effort (survey-first wrapper) — est_effort","title":"Estimate Fishing Effort (survey-first wrapper) — est_effort","text":"High-level convenience wrapper delegates survey-first instantaneous progressive estimators. ensures valid day-level survey design available passes appropriate estimator.","code":""},{"path":"/reference/est_effort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Fishing Effort (survey-first wrapper) — est_effort","text":"","code":"est_effort(   design,   counts,   method = c(\"instantaneous\", \"progressive\"),   by = NULL,   day_id = \"date\",   covariates = NULL,   conf_level = 0.95,   ... )"},{"path":"/reference/est_effort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Fishing Effort (survey-first wrapper) — est_effort","text":"design day-level svydesign/svrepdesign creel_design contains calendar constructing day PSU design. counts Data frame/tibble counts appropriate chosen method. method One \"instantaneous\" (snapshot counts) \"progressive\" (roving/pass-based counts). Character vector grouping variables present counts. NULL, best-effort default used (e.g., location, stratum, shift_block available). day_id Day identifier (PSU) present counts survey design (default \"date\"). covariates Optional character vector additional grouping variables present counts. conf_level Confidence level CIs (default 0.95). ... Forwarded specific estimator.","code":""},{"path":"/reference/est_effort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Fishing Effort (survey-first wrapper) — est_effort","text":"tibble group columns, estimate, se, ci_low, ci_high, n, method, diagnostics list-column.","code":""},{"path":"/reference/est_effort.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Fishing Effort (survey-first wrapper) — est_effort","text":"Effort computed day × group totals combined using survey::svytotal/survey::svyby, variance survey design (including replicate-weight designs via svrepdesign).","code":""},{"path":[]},{"path":"/reference/est_effort.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Fishing Effort (survey-first wrapper) — est_effort","text":"","code":"if (FALSE) { # \\dontrun{ # Build a day-level design from a calendar svy_day <- as_day_svydesign(calendar, day_id = \"date\",   strata_vars = c(\"day_type\",\"month\"))  # Instantaneous effort by location est_effort(svy_day, counts_inst, method = \"instantaneous\", by = \"location\")  # Progressive effort by location est_effort(svy_day, counts_roving, method = \"progressive\", by = \"location\") } # }"},{"path":"/reference/est_effort.instantaneous.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantaneous Effort Estimator (survey-first) — est_effort.instantaneous","title":"Instantaneous Effort Estimator (survey-first) — est_effort.instantaneous","text":"Estimate angler-hours instantaneous (snapshot) counts using mean-count expansion per day × group, compute design-based totals variance via survey package day-level design supplied.","code":""},{"path":"/reference/est_effort.instantaneous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantaneous Effort Estimator (survey-first) — est_effort.instantaneous","text":"","code":"est_effort.instantaneous(   counts,   by = c(\"date\", \"location\"),   minutes_col = c(\"interval_minutes\", \"count_duration\", \"flight_minutes\"),   total_minutes_col = c(\"total_minutes\", \"total_day_minutes\", \"block_total_minutes\"),   day_id = \"date\",   covariates = NULL,   svy = NULL,   conf_level = 0.95 )"},{"path":"/reference/est_effort.instantaneous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantaneous Effort Estimator (survey-first) — est_effort.instantaneous","text":"counts Tibble/data.frame instantaneous counts columns: count, minutes column (one interval_minutes, count_duration, flight_minutes), grouping variables (e.g., date, location), optionally total_day_minutes total_minutes day-level expansion. Character vector grouping variables (e.g., date, location). Missing columns ignored warning. minutes_col Candidate name(s) per-count minutes. first present used. total_minutes_col Candidate name(s) day×group total minutes. absent, falls back sum per-count minutes within day×group (warns). day_id Day identifier (PSU), typically date, used join survey design. covariates Optional character vector additional grouping variables (e.g., shift_block, day_type). svy Optional svydesign/svrepdesign day-level sampling design. conf_level Confidence level Wald CIs (default 0.95).","code":""},{"path":"/reference/est_effort.instantaneous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantaneous Effort Estimator (survey-first) — est_effort.instantaneous","text":"Tibble grouping columns, estimate, se, ci_low, ci_high, n, method, diagnostics list-column.","code":""},{"path":"/reference/est_effort.instantaneous.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Instantaneous Effort Estimator (survey-first) — est_effort.instantaneous","text":"Effort per day×group = mean(count) × total_minutes ÷ 60. Aggregates per-count observations day × group totals uses day-PSU survey design compute totals/variance via survey package. svy provided, non-design fallback uses within-group variability approximate SE/CI; prefer valid survey design defensible inference.","code":""},{"path":[]},{"path":"/reference/est_effort.progressive.html","id":null,"dir":"Reference","previous_headings":"","what":"Progressive (Roving) Effort Estimator (survey-first) — est_effort.progressive","title":"Progressive (Roving) Effort Estimator (survey-first) — est_effort.progressive","text":"Estimate angler-hours progressive (roving) counts summing pass-level counts × route_minutes per day × group, compute design-based totals variance via survey package day-level design supplied.","code":""},{"path":"/reference/est_effort.progressive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Progressive (Roving) Effort Estimator (survey-first) — est_effort.progressive","text":"","code":"est_effort.progressive(   counts,   by = c(\"date\", \"location\"),   route_minutes_col = c(\"route_minutes\", \"circuit_minutes\"),   pass_id = c(\"pass_id\", \"circuit_id\"),   day_id = \"date\",   covariates = NULL,   svy = NULL,   conf_level = 0.95 )"},{"path":"/reference/est_effort.progressive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Progressive (Roving) Effort Estimator (survey-first) — est_effort.progressive","text":"counts Tibble/data.frame progressive counts columns: count, route_minutes (candidate), grouping variables (e.g., date, location), optional pass_id/circuit_id. Character vector grouping variables (e.g., date, location). Missing columns ignored warning. route_minutes_col Name(s) per-pass route minutes column; first present used. pass_id Optional column name identifying passes. absent, rows treated pass records summed within day × group. day_id Day identifier (PSU), typically date, used join survey design. covariates Optional character vector additional grouping variables. svy Optional svydesign/svrepdesign day-level sampling design. conf_level Confidence level Wald CIs (default 0.95).","code":""},{"path":"/reference/est_effort.progressive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Progressive (Roving) Effort Estimator (survey-first) — est_effort.progressive","text":"Tibble grouping columns, estimate, se, ci_low, ci_high, n, method, diagnostics list-column.","code":""},{"path":"/reference/est_effort.progressive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Progressive (Roving) Effort Estimator (survey-first) — est_effort.progressive","text":"Effort per day×group = sum_over_passes(count_pass × route_minutes) ÷ 60. Sums pass-level contributions day × group totals uses day-PSU survey design compute totals variance via survey package.","code":""},{"path":[]},{"path":"/reference/est_effort_aerial.html","id":null,"dir":"Reference","previous_headings":"","what":"Back-compat alias for aerial estimator — est_effort_aerial","title":"Back-compat alias for aerial estimator — est_effort_aerial","text":"Accepts either creel_design x embedded counts counts data frame directly. Prefer est_effort.aerial() counts.","code":""},{"path":"/reference/est_effort_aerial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Back-compat alias for aerial estimator — est_effort_aerial","text":"","code":"est_effort_aerial(   x = NULL,   counts = NULL,   by = c(\"date\", \"location\"),   minutes_col = c(\"flight_minutes\", \"interval_minutes\", \"count_duration\"),   total_minutes_col = c(\"total_minutes\", \"total_day_minutes\", \"block_total_minutes\"),   day_id = \"date\",   covariates = NULL,   visibility_col = NULL,   calibration_col = NULL,   svy = NULL,   conf_level = 0.95,   ... )"},{"path":"/reference/est_effort_aerial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Back-compat alias for aerial estimator — est_effort_aerial","text":"x Optional creel_design containing $counts component. counts Data frame/tibble aerial counts least count minutes column (e.g., flight_minutes, interval_minutes, count_duration). Character vector grouping variables present counts (e.g., date, location). Missing columns ignored warning. minutes_col Candidate column names minutes represented count. first present used. total_minutes_col Optional column giving total minutes represented whole day×group (e.g., full day length block coverage). absent, estimator falls back sum per-count minutes within day×group (warns). day_id Day identifier (PSU), typically date, used join survey design. covariates Optional character vector additional grouping variables aerial conditions (e.g., cloud, glare, observer, altitude). visibility_col Optional name column visibility proportion (0–1). Counts divided value (guarded avoid division small numbers). calibration_col Optional name column multiplicative calibration factors apply visibility correction. svy Optional svydesign/svrepdesign encoding day sampling design (must include day_id svy$variables). provided, totals, SEs, CIs computed survey functions. conf_level Confidence level Wald CIs (default 0.95).","code":""},{"path":"/reference/estimate_cpue.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Catch Per Unit Effort (CPUE) — estimate_cpue","title":"Estimate Catch Per Unit Effort (CPUE) — estimate_cpue","text":"Estimates catch per unit effort species, mode, grouping variables. Supports number-based (fish per hour) weight-based (kg per hour) CPUE.","code":""},{"path":"/reference/estimate_cpue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Catch Per Unit Effort (CPUE) — estimate_cpue","text":"","code":"estimate_cpue(   design,   by = NULL,   species = NULL,   type = c(\"number\", \"weight\"),   level = 0.95 )"},{"path":"/reference/estimate_cpue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Catch Per Unit Effort (CPUE) — estimate_cpue","text":"design creel design object created design_access, design_roving, design_repweights. Character vector variables group estimates . Default estimate overall CPUE. species Character vector species include. NULL, includes species data. type Character, either \"number\" (fish per hour) \"weight\" (kg per hour). Default \"number\". level Confidence level confidence intervals. Default 0.95.","code":""},{"path":"/reference/estimate_cpue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Catch Per Unit Effort (CPUE) — estimate_cpue","text":"tibble columns: group_vars Grouping variables list column n Number interviews group cpue_estimate Estimated CPUE cpue_se Standard error CPUE estimate cpue_lower Lower confidence limit cpue_upper Upper confidence limit species Species included estimate type Type CPUE (number weight) design_type Type survey design used","code":""},{"path":"/reference/estimate_cpue.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Catch Per Unit Effort (CPUE) — estimate_cpue","text":"","code":"if (FALSE) { # \\dontrun{ # Estimate CPUE by species cpue_by_species <- estimate_cpue(design, by = \"target_species\")  # Estimate weight-based CPUE for bass bass_cpue_weight <- estimate_cpue(design, species = \"bass\", type = \"weight\") } # }"},{"path":"/reference/estimate_effort.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Fishing Effort — estimate_effort","title":"Estimate Fishing Effort — estimate_effort","text":"Estimates total fishing effort (angler-hours party-hours) strata overall, using survey design weights. Supports access-point roving survey designs.","code":""},{"path":"/reference/estimate_effort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Fishing Effort — estimate_effort","text":"","code":"estimate_effort(design, by = NULL, total = TRUE, level = 0.95)"},{"path":"/reference/estimate_effort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Fishing Effort — estimate_effort","text":"design creel design object created design_access, design_roving, design_repweights. Character vector variables group estimates . Default strata variables defined design. total Logical, whether include overall total estimate addition grouped estimates. Default TRUE. level Confidence level confidence intervals. Default 0.95.","code":""},{"path":"/reference/estimate_effort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Fishing Effort — estimate_effort","text":"tibble columns: group_vars Grouping variables list column n Number interviews group effort_estimate Estimated total effort effort_se Standard error effort estimate effort_lower Lower confidence limit effort_upper Upper confidence limit design_type Type survey design used estimation_method Method used estimation","code":""},{"path":"/reference/estimate_effort.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Fishing Effort — estimate_effort","text":"","code":"if (FALSE) { # \\dontrun{ # Create design interviews <- readr::read_csv(system.file(\"extdata/toy_interviews.csv\",   package = \"tidycreel\" )) calendar <- readr::read_csv(system.file(\"extdata/toy_calendar.csv\",   package = \"tidycreel\" ))  design <- design_access(interviews = interviews, calendar = calendar)  # Estimate effort by date effort_by_date <- estimate_effort(design, by = \"date\")  # Estimate effort by location and mode effort_by_location_mode <- estimate_effort(design, by = c(\"location\", \"mode\")) } # }"},{"path":"/reference/estimate_harvest.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Total Harvest — estimate_harvest","title":"Estimate Total Harvest — estimate_harvest","text":"Estimates total harvest (catch kept) species, mode, grouping variables. Supports number-based (count) weight-based (kg) harvest.","code":""},{"path":"/reference/estimate_harvest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Total Harvest — estimate_harvest","text":"","code":"estimate_harvest(   design,   by = NULL,   species = NULL,   type = c(\"number\", \"weight\"),   level = 0.95 )"},{"path":"/reference/estimate_harvest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Total Harvest — estimate_harvest","text":"design creel design object created design_access, design_roving, design_repweights. Character vector variables group estimates . Default estimate overall harvest. species Character vector species include. NULL, includes species data. type Character, either \"number\" (count) \"weight\" (kg). Default \"number\". level Confidence level confidence intervals. Default 0.95.","code":""},{"path":"/reference/estimate_harvest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Total Harvest — estimate_harvest","text":"tibble columns: group_vars Grouping variables list column n Number interviews group harvest_estimate Estimated total harvest harvest_se Standard error harvest estimate harvest_lower Lower confidence limit harvest_upper Upper confidence limit species Species included estimate type Type harvest (number weight) design_type Type survey design used","code":""},{"path":"/reference/estimate_harvest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Total Harvest — estimate_harvest","text":"","code":"if (FALSE) { # \\dontrun{ # Estimate harvest by species harvest_by_species <- estimate_harvest(design, by = \"target_species\")  # Estimate weight-based harvest for walleye walleye_harvest_weight <- estimate_harvest(design, species = \"walleye\", type = \"weight\") } # }"},{"path":"/reference/estimators.html","id":null,"dir":"Reference","previous_headings":"","what":"Core Estimators for Creel Survey Analysis — estimators","title":"Core Estimators for Creel Survey Analysis — estimators","text":"functions provide design-based estimation fishing effort, catch per unit effort (CPUE), harvest totals creel surveys. estimators integrate survey design objects created design constructors.","code":""},{"path":"/reference/hectares_to_acres.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert hectares to acres — hectares_to_acres","title":"Convert hectares to acres — hectares_to_acres","text":"Convert hectares acres","code":""},{"path":"/reference/hectares_to_acres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert hectares to acres — hectares_to_acres","text":"","code":"hectares_to_acres(x)"},{"path":"/reference/hectares_to_acres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert hectares to acres — hectares_to_acres","text":"x numeric vector (hectares)","code":""},{"path":"/reference/hectares_to_acres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert hectares to acres — hectares_to_acres","text":"numeric vector (acres)","code":""},{"path":"/reference/interval_minutes.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate interval in minutes between two time columns — interval_minutes","title":"Calculate interval in minutes between two time columns — interval_minutes","text":"Uses lubridate compute difference minutes two POSIXct vectors.","code":""},{"path":"/reference/interval_minutes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate interval in minutes between two time columns — interval_minutes","text":"","code":"interval_minutes(start, end)"},{"path":"/reference/interval_minutes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate interval in minutes between two time columns — interval_minutes","text":"start POSIXct vector end POSIXct vector","code":""},{"path":"/reference/interval_minutes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate interval in minutes between two time columns — interval_minutes","text":"Numeric vector interval lengths minutes","code":""},{"path":"/reference/interval_minutes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate interval in minutes between two time columns — interval_minutes","text":"","code":"start_time <- as.POSIXct(\"2025-01-01 08:00:00\") end_time <- as.POSIXct(\"2025-01-01 12:30:00\") interval_minutes(start_time, end_time) #> [1] 270"},{"path":"/reference/interview_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Interview Data Schema — interview_schema","title":"Interview Data Schema — interview_schema","text":"Defines expected structure angler interview data.","code":""},{"path":"/reference/interview_schema.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Interview Data Schema — interview_schema","text":"tibble following columns: interview_id Character, unique interview identifier date Date, interview date time_start POSIXct, interview start time time_end POSIXct, interview end time location Character, sampling location mode Character, fishing mode (bank, boat, ice, etc.) party_size Integer, number anglers party hours_fished Numeric, hours fished party target_species Character, primary target species catch_total Integer, total fish caught catch_kept Integer, fish kept catch_released Integer, fish released weight_total Numeric, total weight catch (kg) trip_complete Logical, TRUE trip complete interview effort_expansion Numeric, expansion factor effort estimation","code":""},{"path":"/reference/is.even.html","id":null,"dir":"Reference","previous_headings":"","what":"Even-number predicate — is.even","title":"Even-number predicate — is.even","text":"Even-number predicate","code":""},{"path":"/reference/is.even.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Even-number predicate — is.even","text":"","code":"is.even(x)"},{"path":"/reference/is.even.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Even-number predicate — is.even","text":"x integer/numeric vector","code":""},{"path":"/reference/is.even.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Even-number predicate — is.even","text":"logical","code":""},{"path":"/reference/na.return.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace NAs with a value (compat) — na.return","title":"Replace NAs with a value (compat) — na.return","text":"Replace NAs value (compat)","code":""},{"path":"/reference/na.return.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace NAs with a value (compat) — na.return","text":"","code":"na.return(x, value = NA)"},{"path":"/reference/na.return.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace NAs with a value (compat) — na.return","text":"x vector value replacement value (default NA)","code":""},{"path":"/reference/na.return.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace NAs with a value (compat) — na.return","text":"vector NAs replaced","code":""},{"path":"/reference/parse_time_column.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse time columns using lubridate — parse_time_column","title":"Parse time columns using lubridate — parse_time_column","text":"Attempts parse vector time strings POSIXct using lubridate. Returns parsed times original already POSIXct.","code":""},{"path":"/reference/parse_time_column.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse time columns using lubridate — parse_time_column","text":"","code":"parse_time_column(x)"},{"path":"/reference/parse_time_column.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse time columns using lubridate — parse_time_column","text":"x Character vector POSIXct","code":""},{"path":"/reference/parse_time_column.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse time columns using lubridate — parse_time_column","text":"POSIXct vector","code":""},{"path":"/reference/parse_time_column.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parse time columns using lubridate — parse_time_column","text":"","code":"parse_time_column(c(\"2025-08-20 08:00:00\", \"2025-08-20 12:00:00\")) #> [1] \"2025-08-20 08:00:00 UTC\" \"2025-08-20 12:00:00 UTC\""},{"path":"/reference/plot_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot survey design structure — plot_design","title":"Plot survey design structure — plot_design","text":"Visualize survey design date, shift, location, stratum, grouping variables. Supports bar plots, faceted plots, interactive plots (via plotly available).","code":""},{"path":"/reference/plot_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot survey design structure — plot_design","text":"","code":"plot_design(   design,   by = c(\"date\", \"shift_block\", \"location\", \"stratum\"),   type = c(\"bar\", \"facet\", \"interactive\"),   ... )"},{"path":"/reference/plot_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot survey design structure — plot_design","text":"design creel_design object data frame survey structure. Character vector grouping variables (e.g., date, shift_block, location, stratum). type Plot type: \"bar\", \"facet\", \"interactive\". ... Additional arguments passed ggplot2 plotly.","code":""},{"path":"/reference/plot_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot survey design structure — plot_design","text":"ggplot plotly object.","code":""},{"path":"/reference/plot_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot survey design structure — plot_design","text":"Visualizes survey design structure effort estimates. Supports bar, facet, interactive plots. See vignettes usage examples.","code":""},{"path":"/reference/plot_design.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot survey design structure — plot_design","text":"Wickham, H. (2016). ggplot2: Elegant Graphics Data Analysis. Springer-Verlag New York.","code":""},{"path":"/reference/plot_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot survey design structure — plot_design","text":"","code":"if (FALSE) { # \\dontrun{ # Create a design first design <- design_access(interviews, calendar)  # Plot survey design structure plot_design(design, by = c(\"date\", \"shift_block\"), type = \"bar\") } # }"},{"path":"/reference/plot_effort.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot effort estimates — plot_effort","title":"Plot effort estimates — plot_effort","text":"Visualize effort estimates stratum, date, location, grouping variables. Supports line, bar, interactive plots.","code":""},{"path":"/reference/plot_effort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot effort estimates — plot_effort","text":"","code":"plot_effort(   effort_df,   by = c(\"date\", \"location\", \"stratum\"),   type = c(\"line\", \"bar\", \"interactive\"),   ... )"},{"path":"/reference/plot_effort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot effort estimates — plot_effort","text":"effort_df Data frame/tibble effort estimates (output est_effort similar). Character vector grouping variables. type Plot type: \"line\", \"bar\", \"interactive\". ... Additional arguments passed ggplot2 plotly.","code":""},{"path":"/reference/plot_effort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot effort estimates — plot_effort","text":"ggplot plotly object.","code":""},{"path":"/reference/plot_effort.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot effort estimates — plot_effort","text":"Visualizes effort estimates stratum, date, location, grouping variables. Supports line, bar, interactive plots. See vignettes usage examples.","code":""},{"path":"/reference/plot_effort.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot effort estimates — plot_effort","text":"Wickham, H. (2016). ggplot2: Elegant Graphics Data Analysis. Springer-Verlag New York.","code":""},{"path":"/reference/plot_effort.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot effort estimates — plot_effort","text":"","code":"if (FALSE) { # \\dontrun{ # First estimate effort effort_est <- est_effort(design, counts, by = c(\"date\", \"location\"))  # Plot effort estimates plot_effort(effort_est, by = c(\"date\", \"location\"), type = \"line\") } # }"},{"path":"/reference/reference_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Reference Table Schema — reference_schema","title":"Reference Table Schema — reference_schema","text":"Defines expected structure reference tables (species, waterbody, etc.).","code":""},{"path":"/reference/reference_schema.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Reference Table Schema — reference_schema","text":"tibble following columns: code Character, unique code description Character, code description","code":""},{"path":"/reference/report_dropped_rows.html","id":null,"dir":"Reference","previous_headings":"","what":"Report dropped rows — report_dropped_rows","title":"Report dropped rows — report_dropped_rows","text":"Returns summary rows dropped due missing invalid data.","code":""},{"path":"/reference/report_dropped_rows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Report dropped rows — report_dropped_rows","text":"","code":"report_dropped_rows(original, filtered)"},{"path":"/reference/report_dropped_rows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Report dropped rows — report_dropped_rows","text":"original Original data.frame filtered Filtered data.frame","code":""},{"path":"/reference/report_dropped_rows.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Report dropped rows — report_dropped_rows","text":"List n_dropped dropped_rows","code":""},{"path":"/reference/report_dropped_rows.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Report dropped rows — report_dropped_rows","text":"","code":"df_original <- data.frame(id = 1:3, value = c(10, NA, 30)) df_cleaned <- data.frame(id = c(1, 3), value = c(10, 30)) report_dropped_rows(df_original, df_cleaned) #> $n_dropped #> [1] 1 #>  #> $dropped_rows #>   id value #> 1  2    NA #>"},{"path":"/reference/schema_test_runner.html","id":null,"dir":"Reference","previous_headings":"","what":"Run All Schema Validation Functions — schema_test_runner","title":"Run All Schema Validation Functions — schema_test_runner","text":"function runs available schema validation functions named list tibbles. returns list results (invisible pass, errors fail).","code":""},{"path":"/reference/schema_test_runner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run All Schema Validation Functions — schema_test_runner","text":"","code":"schema_test_runner(data_list, strict = TRUE)"},{"path":"/reference/schema_test_runner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run All Schema Validation Functions — schema_test_runner","text":"data_list Named list tibbles: names must match schema types (calendar, interviews, counts, auxiliary, reference) strict Logical, TRUE throws error validation failure","code":""},{"path":"/reference/schema_test_runner.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run All Schema Validation Functions — schema_test_runner","text":"Invisibly returns validated data, errors invalid","code":""},{"path":"/reference/schema_test_runner.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run All Schema Validation Functions — schema_test_runner","text":"","code":"schema_test_runner(list(   calendar = calendar_tbl,   interviews = interviews_tbl,   counts = counts_tbl,   auxiliary = auxiliary_tbl,   reference = reference_tbl )) #> Error: object 'calendar_tbl' not found"},{"path":"/reference/standardize_time_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize time column names using stringr — standardize_time_columns","title":"Standardize time column names using stringr — standardize_time_columns","text":"Renames columns data.frame standard time column names common variants found.","code":""},{"path":"/reference/standardize_time_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize time column names using stringr — standardize_time_columns","text":"","code":"standardize_time_columns(df)"},{"path":"/reference/standardize_time_columns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize time column names using stringr — standardize_time_columns","text":"df Data.frame","code":""},{"path":"/reference/standardize_time_columns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize time column names using stringr — standardize_time_columns","text":"Data.frame standardized time column names","code":""},{"path":"/reference/standardize_time_columns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardize time column names using stringr — standardize_time_columns","text":"","code":"df <- data.frame(timestamp = \"2025-01-01 08:00\", value = 1) standardize_time_columns(df) #>               time value #> 1 2025-01-01 08:00     1"},{"path":"/reference/tc_abort_missing_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Abort with a standardized message for missing columns (cli) — tc_abort_missing_cols","title":"Abort with a standardized message for missing columns (cli) — tc_abort_missing_cols","text":"Abort standardized message missing columns (cli)","code":""},{"path":"/reference/tc_abort_missing_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Abort with a standardized message for missing columns (cli) — tc_abort_missing_cols","text":"","code":"tc_abort_missing_cols(df, cols, context = \"\")"},{"path":"/reference/tc_abort_missing_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Abort with a standardized message for missing columns (cli) — tc_abort_missing_cols","text":"df Data frame check cols Required columns context Context string error message","code":""},{"path":"/reference/tc_as_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility: Parse to POSIXct — tc_as_time","title":"Utility: Parse to POSIXct — tc_as_time","text":"Parses vector POSIXct using lubridate available, else base R.","code":""},{"path":"/reference/tc_as_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility: Parse to POSIXct — tc_as_time","text":"","code":"tc_as_time(x)"},{"path":"/reference/tc_as_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility: Parse to POSIXct — tc_as_time","text":"x Character numeric vector","code":""},{"path":"/reference/tc_as_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility: Parse to POSIXct — tc_as_time","text":"POSIXct vector","code":""},{"path":"/reference/tc_clamp01.html","id":null,"dir":"Reference","previous_headings":"","what":"Clamp probabilities to (0,1] with a warning — tc_clamp01","title":"Clamp probabilities to (0,1] with a warning — tc_clamp01","text":"Clamp probabilities (0,1] warning","code":""},{"path":"/reference/tc_clamp01.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clamp probabilities to (0,1] with a warning — tc_clamp01","text":"","code":"tc_clamp01(x, name = \"probability\")"},{"path":"/reference/tc_clamp01.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clamp probabilities to (0,1] with a warning — tc_clamp01","text":"x numeric vector probabilities name optional name messaging","code":""},{"path":"/reference/tc_clamp01.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clamp probabilities to (0,1] with a warning — tc_clamp01","text":"clamped numeric vector","code":""},{"path":"/reference/tc_confint.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility: Confidence Interval Helper — tc_confint","title":"Utility: Confidence Interval Helper — tc_confint","text":"Computes normal t-based confidence interval.","code":""},{"path":"/reference/tc_confint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility: Confidence Interval Helper — tc_confint","text":"","code":"tc_confint(mean, se, level = 0.95, df = NULL)"},{"path":"/reference/tc_confint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility: Confidence Interval Helper — tc_confint","text":"mean Numeric mean se Standard error level Confidence level df Degrees freedom (optional)","code":""},{"path":"/reference/tc_confint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility: Confidence Interval Helper — tc_confint","text":"Numeric vector: lower, upper","code":""},{"path":"/reference/tc_diag_drop.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility: Diagnostics for Dropped Rows — tc_diag_drop","title":"Utility: Diagnostics for Dropped Rows — tc_diag_drop","text":"Builds diagnostics tibble dropped rows.","code":""},{"path":"/reference/tc_diag_drop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility: Diagnostics for Dropped Rows — tc_diag_drop","text":"","code":"tc_diag_drop(df_before, df_after, reason)"},{"path":"/reference/tc_diag_drop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility: Diagnostics for Dropped Rows — tc_diag_drop","text":"df_before Data frame dropping df_after Data frame dropping reason Reason drop","code":""},{"path":"/reference/tc_diag_drop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility: Diagnostics for Dropped Rows — tc_diag_drop","text":"Tibble diagnostics","code":""},{"path":"/reference/tc_drop_na_rows.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop rows with missing values in required columns; return diagnostics — tc_drop_na_rows","title":"Drop rows with missing values in required columns; return diagnostics — tc_drop_na_rows","text":"Drop rows missing values required columns; return diagnostics","code":""},{"path":"/reference/tc_drop_na_rows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop rows with missing values in required columns; return diagnostics — tc_drop_na_rows","text":"","code":"tc_drop_na_rows(df, required_cols, reason = \"missing required fields\")"},{"path":"/reference/tc_drop_na_rows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop rows with missing values in required columns; return diagnostics — tc_drop_na_rows","text":"df data.frame required_cols character vector column names reason text reason diagnostics","code":""},{"path":"/reference/tc_drop_na_rows.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drop rows with missing values in required columns; return diagnostics — tc_drop_na_rows","text":"list(df = filtered_df, diagnostics = tibble)","code":""},{"path":"/reference/tc_group_warn.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility: Group Warn — tc_group_warn","title":"Utility: Group Warn — tc_group_warn","text":"Drops absent grouping columns warning.","code":""},{"path":"/reference/tc_group_warn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility: Group Warn — tc_group_warn","text":"","code":"tc_group_warn(by, df_names)"},{"path":"/reference/tc_group_warn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility: Group Warn — tc_group_warn","text":"Character vector grouping columns df_names Names data frame","code":""},{"path":"/reference/tc_group_warn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility: Group Warn — tc_group_warn","text":"Filtered grouping columns","code":""},{"path":"/reference/tc_guess_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility: Guess Columns — tc_guess_cols","title":"Utility: Guess Columns — tc_guess_cols","text":"Maps synonyms standard column names present.","code":""},{"path":"/reference/tc_guess_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility: Guess Columns — tc_guess_cols","text":"","code":"tc_guess_cols(df, synonyms)"},{"path":"/reference/tc_guess_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility: Guess Columns — tc_guess_cols","text":"df Data frame synonyms Named character vector (names = standard, values = synonyms)","code":""},{"path":"/reference/tc_guess_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility: Guess Columns — tc_guess_cols","text":"Data frame columns renamed","code":""},{"path":"/reference/tc_require_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility: Require Columns — tc_require_cols","title":"Utility: Require Columns — tc_require_cols","text":"Checks required columns present data.frame. Throws error listing missing columns.","code":""},{"path":"/reference/tc_require_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility: Require Columns — tc_require_cols","text":"","code":"tc_require_cols(df, cols, context = \"\")"},{"path":"/reference/tc_require_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility: Require Columns — tc_require_cols","text":"df Data frame check cols Character vector required column names context Optional string describing context (error message)","code":""},{"path":"/reference/tc_require_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility: Require Columns — tc_require_cols","text":"Invisibly returns TRUE columns present","code":""},{"path":"/reference/tc_require_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utility: Require Columns — tc_require_cols","text":"","code":"tc_require_cols(data.frame(a=1, b=2), c(\"a\", \"b\"))"},{"path":"/reference/tidycreel-compat-stubs.html","id":null,"dir":"Reference","previous_headings":"","what":"Legacy stubs removed; not part of the package — tidycreel-compat-stubs","title":"Legacy stubs removed; not part of the package — tidycreel-compat-stubs","text":"Legacy stubs removed; part package","code":""},{"path":"/reference/tidycreel-package.html","id":null,"dir":"Reference","previous_headings":"","what":"tidycreel: Tools for creel survey design, estimation, and reporting — tidycreel-package","title":"tidycreel: Tools for creel survey design, estimation, and reporting — tidycreel-package","text":"(One-sentence summary goes .)","code":""},{"path":[]},{"path":"/reference/tidycreel-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"tidycreel: Tools for creel survey design, estimation, and reporting — tidycreel-package","text":"Maintainer: Christopher Chizinski chris.chizinski@unl.edu (ORCID)","code":""},{"path":"/reference/trim.html","id":null,"dir":"Reference","previous_headings":"","what":"Trim leading and trailing whitespace — trim","title":"Trim leading and trailing whitespace — trim","text":"Trim leading trailing whitespace","code":""},{"path":"/reference/trim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trim leading and trailing whitespace — trim","text":"","code":"trim(x)"},{"path":"/reference/trim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trim leading and trailing whitespace — trim","text":"x character vector","code":""},{"path":"/reference/trim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trim leading and trailing whitespace — trim","text":"character vector","code":""},{"path":"/reference/validate_allowed_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate values in a column — validate_allowed_values","title":"Validate values in a column — validate_allowed_values","text":"Checks values column within set allowed values. Returns TRUE valid, otherwise returns vector invalid values.","code":""},{"path":"/reference/validate_allowed_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate values in a column — validate_allowed_values","text":"","code":"validate_allowed_values(x, allowed)"},{"path":"/reference/validate_allowed_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate values in a column — validate_allowed_values","text":"x Vector values allowed Allowed values","code":""},{"path":"/reference/validate_allowed_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate values in a column — validate_allowed_values","text":"TRUE valid, else vector invalid values","code":""},{"path":"/reference/validate_allowed_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate values in a column — validate_allowed_values","text":"","code":"shifts <- c(\"AM\", \"PM\", \"AM\") validate_allowed_values(shifts, c(\"AM\", \"PM\", \"EVE\")) #> [1] TRUE"},{"path":"/reference/validate_auxiliary.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate auxiliary data schema — validate_auxiliary","title":"Validate auxiliary data schema — validate_auxiliary","text":"Validate auxiliary data schema","code":""},{"path":"/reference/validate_auxiliary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate auxiliary data schema — validate_auxiliary","text":"","code":"validate_auxiliary(auxiliary, strict = TRUE)"},{"path":"/reference/validate_auxiliary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate auxiliary data schema — validate_auxiliary","text":"auxiliary tibble containing auxiliary data strict Logical, TRUE throws error validation failure","code":""},{"path":"/reference/validate_auxiliary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate auxiliary data schema — validate_auxiliary","text":"Invisibly returns validated data, throws error invalid","code":""},{"path":"/reference/validate_calendar.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Calendar Data — validate_calendar","title":"Validate Calendar Data — validate_calendar","text":"Validates calendar data conforms expected schema.","code":""},{"path":"/reference/validate_calendar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Calendar Data — validate_calendar","text":"","code":"validate_calendar(calendar, strict = TRUE)"},{"path":"/reference/validate_calendar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Calendar Data — validate_calendar","text":"calendar tibble containing calendar data strict Logical, TRUE throws error validation failure","code":""},{"path":"/reference/validate_calendar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Calendar Data — validate_calendar","text":"Invisibly returns validated data, throws error invalid","code":""},{"path":"/reference/validate_calendar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Calendar Data — validate_calendar","text":"","code":"if (FALSE) { # \\dontrun{ calendar <- tibble::tibble(   date = as.Date(\"2024-01-01\"),   stratum_id = \"2024-01-01-weekday-morning\",   day_type = \"weekday\",   season = \"winter\",   month = \"January\",   weekend = FALSE,   holiday = FALSE,   shift_block = \"morning\",   target_sample = 10L,   actual_sample = 8L ) validate_calendar(calendar) } # }"},{"path":"/reference/validate_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Count Data — validate_counts","title":"Validate Count Data — validate_counts","text":"Validates instantaneous count data conforms expected schema.","code":""},{"path":"/reference/validate_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Count Data — validate_counts","text":"","code":"validate_counts(counts, strict = TRUE)"},{"path":"/reference/validate_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Count Data — validate_counts","text":"counts tibble containing count data strict Logical, TRUE throws error validation failure","code":""},{"path":"/reference/validate_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Count Data — validate_counts","text":"Invisibly returns validated data, throws error invalid","code":""},{"path":"/reference/validate_counts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Count Data — validate_counts","text":"","code":"if (FALSE) { # \\dontrun{ counts <- tibble::tibble(   count_id = \"CNT001\",   date = as.Date(\"2024-01-01\"),   time = as.POSIXct(\"2024-01-01 09:00:00\"),   location = \"Lake_A\",   mode = \"boat\",   anglers_count = 15L,   parties_count = 8L,   weather_code = \"clear\",   temperature = 22.5,   wind_speed = 5.2,   visibility = \"good\",   count_duration = 15 ) validate_counts(counts) } # }"},{"path":"/reference/validate_interviews.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Interview Data — validate_interviews","title":"Validate Interview Data — validate_interviews","text":"Validates interview data conforms expected schema.","code":""},{"path":"/reference/validate_interviews.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Interview Data — validate_interviews","text":"","code":"validate_interviews(interviews, strict = TRUE)"},{"path":"/reference/validate_interviews.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Interview Data — validate_interviews","text":"interviews tibble containing interview data strict Logical, TRUE throws error validation failure","code":""},{"path":"/reference/validate_interviews.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Interview Data — validate_interviews","text":"Invisibly returns validated data, throws error invalid","code":""},{"path":"/reference/validate_interviews.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Interview Data — validate_interviews","text":"","code":"if (FALSE) { # \\dontrun{ interviews <- tibble::tibble(   interview_id = \"INT001\",   date = as.Date(\"2024-01-01\"),   time_start = as.POSIXct(\"2024-01-01 08:00:00\"),   time_end = as.POSIXct(\"2024-01-01 08:15:00\"),   location = \"Lake_A\",   mode = \"boat\",   party_size = 2L,   hours_fished = 4.5,   target_species = \"walleye\",   catch_total = 5L,   catch_kept = 3L,   catch_released = 2L,   weight_total = 2.5,   trip_complete = TRUE,   effort_expansion = 1.0 ) validate_interviews(interviews) } # }"},{"path":"/reference/validate_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate reference table schema — validate_reference","title":"Validate reference table schema — validate_reference","text":"Validate reference table schema","code":""},{"path":"/reference/validate_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate reference table schema — validate_reference","text":"","code":"validate_reference(reference, strict = TRUE)"},{"path":"/reference/validate_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate reference table schema — validate_reference","text":"reference tibble containing reference table data strict Logical, TRUE throws error validation failure","code":""},{"path":"/reference/validate_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate reference table schema — validate_reference","text":"Invisibly returns validated data, throws error invalid","code":""},{"path":"/reference/validate_required_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate required columns in a data.frame — validate_required_columns","title":"Validate required columns in a data.frame — validate_required_columns","text":"Checks required columns present input data.frame tibble. Returns TRUE present, otherwise returns character vector missing columns.","code":""},{"path":"/reference/validate_required_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate required columns in a data.frame — validate_required_columns","text":"","code":"validate_required_columns(df, required)"},{"path":"/reference/validate_required_columns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate required columns in a data.frame — validate_required_columns","text":"df data.frame tibble required Character vector required column names","code":""},{"path":"/reference/validate_required_columns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate required columns in a data.frame — validate_required_columns","text":"TRUE present, else character vector missing columns","code":""},{"path":"/reference/validate_required_columns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate required columns in a data.frame — validate_required_columns","text":"","code":"df <- data.frame(date = \"2025-01-01\", count = 5) validate_required_columns(df, c(\"date\", \"count\")) #> [1] TRUE"},{"path":"/news/index.html","id":"tidycreel-0009000-development","dir":"Changelog","previous_headings":"","what":"tidycreel 0.0.0.9000 (development)","title":"tidycreel 0.0.0.9000 (development)","text":"Survey-first refactor: Estimation relies day-PSU designs as_day_svydesign() interview-level svydesign; legacy constructors (design_access, design_roving, design_repweights) removed. New effort estimators (survey-first): est_effort.instantaneous, est_effort.progressive, est_effort.aerial, est_effort.busroute_design design-based variance (supports svydesign svrepdesign). Aerial enhancements: visibility/calibration adjustments; optional post-stratification calibration via survey. estimate_effort(), estimate_cpue(), estimate_harvest() now error guidance new APIs. Replicate-weight helpers removed; use survey::.svrepdesign() day-PSU designs needed. Added “Survey Package Creel: Translator”. Added “Replicate Designs Creel Inference”. Updated “Getting Started”, “Effort (Survey-First)”, aerial examples use as_day_svydesign() new estimators. Docs/DevEx: Updated README, pkgdown navbar, AGENTS.md conventions; modernized CI workflows (R CMD check, lintr, pkgdown).","code":""},{"path":"/news/index.html","id":"tidycreel-0009000-2025-08-22","dir":"Changelog","previous_headings":"","what":"tidycreel 0.0.0.9000 (2025-08-22)","title":"tidycreel 0.0.0.9000 (2025-08-22)","text":"Added survey-first CPUE Catch estimators: est_cpue() (ratio--means default; mean--ratios option) est_catch() (totals via svytotal/svyby). Updated README Getting Started vignette CPUE/Catch examples; exported new functions; added minimal tests.","code":""}]
